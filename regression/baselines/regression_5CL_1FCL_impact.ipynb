{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hipecta.data import ctaTelescope2Matrix\n",
    "from hipecta import core\n",
    "import numpy as np\n",
    "import h5py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset, ConcatDataset, sampler\n",
    "from torch.optim import lr_scheduler\n",
    "import matplotlib.pyplot as plt\n",
    "import hipecta.plots as plots\n",
    "from torchvision import transforms, utils\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "\n",
    "converter_path = os.path.abspath(os.path.join('/home/jacquemont/GammaLearn/converter_hdf5'))\n",
    "if converter_path not in sys.path:\n",
    "    sys.path.append(converter_path)\n",
    "    \n",
    "from converter_hdf5 import *\n",
    "from datasets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CNNModelLST(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModelLST, self).__init__()\n",
    "        # conv1\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        # non-linearity\n",
    "        self.relu1 = nn.ReLU()\n",
    "        # maxpooling 1, by default floor\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2) # nn.AvgPool2d\n",
    "        # batch norm\n",
    "        self.batchnorm1 = nn.BatchNorm2d(16)\n",
    "        \n",
    "        # conv2\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        # non-linearity\n",
    "        self.relu2 = nn.ReLU()\n",
    "        # maxpooling 2\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        # batch norm\n",
    "        self.batchnorm2 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        # conv3\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        # non-linearity\n",
    "        self.relu3 = nn.ReLU()\n",
    "        # maxpooling 3\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=2) # nn.AvgPool2d\n",
    "        # batch norm\n",
    "        self.batchnorm3 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        # conv4\n",
    "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        # non-linearity\n",
    "        self.relu4 = nn.ReLU()\n",
    "        # maxpooling 4\n",
    "        self.maxpool4 = nn.MaxPool2d(kernel_size=2) # nn.AvgPool2d\n",
    "        # batch norm\n",
    "        self.batchnorm4 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        # conv5\n",
    "        self.conv5 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=0)\n",
    "        # non-linearity\n",
    "        self.relu5 = nn.ReLU()\n",
    "        \n",
    "        # readout, regression of energy, altitude, azimuth, xCore, yCore\n",
    "        #self.fc1 = nn.Linear(128, 5)\n",
    "         # readout, regression of xCore and yCore\n",
    "        self.fc1 = nn.Linear(128, 2)\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_uniform(m.weight.data, mode='fan_out')\n",
    "                \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.maxpool1(out)\n",
    "        out = self.batchnorm1(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.maxpool2(out)\n",
    "        out = self.batchnorm2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.relu3(out)\n",
    "        out = self.maxpool3(out)\n",
    "        out = self.batchnorm3(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.relu4(out)\n",
    "        out = self.maxpool4(out)\n",
    "        out = self.batchnorm4(out)\n",
    "        out = self.conv5(out)\n",
    "        out = self.relu5(out)\n",
    "\n",
    "        # Reshape out from 100,128,1 to 100,128\n",
    "        out = out.view(out.size(0),-1)\n",
    "        \n",
    "        out = self.fc1(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_file = '/home/jacquemont/projets_CTA/gamma0.hdf5'\n",
    "f = h5py.File(test_file, 'r')\n",
    "injTable = np.array(f['/Cameras/LSTCAM/injTable'])\n",
    "nbRow = f['/Cameras/LSTCAM'].attrs['nbRow']\n",
    "nbCol = f['/Cameras/LSTCAM'].attrs['nbCol']\n",
    "test_dataset = LSTCamDataset(hdf5_file=f,\n",
    "                             transform=transforms.Compose([\n",
    "                                 TelescopeToSquareMatrix(injTable, nbRow, nbCol),\n",
    "                                 ToTensor()\n",
    "                             ]))\n",
    "\n",
    "test_dataset_2 = LSTCamDataset(hdf5_file=f)\n",
    "\n",
    "test_dataset_3 = ConcatDataset([test_dataset, test_dataset_2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "# Creation of subset train and test\n",
    "random_indices = torch.randperm(len(test_dataset))\n",
    "train_max_index = int(len(test_dataset)*0.9)\n",
    "train_set_sampler = sampler.SubsetRandomSampler(random_indices[0:train_max_index])\n",
    "test_set_sampler = sampler.SubsetRandomSampler(random_indices[train_max_index + 1:])\n",
    "\n",
    "batch_size = 16\n",
    "n_iters = 12000\n",
    "num_epochs = int(n_iters/(len(test_dataset)*0.9/batch_size))\n",
    "print(num_epochs)\n",
    "\n",
    "# iterable subset creation\n",
    "train_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           sampler=train_set_sampler)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          sampler=test_set_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model on GPU\n",
      "Epoch 0 Iteration 100 Training Loss 39427.14497528522 \n",
      "Epoch 0 Iteration 200 Training Loss 5279.98872134317 \n",
      "Epoch 0 Iteration 300 Training Loss 4409.307007414986 \n",
      "Epoch 0 Iteration 400 Training Loss 3302.156277995574 \n",
      "Epoch 0 Iteration 500 Training Loss 5395.072735535494 \n",
      "Epoch 0 Test Loss 6022.972550087563 \n",
      "Epoch 1 Iteration 600 Training Loss 4762.070749461 \n",
      "Epoch 1 Iteration 700 Training Loss 7101.818507311896 \n",
      "Epoch 1 Iteration 800 Training Loss 4396.959261437381 \n",
      "Epoch 1 Iteration 900 Training Loss 8393.554597659046 \n",
      "Epoch 1 Iteration 1000 Training Loss 9868.994740967419 \n",
      "Epoch 1 Iteration 1100 Training Loss 4543.771864011186 \n",
      "Epoch 1 Test Loss 5880.074019820729 \n",
      "Epoch 2 Iteration 1200 Training Loss 3737.728743594087 \n",
      "Epoch 2 Iteration 1300 Training Loss 2610.7091326709315 \n",
      "Epoch 2 Iteration 1400 Training Loss 4131.904023934895 \n",
      "Epoch 2 Iteration 1500 Training Loss 16759.26318040358 \n",
      "Epoch 2 Iteration 1600 Training Loss 4097.826266722402 \n",
      "Epoch 2 Iteration 1700 Training Loss 3356.1692772540528 \n",
      "Epoch 2 Test Loss 11020.167231020227 \n",
      "Epoch 3 Iteration 1800 Training Loss 5078.966130796353 \n",
      "Epoch 3 Iteration 1900 Training Loss 14051.892335016204 \n",
      "Epoch 3 Iteration 2000 Training Loss 4339.861739194954 \n",
      "Epoch 3 Iteration 2100 Training Loss 4386.00542252982 \n",
      "Epoch 3 Iteration 2200 Training Loss 8913.231666336254 \n",
      "Epoch 3 Test Loss 5468.938621246466 \n",
      "Epoch 4 Iteration 2300 Training Loss 3736.5926413391044 \n",
      "Epoch 4 Iteration 2400 Training Loss 6968.663583129099 \n",
      "Epoch 4 Iteration 2500 Training Loss 4184.079606023469 \n",
      "Epoch 4 Iteration 2600 Training Loss 9810.446521462487 \n",
      "Epoch 4 Iteration 2700 Training Loss 3279.817843309179 \n",
      "Epoch 4 Iteration 2800 Training Loss 3736.522223015242 \n",
      "Epoch 4 Test Loss 7710.398955244796 \n",
      "Epoch 5 Iteration 2900 Training Loss 3548.653212146234 \n",
      "Epoch 5 Iteration 3000 Training Loss 5509.054931863247 \n",
      "Epoch 5 Iteration 3100 Training Loss 4336.718741818804 \n",
      "Epoch 5 Iteration 3200 Training Loss 5115.778429534013 \n",
      "Epoch 5 Iteration 3300 Training Loss 4637.349529894266 \n",
      "Epoch 5 Iteration 3400 Training Loss 7715.32346871516 \n",
      "Epoch 5 Test Loss 5872.416114646864 \n",
      "Epoch 6 Iteration 3500 Training Loss 3970.1646247449794 \n",
      "Epoch 6 Iteration 3600 Training Loss 4288.132557888435 \n",
      "Epoch 6 Iteration 3700 Training Loss 3441.0859968385366 \n",
      "Epoch 6 Iteration 3800 Training Loss 5204.459414242108 \n",
      "Epoch 6 Iteration 3900 Training Loss 5795.832957336726 \n",
      "Epoch 6 Test Loss 6197.005053206124 \n",
      "Epoch 7 Iteration 4000 Training Loss 6481.803129659722 \n",
      "Epoch 7 Iteration 4100 Training Loss 4339.358135658247 \n",
      "Epoch 7 Iteration 4200 Training Loss 4914.12761678969 \n",
      "Epoch 7 Iteration 4300 Training Loss 2965.9076824655976 \n",
      "Epoch 7 Iteration 4400 Training Loss 6773.676308185144 \n",
      "Epoch 7 Iteration 4500 Training Loss 6200.605650379364 \n",
      "Epoch 7 Test Loss 5514.274656816527 \n",
      "Epoch 8 Iteration 4600 Training Loss 4800.806561448964 \n",
      "Epoch 8 Iteration 4700 Training Loss 3103.94926022488 \n",
      "Epoch 8 Iteration 4800 Training Loss 6242.194019663314 \n",
      "Epoch 8 Iteration 4900 Training Loss 3672.048825759359 \n",
      "Epoch 8 Iteration 5000 Training Loss 7078.664139362555 \n",
      "Epoch 8 Iteration 5100 Training Loss 4613.766125768054 \n",
      "Epoch 8 Test Loss 8607.198896389657 \n",
      "Epoch 9 Iteration 5200 Training Loss 4027.4190320266357 \n",
      "Epoch 9 Iteration 5300 Training Loss 5353.436638247213 \n",
      "Epoch 9 Iteration 5400 Training Loss 3470.10043553343 \n",
      "Epoch 9 Iteration 5500 Training Loss 4797.86550971817 \n",
      "Epoch 9 Iteration 5600 Training Loss 6282.931937819525 \n",
      "Epoch 9 Iteration 5700 Training Loss 4078.12628080824 \n",
      "Epoch 9 Test Loss 5746.599941476136 \n",
      "Epoch 10 Iteration 5800 Training Loss 4378.131374481651 \n",
      "Epoch 10 Iteration 5900 Training Loss 3225.9831756599815 \n",
      "Epoch 10 Iteration 6000 Training Loss 4513.151817531551 \n",
      "Epoch 10 Iteration 6100 Training Loss 4362.740490174854 \n",
      "Epoch 10 Iteration 6200 Training Loss 4205.71431890379 \n",
      "Epoch 10 Test Loss 7520.729291928378 \n",
      "Epoch 11 Iteration 6300 Training Loss 4806.229344425241 \n",
      "Epoch 11 Iteration 6400 Training Loss 4337.312973841246 \n",
      "Epoch 11 Iteration 6500 Training Loss 6645.116482351546 \n",
      "Epoch 11 Iteration 6600 Training Loss 2897.6228992398046 \n",
      "Epoch 11 Iteration 6700 Training Loss 2916.0115966319167 \n",
      "Epoch 11 Iteration 6800 Training Loss 2699.1928250154233 \n",
      "Epoch 11 Test Loss 5506.6403328889955 \n",
      "Epoch 12 Iteration 6900 Training Loss 3434.2551154564635 \n",
      "Epoch 12 Iteration 7000 Training Loss 4626.756885599307 \n",
      "Epoch 12 Iteration 7100 Training Loss 2765.457134242245 \n",
      "Epoch 12 Iteration 7200 Training Loss 2838.774339115761 \n",
      "Epoch 12 Iteration 7300 Training Loss 4350.524236591569 \n",
      "Epoch 12 Iteration 7400 Training Loss 4690.2047061691255 \n",
      "Epoch 12 Test Loss 5588.816913758486 \n",
      "Epoch 13 Iteration 7500 Training Loss 4158.186767316369 \n",
      "Epoch 13 Iteration 7600 Training Loss 2656.702474179061 \n",
      "Epoch 13 Iteration 7700 Training Loss 4641.9208844770055 \n",
      "Epoch 13 Iteration 7800 Training Loss 2518.8299781050077 \n",
      "Epoch 13 Iteration 7900 Training Loss 6373.927947271731 \n",
      "Epoch 13 Test Loss 6294.9228550652 \n",
      "Epoch 14 Iteration 8000 Training Loss 3892.718748746841 \n",
      "Epoch 14 Iteration 8100 Training Loss 2931.055449506926 \n",
      "Epoch 14 Iteration 8200 Training Loss 3057.329847301466 \n",
      "Epoch 14 Iteration 8300 Training Loss 3883.699688941936 \n",
      "Epoch 14 Iteration 8400 Training Loss 9249.76557736814 \n",
      "Epoch 14 Iteration 8500 Training Loss 2674.908946959678 \n",
      "Epoch 14 Test Loss 5505.151886998299 \n",
      "Epoch 15 Iteration 8600 Training Loss 3517.2031667102815 \n",
      "Epoch 15 Iteration 8700 Training Loss 4182.927479379119 \n",
      "Epoch 15 Iteration 8800 Training Loss 2743.8516950833814 \n",
      "Epoch 15 Iteration 8900 Training Loss 4650.380982731877 \n",
      "Epoch 15 Iteration 9000 Training Loss 3605.751368080741 \n",
      "Epoch 15 Iteration 9100 Training Loss 3027.9057398887944 \n",
      "Epoch 15 Test Loss 6664.156109814862 \n",
      "Epoch 16 Iteration 9200 Training Loss 3074.1634612634043 \n",
      "Epoch 16 Iteration 9300 Training Loss 4384.456486039504 \n",
      "Epoch 16 Iteration 9400 Training Loss 3667.685435865932 \n",
      "Epoch 16 Iteration 9500 Training Loss 4011.0263255404166 \n",
      "Epoch 16 Iteration 9600 Training Loss 3037.9776780740112 \n",
      "Epoch 16 Iteration 9700 Training Loss 3157.7177725420224 \n",
      "Epoch 16 Test Loss 5650.500537383423 \n",
      "Epoch 17 Iteration 9800 Training Loss 3932.217681547363 \n",
      "Epoch 17 Iteration 9900 Training Loss 3518.342044437105 \n",
      "Epoch 17 Iteration 10000 Training Loss 3484.2237671429457 \n",
      "Epoch 17 Iteration 10100 Training Loss 3084.956350301593 \n",
      "Epoch 17 Iteration 10200 Training Loss 2765.964337322216 \n",
      "Epoch 17 Test Loss 6285.530715819514 \n",
      "Epoch 18 Iteration 10300 Training Loss 2832.2618198977443 \n",
      "Epoch 18 Iteration 10400 Training Loss 3407.690656390221 \n",
      "Epoch 18 Iteration 10500 Training Loss 2628.8355999163578 \n",
      "Epoch 18 Iteration 10600 Training Loss 2414.630470794474 \n",
      "Epoch 18 Iteration 10700 Training Loss 2394.8557097944795 \n",
      "Epoch 18 Iteration 10800 Training Loss 3595.0160652307204 \n",
      "Epoch 18 Test Loss 5844.732885445171 \n",
      "Epoch 19 Iteration 10900 Training Loss 2413.4340727514873 \n",
      "Epoch 19 Iteration 11000 Training Loss 2708.391352130673 \n",
      "Epoch 19 Iteration 11100 Training Loss 1934.541007910141 \n",
      "Epoch 19 Iteration 11200 Training Loss 2550.2785870552407 \n",
      "Epoch 19 Iteration 11300 Training Loss 2352.8843156554894 \n",
      "Epoch 19 Iteration 11400 Training Loss 2906.645103910915 \n",
      "Epoch 19 Test Loss 6331.024036406058 \n",
      "Epoch 20 Iteration 11500 Training Loss 2392.697483401282 \n",
      "Epoch 20 Iteration 11600 Training Loss 1686.010904192572 \n",
      "Epoch 20 Iteration 11700 Training Loss 2721.686957387903 \n",
      "Epoch 20 Iteration 11800 Training Loss 2509.9786780021122 \n",
      "Epoch 20 Iteration 11900 Training Loss 3698.5632453757676 \n",
      "Epoch 20 Test Loss 5941.808685307817 \n",
      "Ratio of gpu time :  0.48034677185926355\n"
     ]
    }
   ],
   "source": [
    "model = CNNModelLST()\n",
    "model.double()\n",
    "onGPU = True\n",
    "\n",
    "## Run on GPU ##\n",
    "if torch.cuda.is_available() and onGPU:\n",
    "    print('model on GPU')\n",
    "    model.cuda()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "learning_rate = 0.00005\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "#scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2)\n",
    "loss_epoch = []\n",
    "itera = 0\n",
    "time_1 = time.time()\n",
    "gpu_time = 0\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for i, samples in enumerate(train_loader):\n",
    "\n",
    "        ## Run on GPU ##\n",
    "        if torch.cuda.is_available() and onGPU:\n",
    "            #Load data as variable\n",
    "            images = Variable(samples['image'].cuda())\n",
    "            labels = Variable(samples['labels'].cuda())\n",
    "        else:\n",
    "            images = Variable(samples['image'])\n",
    "            labels = Variable(samples['labels'])\n",
    "        \n",
    "        time_g = time.time()\n",
    "        # clear gradient wrt parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "\n",
    "        # forward pass\n",
    "        outputs = model(images)\n",
    "    \n",
    "        # claculate loss\n",
    "        loss = criterion(outputs, labels[:, 3:5])\n",
    "    \n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "    \n",
    "        gpu_time += (time.time() - time_g)\n",
    "        \n",
    "        itera +=1\n",
    "    \n",
    "        if itera%100==0:    \n",
    "            print('Epoch {} Iteration {} Training Loss {} '.format(epoch, itera, loss.data[0]))\n",
    "            #print(model.state_dict()['conv1.weight'][0])\n",
    "    time_g = time.time()\n",
    "    pos = np.empty((0, 2), np.double)\n",
    "    pos_inferred = np.empty((0, 2), np.double)\n",
    "    for i, samples in enumerate(test_loader):\n",
    "\n",
    "        ## Run on GPU ##\n",
    "        if torch.cuda.is_available() and onGPU:\n",
    "            #Load data as variable\n",
    "            images = Variable(samples['image'].cuda())\n",
    "            labels = Variable(samples['labels'].cuda())\n",
    "        else:\n",
    "            images = Variable(samples['image'])\n",
    "            labels = Variable(samples['labels'])\n",
    "        model.eval()\n",
    "        # forward pass\n",
    "        outputs = model(images)\n",
    "        pos = np.append(pos, labels.data[:, 3:5].cpu().numpy())\n",
    "        pos_inferred = np.append(pos_inferred, outputs.data.cpu().numpy())\n",
    "    \n",
    "    loss_epoch.append(np.mean((pos - pos_inferred)**2))\n",
    "    gpu_time += (time.time() - time_g)\n",
    "    print('Epoch {} Test Loss {} '.format(epoch, loss_epoch[epoch]))\n",
    "    \n",
    "ratio_gpu = gpu_time / (time.time() - time_1)\n",
    "print('Ratio of gpu time : ', ratio_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('conv1.weight', \n",
       "              (0 ,0 ,.,.) = \n",
       "                0.0464 -0.2987  0.9670\n",
       "               -0.4824 -0.9340  0.2873\n",
       "                0.0052 -0.3701 -0.3409\n",
       "              \n",
       "              (1 ,0 ,.,.) = \n",
       "                0.3603 -0.3119 -0.6208\n",
       "                0.2451  1.2015 -0.0618\n",
       "               -0.3185 -0.9229 -1.4444\n",
       "              \n",
       "              (2 ,0 ,.,.) = \n",
       "               -0.5884  0.9962 -0.6980\n",
       "               -0.6335  0.9813 -0.5775\n",
       "               -0.7269  0.3129  0.0307\n",
       "              \n",
       "              (3 ,0 ,.,.) = \n",
       "               -0.4889 -0.5316 -0.5975\n",
       "               -0.0460 -0.0203 -0.8443\n",
       "               -0.2539  1.5032 -0.4175\n",
       "              \n",
       "              (4 ,0 ,.,.) = \n",
       "               -0.6897  0.3641 -0.8150\n",
       "                0.2027  0.1437  0.0313\n",
       "                0.7548 -0.3436  0.2240\n",
       "              \n",
       "              (5 ,0 ,.,.) = \n",
       "                0.3976  0.2780  0.2113\n",
       "                0.5273  0.2684  0.0467\n",
       "                0.3638  0.5271  0.5193\n",
       "              \n",
       "              (6 ,0 ,.,.) = \n",
       "               -2.0351 -0.7982 -0.1742\n",
       "                1.1177  2.1657 -0.0064\n",
       "               -1.1398  0.2237 -0.0150\n",
       "              \n",
       "              (7 ,0 ,.,.) = \n",
       "               -0.1353 -0.3105 -0.4499\n",
       "                0.1641 -0.4079  0.0470\n",
       "               -0.1567 -0.5183 -0.3814\n",
       "              \n",
       "              (8 ,0 ,.,.) = \n",
       "               -1.8612 -0.9167 -0.6797\n",
       "               -0.3529  0.3071  0.3313\n",
       "               -1.5812  0.9360  1.0299\n",
       "              \n",
       "              (9 ,0 ,.,.) = \n",
       "                0.1722  0.5630  1.1098\n",
       "               -0.5013  0.2919  0.4430\n",
       "               -0.3839 -0.5134 -0.7582\n",
       "              \n",
       "              (10,0 ,.,.) = \n",
       "                0.0991  0.2195  0.2693\n",
       "                0.7021  0.3443  0.2975\n",
       "                0.3426  0.4710  0.7324\n",
       "              \n",
       "              (11,0 ,.,.) = \n",
       "               -0.6035 -0.5971 -1.7233\n",
       "                0.9085 -0.0904 -1.0961\n",
       "                1.2716 -0.0087 -1.0612\n",
       "              \n",
       "              (12,0 ,.,.) = \n",
       "               -0.5307 -0.6888 -0.6164\n",
       "               -0.4894 -0.2024 -0.7537\n",
       "               -0.7342 -0.4433 -0.6302\n",
       "              \n",
       "              (13,0 ,.,.) = \n",
       "                0.0212  0.2048  0.2858\n",
       "                0.0680  0.0556  0.1689\n",
       "                0.0921 -0.0418 -0.0812\n",
       "              \n",
       "              (14,0 ,.,.) = \n",
       "               -0.3086  0.9350  1.0302\n",
       "                0.4494  0.6550  1.1962\n",
       "                0.0165  0.3343  0.0499\n",
       "              \n",
       "              (15,0 ,.,.) = \n",
       "               -0.5173 -0.6989  0.2468\n",
       "                0.0628  0.6031  0.3985\n",
       "                0.4519  0.2213  0.1601\n",
       "              [torch.cuda.DoubleTensor of size 16x1x3x3 (GPU 0)]),\n",
       "             ('conv1.bias', \n",
       "              -0.3420\n",
       "              -0.5768\n",
       "               0.3148\n",
       "               0.3521\n",
       "               0.8205\n",
       "              -0.6025\n",
       "               8.0434\n",
       "              -0.4150\n",
       "              -0.9582\n",
       "               0.0473\n",
       "              -0.0745\n",
       "               0.2980\n",
       "               8.0327\n",
       "              -0.2956\n",
       "               0.0624\n",
       "               0.0479\n",
       "              [torch.cuda.DoubleTensor of size 16 (GPU 0)]),\n",
       "             ('batchnorm1.weight', \n",
       "               1.4526\n",
       "               1.5156\n",
       "               1.6549\n",
       "               1.6081\n",
       "               1.1839\n",
       "               1.4276\n",
       "              -0.5325\n",
       "               0.7956\n",
       "               2.0719\n",
       "               1.8198\n",
       "               1.5683\n",
       "               2.3699\n",
       "               2.4202\n",
       "               0.1875\n",
       "               2.4304\n",
       "               1.2896\n",
       "              [torch.cuda.DoubleTensor of size 16 (GPU 0)]),\n",
       "             ('batchnorm1.bias', \n",
       "              -0.0168\n",
       "              -0.2524\n",
       "               0.2425\n",
       "               0.3680\n",
       "               0.6160\n",
       "               0.1226\n",
       "               2.6419\n",
       "              -0.0571\n",
       "              -0.8675\n",
       "               0.6761\n",
       "               0.5309\n",
       "              -0.2783\n",
       "               1.1821\n",
       "               0.0011\n",
       "               0.9895\n",
       "               0.8922\n",
       "              [torch.cuda.DoubleTensor of size 16 (GPU 0)]),\n",
       "             ('batchnorm1.running_mean', \n",
       "                1.5866\n",
       "                2.1490\n",
       "                2.6594\n",
       "                2.7328\n",
       "                2.6571\n",
       "                1.5087\n",
       "               12.2516\n",
       "                0.6185\n",
       "                2.6937\n",
       "                2.2752\n",
       "                2.0525\n",
       "                3.3432\n",
       "                9.0382\n",
       "                0.4710\n",
       "                3.1708\n",
       "                1.7275\n",
       "              [torch.cuda.DoubleTensor of size 16 (GPU 0)]),\n",
       "             ('batchnorm1.running_var', \n",
       "                 7.9673\n",
       "                 8.0691\n",
       "                11.3168\n",
       "                13.9399\n",
       "                 8.1740\n",
       "                73.7279\n",
       "                39.6171\n",
       "                 0.7157\n",
       "                18.9786\n",
       "                32.7906\n",
       "                92.4162\n",
       "                28.4041\n",
       "                 4.7382\n",
       "                 5.4024\n",
       "               172.3169\n",
       "                16.5256\n",
       "              [torch.cuda.DoubleTensor of size 16 (GPU 0)]),\n",
       "             ('conv2.weight', \n",
       "              (0 ,0 ,.,.) = \n",
       "                1.9365e-01  1.1194e-01 -2.6500e-02\n",
       "               -4.5596e-02  4.7065e-02  4.0098e-01\n",
       "                9.4505e-02  3.9640e-02  4.0665e-01\n",
       "              \n",
       "              (0 ,1 ,.,.) = \n",
       "               -1.4913e-01  4.1469e-01 -5.0009e-01\n",
       "               -3.9376e-01 -9.6639e-02 -4.1198e-03\n",
       "               -3.4751e-01 -7.1267e-02  4.3412e-01\n",
       "              \n",
       "              (0 ,2 ,.,.) = \n",
       "               -3.4542e-01  1.5297e-01 -6.7896e-02\n",
       "                1.6708e-01 -6.6419e-02  5.2163e-02\n",
       "                6.0495e-03 -3.4994e-01  8.2679e-02\n",
       "                 ...\n",
       "              \n",
       "              (0 ,13,.,.) = \n",
       "                3.4229e-02 -2.8857e-02 -5.6076e-02\n",
       "                1.0741e-02  1.4735e-01 -9.7219e-02\n",
       "                8.7311e-02  1.4320e-01  1.3651e-01\n",
       "              \n",
       "              (0 ,14,.,.) = \n",
       "               -4.3241e-01  1.8931e-01 -1.8382e-02\n",
       "               -5.0779e-01  1.0907e-01  5.9715e-01\n",
       "                2.6856e-02  5.2685e-01  2.8224e-01\n",
       "              \n",
       "              (0 ,15,.,.) = \n",
       "               -2.3276e-01 -1.0327e-01  5.7855e-02\n",
       "               -1.1105e-01  1.1566e-01  1.9898e-01\n",
       "               -4.2770e-02  1.4800e-01 -2.0666e-01\n",
       "                   ⋮ \n",
       "              \n",
       "              (1 ,0 ,.,.) = \n",
       "               -4.0725e-02  2.1715e-01 -1.5909e-01\n",
       "                1.7571e-01  2.3222e-01 -2.1552e-01\n",
       "               -4.6570e-01  1.4967e-01  7.5506e-02\n",
       "              \n",
       "              (1 ,1 ,.,.) = \n",
       "                1.9736e-01  1.0609e-01 -1.9310e-01\n",
       "                1.0076e-01  1.5529e-01  2.1342e-01\n",
       "               -3.2922e-01 -6.9427e-02  1.5621e-01\n",
       "              \n",
       "              (1 ,2 ,.,.) = \n",
       "                5.3537e-02 -1.5486e-01  3.8280e-01\n",
       "               -1.5256e-01  4.4569e-02  3.1614e-01\n",
       "               -3.2549e-01 -4.5489e-01  1.7447e-01\n",
       "                 ...\n",
       "              \n",
       "              (1 ,13,.,.) = \n",
       "               -2.2043e-02 -6.9850e-02  7.6827e-02\n",
       "                1.2964e-01  9.8325e-03  1.1918e-01\n",
       "                1.8140e-02  3.9691e-02 -1.1394e-01\n",
       "              \n",
       "              (1 ,14,.,.) = \n",
       "               -8.6333e-02 -6.6334e-02  2.3966e-01\n",
       "               -3.7093e-01 -1.5962e-01  2.6991e-03\n",
       "                3.7423e-02  1.2448e-01  3.0273e-01\n",
       "              \n",
       "              (1 ,15,.,.) = \n",
       "               -9.6566e-02  3.0406e-02 -2.7151e-01\n",
       "               -6.6675e-02 -2.1610e-01  1.9529e-01\n",
       "                4.7489e-02  3.5124e-02 -1.0790e-02\n",
       "                   ⋮ \n",
       "              \n",
       "              (2 ,0 ,.,.) = \n",
       "               -7.9066e-02 -6.4119e-02 -2.0726e-01\n",
       "                4.1986e-02  1.3316e-01 -5.6656e-02\n",
       "               -1.9357e-01  7.4406e-02  1.9578e-01\n",
       "              \n",
       "              (2 ,1 ,.,.) = \n",
       "               -1.4189e-01 -1.8103e-01 -6.5965e-03\n",
       "                2.3636e-01 -4.0859e-03  2.2258e-01\n",
       "               -8.6459e-02  2.7836e-01 -2.5949e-01\n",
       "              \n",
       "              (2 ,2 ,.,.) = \n",
       "               -1.3832e-01 -2.1925e-02  3.1601e-02\n",
       "                3.7467e-03 -1.4997e-02  2.9525e-02\n",
       "               -1.2078e-02  3.3794e-01  7.0043e-02\n",
       "                 ...\n",
       "              \n",
       "              (2 ,13,.,.) = \n",
       "               -1.5362e-01 -1.6691e-02 -1.1628e-01\n",
       "                1.1566e-01  3.2754e-02  9.3019e-02\n",
       "                9.1607e-02 -1.0251e-03  9.9312e-03\n",
       "              \n",
       "              (2 ,14,.,.) = \n",
       "               -1.9649e-01 -2.5474e-01 -2.9208e-01\n",
       "               -2.2159e-01 -1.1947e-01 -2.1350e-02\n",
       "               -2.9677e-01  1.3520e-01  2.0354e-01\n",
       "              \n",
       "              (2 ,15,.,.) = \n",
       "               -1.8240e-01 -1.8186e-01 -3.0917e-01\n",
       "               -2.5689e-01 -2.7602e-01  1.1447e-02\n",
       "               -7.9835e-02  1.8303e-02  2.5348e-01\n",
       "              ...   \n",
       "                   ⋮ \n",
       "              \n",
       "              (29,0 ,.,.) = \n",
       "               -1.2187e-01  4.4283e-02 -8.4377e-02\n",
       "               -8.1497e-02 -2.1880e-01  6.2161e-02\n",
       "                1.4651e-01  1.0038e-03 -1.4379e-01\n",
       "              \n",
       "              (29,1 ,.,.) = \n",
       "                2.0778e-01  3.8706e-01  2.9973e-01\n",
       "               -2.1389e-01  1.4205e-01  4.0011e-01\n",
       "                1.7337e-02  2.2605e-01 -1.0351e-01\n",
       "              \n",
       "              (29,2 ,.,.) = \n",
       "               -1.4781e-01 -6.2622e-02 -1.0810e-01\n",
       "               -8.0237e-02 -2.3336e-01 -2.4538e-01\n",
       "               -8.7948e-02 -2.1730e-02 -7.8872e-02\n",
       "                 ...\n",
       "              \n",
       "              (29,13,.,.) = \n",
       "                8.0475e-02 -4.3609e-02  6.0580e-02\n",
       "               -7.9244e-03  6.0728e-02 -9.4164e-02\n",
       "                1.2121e-01  7.3744e-03 -4.1605e-02\n",
       "              \n",
       "              (29,14,.,.) = \n",
       "               -8.9068e-01 -6.6705e-01 -1.8855e-01\n",
       "               -4.0397e-01 -4.2035e-01 -2.9533e-01\n",
       "               -3.0646e-01 -3.5421e-01 -3.8365e-01\n",
       "              \n",
       "              (29,15,.,.) = \n",
       "               -3.5755e-01 -4.3645e-01 -3.3427e-01\n",
       "               -1.6087e-01 -3.3312e-01 -3.6675e-01\n",
       "               -2.7340e-01 -4.0306e-01 -1.2930e-01\n",
       "                   ⋮ \n",
       "              \n",
       "              (30,0 ,.,.) = \n",
       "                3.2446e-02 -1.3700e-01 -1.0447e-01\n",
       "               -1.6870e-01 -9.3645e-03 -1.4125e-01\n",
       "               -9.5297e-02 -8.2729e-02 -1.3024e-01\n",
       "              \n",
       "              (30,1 ,.,.) = \n",
       "                2.2897e-02 -2.1007e-02 -4.7191e-02\n",
       "                4.0820e-01  8.9358e-02 -1.4716e-01\n",
       "                1.2341e-03  2.3508e-01 -1.0346e-01\n",
       "              \n",
       "              (30,2 ,.,.) = \n",
       "               -9.5310e-03  4.5640e-03 -1.0687e-01\n",
       "                2.3993e-01 -9.1200e-02 -8.6706e-02\n",
       "               -2.4026e-01  2.5429e-01 -2.5823e-01\n",
       "                 ...\n",
       "              \n",
       "              (30,13,.,.) = \n",
       "               -2.8958e-02  1.1491e-01  8.1378e-02\n",
       "                1.0638e-01  7.3075e-02 -3.8277e-02\n",
       "               -1.2302e-01  9.8170e-02  1.0214e-01\n",
       "              \n",
       "              (30,14,.,.) = \n",
       "               -6.3299e-02 -2.8071e-01 -2.4784e-01\n",
       "               -1.1309e-01 -2.1071e-02 -2.8802e-01\n",
       "               -2.0723e-01  8.8014e-03  2.0031e-01\n",
       "              \n",
       "              (30,15,.,.) = \n",
       "               -5.0150e-02 -2.1137e-01 -6.6680e-02\n",
       "               -3.1099e-01 -6.6596e-02 -2.3565e-01\n",
       "               -1.1402e-03 -4.2674e-02 -3.6194e-02\n",
       "                   ⋮ \n",
       "              \n",
       "              (31,0 ,.,.) = \n",
       "                6.1773e-02  5.1686e-02 -1.1097e-01\n",
       "               -4.7660e-01  9.6806e-03  3.4915e-01\n",
       "                3.0982e-01 -5.3450e-02  3.8970e-01\n",
       "              \n",
       "              (31,1 ,.,.) = \n",
       "               -2.4656e-01  1.4762e-01 -5.4735e-02\n",
       "               -1.9295e-01 -1.8110e-01  7.0089e-02\n",
       "               -4.6994e-01  2.3673e-01  1.5981e-01\n",
       "              \n",
       "              (31,2 ,.,.) = \n",
       "                3.1642e-01 -3.2819e-01  2.4065e-01\n",
       "                1.1223e-01  1.6715e-01 -2.3624e-01\n",
       "               -3.5127e-01 -1.5781e-01  3.7416e-01\n",
       "                 ...\n",
       "              \n",
       "              (31,13,.,.) = \n",
       "               -1.0347e-01 -7.2866e-02  7.0240e-02\n",
       "               -1.3073e-01 -1.7388e-02  2.4018e-02\n",
       "                2.4052e-02 -1.5077e-01 -6.2585e-03\n",
       "              \n",
       "              (31,14,.,.) = \n",
       "               -9.5592e-02  9.6658e-02  2.9606e-01\n",
       "               -5.6158e-01 -2.5542e-01  2.9945e-01\n",
       "               -3.4556e-01 -2.1029e-01  8.2367e-01\n",
       "              \n",
       "              (31,15,.,.) = \n",
       "               -8.7708e-02  1.3524e-01  6.7855e-02\n",
       "               -8.9844e-02 -1.3925e-01  2.7005e-01\n",
       "               -1.7929e-01 -6.8990e-02 -1.4209e-01\n",
       "              [torch.cuda.DoubleTensor of size 32x16x3x3 (GPU 0)]),\n",
       "             ('conv2.bias', \n",
       "              -0.1821\n",
       "               0.0378\n",
       "              -0.4012\n",
       "               0.0604\n",
       "              -0.2940\n",
       "              -0.5714\n",
       "               0.0291\n",
       "              -0.0744\n",
       "              -0.2466\n",
       "              -0.9655\n",
       "               0.0610\n",
       "              -0.2337\n",
       "              -0.1764\n",
       "              -0.2357\n",
       "               0.0640\n",
       "              -0.2090\n",
       "              -0.0588\n",
       "              -0.1743\n",
       "               0.1027\n",
       "              -0.1414\n",
       "              -0.3099\n",
       "              -0.1067\n",
       "              -0.4730\n",
       "              -0.1675\n",
       "              -0.5182\n",
       "               0.1536\n",
       "              -0.4108\n",
       "               0.1833\n",
       "              -0.0175\n",
       "              -0.6366\n",
       "              -0.2160\n",
       "               0.1213\n",
       "              [torch.cuda.DoubleTensor of size 32 (GPU 0)]),\n",
       "             ('batchnorm2.weight', \n",
       "               1.9899\n",
       "               1.2674\n",
       "               1.5258\n",
       "               0.6765\n",
       "               1.6477\n",
       "               1.7398\n",
       "               1.2565\n",
       "               1.6461\n",
       "               0.1815\n",
       "               2.9369\n",
       "               0.9723\n",
       "               1.3248\n",
       "               1.1619\n",
       "               0.3891\n",
       "               0.4867\n",
       "               2.2638\n",
       "               0.0430\n",
       "               1.2528\n",
       "               1.4128\n",
       "               1.3059\n",
       "               1.1886\n",
       "               0.3338\n",
       "               1.9557\n",
       "               1.4004\n",
       "               1.1560\n",
       "               0.9205\n",
       "               2.2333\n",
       "              -0.2492\n",
       "               1.0363\n",
       "               1.1568\n",
       "               1.5324\n",
       "               1.7787\n",
       "              [torch.cuda.DoubleTensor of size 32 (GPU 0)]),\n",
       "             ('batchnorm2.bias', \n",
       "               0.1845\n",
       "              -0.1017\n",
       "               0.5178\n",
       "              -0.0558\n",
       "               0.0428\n",
       "              -0.4617\n",
       "              -0.1047\n",
       "              -0.0732\n",
       "              -0.1453\n",
       "               0.6927\n",
       "               0.0956\n",
       "               0.0495\n",
       "               0.1635\n",
       "              -0.0745\n",
       "              -0.0554\n",
       "              -0.0992\n",
       "               0.0421\n",
       "               0.0023\n",
       "               0.1779\n",
       "               0.0695\n",
       "               0.4826\n",
       "              -0.1773\n",
       "               0.2036\n",
       "              -0.1093\n",
       "              -0.3903\n",
       "               0.4077\n",
       "               0.0463\n",
       "              -0.1212\n",
       "               0.0732\n",
       "              -0.4050\n",
       "               0.0285\n",
       "               0.0650\n",
       "              [torch.cuda.DoubleTensor of size 32 (GPU 0)]),\n",
       "             ('batchnorm2.running_mean', \n",
       "               1.0567e+01\n",
       "               5.6715e+00\n",
       "               5.8387e-01\n",
       "               1.2720e+00\n",
       "               8.0485e-01\n",
       "               3.2989e+00\n",
       "               8.7668e+00\n",
       "               4.8963e+00\n",
       "               1.0927e+00\n",
       "               9.6810e-01\n",
       "               4.4069e+00\n",
       "               4.5580e-01\n",
       "               2.1735e-01\n",
       "               1.0515e-04\n",
       "               3.0454e+00\n",
       "               6.0914e+00\n",
       "               5.7003e-02\n",
       "               1.0806e+00\n",
       "               9.8146e+00\n",
       "               3.8688e+00\n",
       "               8.0693e-02\n",
       "               6.0194e+00\n",
       "               9.4799e-01\n",
       "               4.7521e+00\n",
       "               9.0710e-39\n",
       "               1.3078e+01\n",
       "               8.4605e+00\n",
       "               9.2499e+00\n",
       "               2.0705e+00\n",
       "               1.5992e-06\n",
       "               3.3309e-01\n",
       "               1.0756e+01\n",
       "              [torch.cuda.DoubleTensor of size 32 (GPU 0)]),\n",
       "             ('batchnorm2.running_var', \n",
       "               1.8120e+02\n",
       "               3.8314e+01\n",
       "               4.4580e+01\n",
       "               6.4655e+00\n",
       "               3.5957e+01\n",
       "               8.7767e+01\n",
       "               2.5831e+01\n",
       "               1.4310e+02\n",
       "               4.0942e+00\n",
       "               1.0583e+02\n",
       "               1.4626e+01\n",
       "               1.0291e+01\n",
       "               5.0850e+00\n",
       "               1.1514e-03\n",
       "               2.5003e+00\n",
       "               2.1642e+02\n",
       "               6.0687e-01\n",
       "               1.6961e+01\n",
       "               5.6779e+01\n",
       "               4.0709e+01\n",
       "               3.5977e+00\n",
       "               9.0292e+01\n",
       "               5.4244e+01\n",
       "               6.1029e+01\n",
       "               6.2523e-39\n",
       "               2.2669e+01\n",
       "               2.5574e+02\n",
       "               5.4163e+01\n",
       "               1.1682e+01\n",
       "               1.6314e-06\n",
       "               1.1506e+01\n",
       "               1.2622e+02\n",
       "              [torch.cuda.DoubleTensor of size 32 (GPU 0)]),\n",
       "             ('conv3.weight', \n",
       "              (0 ,0 ,.,.) = \n",
       "               -2.1112e-01 -1.4440e-02 -1.3407e-01\n",
       "               -2.1207e-01  2.1923e-01  4.3245e-02\n",
       "               -1.3651e-02  2.3852e-02 -1.4150e-01\n",
       "              \n",
       "              (0 ,1 ,.,.) = \n",
       "                5.8572e-03  1.6337e-02 -1.7136e-01\n",
       "                1.1366e-02 -8.4973e-02  1.2394e-01\n",
       "                2.2804e-01 -4.2852e-01  1.7962e-03\n",
       "              \n",
       "              (0 ,2 ,.,.) = \n",
       "               -3.2802e-03 -3.1005e-02 -2.3434e-01\n",
       "               -3.7159e-02 -1.8974e-01  1.3254e-01\n",
       "                2.0111e-02 -8.5894e-02 -9.4608e-02\n",
       "                 ...\n",
       "              \n",
       "              (0 ,29,.,.) = \n",
       "               -4.2619e-02 -3.7080e-02 -1.2685e-02\n",
       "               -1.4491e-02 -1.4112e-01  8.9157e-02\n",
       "               -1.2926e-01 -4.8936e-02 -2.4714e-02\n",
       "              \n",
       "              (0 ,30,.,.) = \n",
       "                1.0803e-01 -3.3349e-02 -1.0458e-02\n",
       "               -1.4943e-01 -1.5317e-01 -4.8079e-02\n",
       "                2.5987e-04 -2.9825e-02 -2.2416e-02\n",
       "              \n",
       "              (0 ,31,.,.) = \n",
       "               -3.4953e-02 -3.8949e-02 -1.0201e-01\n",
       "               -8.2300e-03  3.0325e-01 -1.5105e-01\n",
       "                1.7589e-01 -1.3469e-01  3.8574e-01\n",
       "                   ⋮ \n",
       "              \n",
       "              (1 ,0 ,.,.) = \n",
       "               -4.5106e-01  2.5411e-01 -7.4796e-02\n",
       "               -2.8894e-01 -4.4127e-02 -7.9511e-02\n",
       "               -1.8844e-01 -3.8670e-01 -9.1867e-02\n",
       "              \n",
       "              (1 ,1 ,.,.) = \n",
       "               -2.3043e-01 -1.2603e-01  7.0291e-02\n",
       "               -3.1627e-01 -3.6529e-02 -2.9117e-01\n",
       "               -4.1552e-01 -1.3283e-01  1.2577e-01\n",
       "              \n",
       "              (1 ,2 ,.,.) = \n",
       "               -6.9160e-02  6.0649e-02  7.3557e-05\n",
       "                5.8091e-02  1.4859e-01 -9.3739e-03\n",
       "               -2.2706e-01 -2.7251e-01 -4.8861e-01\n",
       "                 ...\n",
       "              \n",
       "              (1 ,29,.,.) = \n",
       "               -1.5283e-01 -1.2226e-01 -1.8362e-01\n",
       "               -1.9222e-01 -3.3009e-01 -2.3470e-01\n",
       "               -1.9293e-01 -5.1826e-02 -6.4249e-02\n",
       "              \n",
       "              (1 ,30,.,.) = \n",
       "               -4.8106e-01 -2.3067e-02 -1.8252e-01\n",
       "               -1.4032e-01 -4.8956e-02 -1.3067e-01\n",
       "               -1.0034e-01 -2.9583e-01 -3.5735e-01\n",
       "              \n",
       "              (1 ,31,.,.) = \n",
       "                4.8072e-01 -1.2184e-01 -5.2605e-01\n",
       "               -2.8688e-01  3.0272e-01 -1.3454e-02\n",
       "               -2.5246e-01 -5.6953e-01 -4.3385e-01\n",
       "                   ⋮ \n",
       "              \n",
       "              (2 ,0 ,.,.) = \n",
       "               -5.5149e-02 -1.5624e-01  2.6910e-01\n",
       "               -1.9248e-01 -2.1503e-01  2.6947e-01\n",
       "               -4.0490e-02 -2.5955e-02 -9.3572e-02\n",
       "              \n",
       "              (2 ,1 ,.,.) = \n",
       "               -2.0282e-01 -2.8390e-01 -9.6238e-04\n",
       "               -4.7166e-02  2.5874e-02  2.1836e-01\n",
       "                1.3191e-01  1.9654e-01  1.9498e-02\n",
       "              \n",
       "              (2 ,2 ,.,.) = \n",
       "                3.0504e-02 -2.6421e-01 -4.2913e-01\n",
       "                2.2801e-02 -1.9006e-02 -1.9830e-01\n",
       "               -2.0854e-02 -1.4058e-01 -1.6527e-01\n",
       "                 ...\n",
       "              \n",
       "              (2 ,29,.,.) = \n",
       "                1.7493e-01  1.7943e-01  3.7527e-02\n",
       "               -8.1259e-05 -4.0185e-02  4.8778e-02\n",
       "               -6.8790e-03 -8.6017e-02 -3.1858e-02\n",
       "              \n",
       "              (2 ,30,.,.) = \n",
       "               -1.0266e-01 -1.0780e-01  1.6018e-02\n",
       "               -1.3225e-01 -5.1738e-02 -2.5780e-01\n",
       "               -6.0580e-02 -5.9083e-02  8.1775e-02\n",
       "              \n",
       "              (2 ,31,.,.) = \n",
       "               -1.6818e-01 -3.3412e-01 -2.5172e-01\n",
       "               -1.4683e-01 -9.8555e-04  1.4284e-01\n",
       "               -1.2446e-01 -2.9541e-01  1.4521e-01\n",
       "              ...   \n",
       "                   ⋮ \n",
       "              \n",
       "              (61,0 ,.,.) = \n",
       "               -1.2507e-01 -1.3140e-01  2.8282e-01\n",
       "               -2.7479e-01 -2.0958e-01 -2.0286e-01\n",
       "                3.6591e-01 -3.0937e-01 -2.1493e-01\n",
       "              \n",
       "              (61,1 ,.,.) = \n",
       "                3.3553e-01  5.3083e-02 -8.1989e-02\n",
       "               -1.3431e-01  5.6559e-02 -1.5171e-01\n",
       "                3.5827e-01  2.7494e-02 -3.3990e-01\n",
       "              \n",
       "              (61,2 ,.,.) = \n",
       "               -3.0131e-01 -8.9239e-02 -1.6027e-01\n",
       "               -2.1220e-01 -1.2425e-01 -1.4556e-01\n",
       "                1.8605e-01 -2.7540e-01 -3.6371e-02\n",
       "                 ...\n",
       "              \n",
       "              (61,29,.,.) = \n",
       "                1.0087e-01 -9.0397e-02  1.3328e-01\n",
       "               -6.8740e-04 -9.4076e-02 -4.9370e-02\n",
       "                1.5264e-02 -1.1608e-01  4.9781e-02\n",
       "              \n",
       "              (61,30,.,.) = \n",
       "                3.4169e-01 -3.1995e-04  2.8671e-01\n",
       "               -2.4122e-01 -6.3882e-02 -6.1610e-02\n",
       "               -2.4319e-01 -1.1021e-01 -7.5273e-03\n",
       "              \n",
       "              (61,31,.,.) = \n",
       "               -6.2439e-03  8.5025e-02  1.4424e-01\n",
       "                1.1660e-01 -1.3618e-01 -2.1102e-01\n",
       "                1.5953e-01 -1.0947e-01 -2.3697e-02\n",
       "                   ⋮ \n",
       "              \n",
       "              (62,0 ,.,.) = \n",
       "               -2.7136e-01 -2.1178e-02  5.6652e-02\n",
       "               -1.3895e-01 -3.8734e-01 -2.2884e-01\n",
       "               -7.3317e-02 -3.0973e-01  2.7247e-01\n",
       "              \n",
       "              (62,1 ,.,.) = \n",
       "                9.1006e-02 -2.0540e-01  1.9018e-01\n",
       "               -7.4299e-02 -5.9444e-02 -2.6612e-01\n",
       "                1.3662e-01  1.3214e-01  2.8052e-01\n",
       "              \n",
       "              (62,2 ,.,.) = \n",
       "               -3.3298e-01 -9.7790e-02 -8.6679e-03\n",
       "                1.8929e-01 -1.8926e-01 -3.9946e-03\n",
       "               -8.8905e-02 -1.2745e-01  2.6227e-02\n",
       "                 ...\n",
       "              \n",
       "              (62,29,.,.) = \n",
       "               -1.1701e-01  1.3847e-01  1.0530e-01\n",
       "               -2.6955e-02 -4.2190e-02  4.0663e-02\n",
       "                1.5929e-01  9.9563e-02  1.9152e-02\n",
       "              \n",
       "              (62,30,.,.) = \n",
       "               -2.6017e-01 -8.4047e-02 -2.6464e-02\n",
       "                4.7813e-02  7.5865e-02 -8.7346e-02\n",
       "               -3.3532e-01  6.3711e-02  3.8721e-01\n",
       "              \n",
       "              (62,31,.,.) = \n",
       "                5.9560e-02 -2.1341e-01  2.2617e-01\n",
       "               -2.6105e-01 -1.3092e-01 -5.3405e-01\n",
       "                1.2279e-01 -1.3878e-01  1.8988e-02\n",
       "                   ⋮ \n",
       "              \n",
       "              (63,0 ,.,.) = \n",
       "               -1.6904e-01  7.2981e-02 -1.2033e-01\n",
       "               -2.8389e-02  1.1025e-01 -1.5268e-01\n",
       "                1.6542e-01 -1.6033e-01 -1.9097e-01\n",
       "              \n",
       "              (63,1 ,.,.) = \n",
       "               -1.3139e-01 -2.5423e-03  1.3436e-01\n",
       "               -1.6965e-01  8.9091e-02  4.3024e-02\n",
       "               -1.9166e-02  5.7143e-03 -5.9951e-03\n",
       "              \n",
       "              (63,2 ,.,.) = \n",
       "               -2.4520e-02  1.4515e-01 -5.1173e-02\n",
       "               -1.1058e-01  3.3004e-02 -1.7058e-01\n",
       "                1.5964e-01 -1.4349e-01  4.3318e-02\n",
       "                 ...\n",
       "              \n",
       "              (63,29,.,.) = \n",
       "                1.6558e-01 -8.3179e-02  6.4731e-02\n",
       "                1.3140e-02  8.1827e-02  5.3393e-02\n",
       "                7.4470e-02  4.9442e-02 -8.3066e-02\n",
       "              \n",
       "              (63,30,.,.) = \n",
       "                1.3662e-01  9.8730e-02  4.1895e-03\n",
       "                8.2388e-02 -2.4165e-02 -4.4924e-02\n",
       "                1.0395e-01  3.9323e-02 -1.0117e-01\n",
       "              \n",
       "              (63,31,.,.) = \n",
       "               -7.5234e-02 -1.3954e-01 -7.9718e-03\n",
       "               -4.8825e-02  2.6133e-02 -1.3871e-01\n",
       "               -1.9613e-01  3.6331e-02 -1.0531e-01\n",
       "              [torch.cuda.DoubleTensor of size 64x32x3x3 (GPU 0)]),\n",
       "             ('conv3.bias', \n",
       "              -0.0297\n",
       "               0.4575\n",
       "              -0.0430\n",
       "              -0.0561\n",
       "               0.0240\n",
       "               0.0630\n",
       "               0.0809\n",
       "               0.0250\n",
       "              -0.0980\n",
       "              -0.0603\n",
       "               0.0537\n",
       "              -0.1094\n",
       "              -0.1038\n",
       "               0.1048\n",
       "               0.0148\n",
       "              -0.2931\n",
       "               0.0302\n",
       "              -0.0534\n",
       "               0.1839\n",
       "              -0.0075\n",
       "              -0.2944\n",
       "              -0.0554\n",
       "               0.0569\n",
       "              -0.1509\n",
       "              -0.1289\n",
       "              -0.0502\n",
       "               0.0263\n",
       "              -0.0152\n",
       "              -0.1550\n",
       "              -0.0755\n",
       "               0.0633\n",
       "              -0.0290\n",
       "              -0.0895\n",
       "              -0.0199\n",
       "               0.0613\n",
       "               0.3522\n",
       "               0.0156\n",
       "              -0.3772\n",
       "              -0.1219\n",
       "              -0.0216\n",
       "              -0.0232\n",
       "              -0.0059\n",
       "              -0.0399\n",
       "               0.0586\n",
       "               0.1929\n",
       "              -0.1414\n",
       "              -0.0773\n",
       "               0.0734\n",
       "              -0.0776\n",
       "               0.1256\n",
       "               0.0451\n",
       "              -0.0197\n",
       "              -0.0051\n",
       "               0.0339\n",
       "               0.0040\n",
       "               0.0673\n",
       "              -0.1450\n",
       "              -0.0191\n",
       "              -0.0158\n",
       "              -0.0060\n",
       "               0.3561\n",
       "              -0.0105\n",
       "               0.0334\n",
       "               0.0007\n",
       "              [torch.cuda.DoubleTensor of size 64 (GPU 0)]),\n",
       "             ('batchnorm3.weight', \n",
       "               1.1179\n",
       "               1.1858\n",
       "               1.1025\n",
       "               0.8623\n",
       "               0.3491\n",
       "               1.0032\n",
       "               1.4408\n",
       "               0.4325\n",
       "               0.9548\n",
       "               0.9789\n",
       "               1.1352\n",
       "               1.1944\n",
       "               0.8488\n",
       "               1.4405\n",
       "               1.0527\n",
       "               1.2235\n",
       "               0.7942\n",
       "               0.6078\n",
       "               1.2417\n",
       "               0.9021\n",
       "               0.4911\n",
       "               0.7136\n",
       "               1.1354\n",
       "               0.9869\n",
       "               0.5802\n",
       "               1.1290\n",
       "               0.5819\n",
       "               1.0375\n",
       "               0.8317\n",
       "               1.0763\n",
       "               1.5091\n",
       "               1.0127\n",
       "               1.2422\n",
       "               0.3374\n",
       "               0.8238\n",
       "               1.4612\n",
       "               0.9409\n",
       "               0.8007\n",
       "               0.8524\n",
       "               1.0869\n",
       "               1.0658\n",
       "               0.9087\n",
       "               0.5539\n",
       "               0.7354\n",
       "               1.1309\n",
       "               0.9731\n",
       "               0.9303\n",
       "               0.9405\n",
       "               0.9166\n",
       "               1.2437\n",
       "               0.7902\n",
       "               0.4227\n",
       "               0.5883\n",
       "               1.0719\n",
       "               1.3046\n",
       "               0.7271\n",
       "               0.9275\n",
       "               1.0097\n",
       "               1.1176\n",
       "               0.2714\n",
       "               1.2526\n",
       "               1.1792\n",
       "               1.5364\n",
       "               0.7767\n",
       "              [torch.cuda.DoubleTensor of size 64 (GPU 0)]),\n",
       "             ('batchnorm3.bias', \n",
       "               0.1885\n",
       "               0.2299\n",
       "              -0.1089\n",
       "              -0.3795\n",
       "               0.1284\n",
       "               0.9192\n",
       "               0.4424\n",
       "               0.5570\n",
       "              -0.0839\n",
       "               0.1012\n",
       "               0.0975\n",
       "               0.4716\n",
       "               0.3483\n",
       "               0.3874\n",
       "               0.2411\n",
       "              -0.0265\n",
       "               0.1324\n",
       "               0.3348\n",
       "               0.4718\n",
       "              -0.1605\n",
       "              -0.1334\n",
       "               0.1972\n",
       "              -0.0234\n",
       "               0.0973\n",
       "               0.6900\n",
       "               0.3930\n",
       "               0.0747\n",
       "              -0.0096\n",
       "               0.3180\n",
       "               0.2733\n",
       "               0.3639\n",
       "              -0.0924\n",
       "               0.0710\n",
       "               0.0810\n",
       "              -0.0454\n",
       "              -0.1868\n",
       "               0.0918\n",
       "               1.1306\n",
       "               0.3765\n",
       "              -0.1182\n",
       "               0.6295\n",
       "               0.4036\n",
       "              -0.0088\n",
       "               0.4122\n",
       "              -0.1354\n",
       "               0.3192\n",
       "               0.0581\n",
       "               0.5641\n",
       "              -0.1720\n",
       "               0.0846\n",
       "               0.0594\n",
       "               0.4978\n",
       "               0.0478\n",
       "              -0.1531\n",
       "               0.1565\n",
       "               0.2447\n",
       "               0.4319\n",
       "               0.3614\n",
       "               0.2239\n",
       "               0.0058\n",
       "               0.1542\n",
       "               0.4799\n",
       "               0.0394\n",
       "               0.1840\n",
       "              [torch.cuda.DoubleTensor of size 64 (GPU 0)]),\n",
       "             ('batchnorm3.running_mean', \n",
       "               1.9419\n",
       "               7.3968\n",
       "               1.6900\n",
       "               1.9265\n",
       "               0.9638\n",
       "               2.9096\n",
       "               4.3612\n",
       "               1.3950\n",
       "               1.2754\n",
       "               5.0392\n",
       "               3.4473\n",
       "               1.8461\n",
       "               1.1871\n",
       "               3.3387\n",
       "               2.5705\n",
       "               2.3820\n",
       "               0.8967\n",
       "               1.5571\n",
       "               4.3970\n",
       "               0.7702\n",
       "               0.0329\n",
       "               0.9451\n",
       "               2.0005\n",
       "               0.9624\n",
       "               0.4403\n",
       "               1.6424\n",
       "               0.6308\n",
       "               2.9635\n",
       "               0.4408\n",
       "               2.1253\n",
       "               3.5444\n",
       "               1.2751\n",
       "               3.1417\n",
       "               0.7424\n",
       "               1.6003\n",
       "               9.3973\n",
       "               1.8271\n",
       "               1.0899\n",
       "               1.3018\n",
       "               2.2885\n",
       "               1.1761\n",
       "               1.0299\n",
       "               1.0170\n",
       "               1.7371\n",
       "               5.9622\n",
       "               2.8105\n",
       "               1.2002\n",
       "               2.8775\n",
       "               2.6010\n",
       "               4.4428\n",
       "               2.1319\n",
       "               0.7863\n",
       "               1.2278\n",
       "               5.5992\n",
       "               3.0795\n",
       "               0.4116\n",
       "               0.7869\n",
       "               2.2668\n",
       "               2.4777\n",
       "               1.4114\n",
       "               8.5541\n",
       "               2.2429\n",
       "               3.1261\n",
       "               0.9811\n",
       "              [torch.cuda.DoubleTensor of size 64 (GPU 0)]),\n",
       "             ('batchnorm3.running_var', \n",
       "                13.1594\n",
       "                10.4653\n",
       "                 3.0131\n",
       "                 4.0607\n",
       "                 0.8128\n",
       "                 8.6629\n",
       "                15.5866\n",
       "                 4.1950\n",
       "                 1.8408\n",
       "                11.1356\n",
       "                 4.4440\n",
       "                19.7157\n",
       "                 2.5606\n",
       "                15.2169\n",
       "                 5.7461\n",
       "                 7.3006\n",
       "                 3.2721\n",
       "                 3.0208\n",
       "                 7.9441\n",
       "                10.6265\n",
       "                 0.0325\n",
       "                13.1193\n",
       "                20.2448\n",
       "                 1.2588\n",
       "                 1.8649\n",
       "                12.6082\n",
       "                 2.4477\n",
       "                 5.9342\n",
       "                 3.2941\n",
       "                 5.4419\n",
       "                23.3731\n",
       "                 4.6768\n",
       "                 6.4087\n",
       "                 4.6425\n",
       "                 1.1592\n",
       "                18.4461\n",
       "                29.9003\n",
       "                17.9728\n",
       "                 1.5769\n",
       "                11.1846\n",
       "                 7.6338\n",
       "                 5.2524\n",
       "                 2.0735\n",
       "                 4.9414\n",
       "                 8.3307\n",
       "                 3.8063\n",
       "                 1.2629\n",
       "                11.8175\n",
       "                 4.5423\n",
       "                 7.8393\n",
       "                 3.6751\n",
       "                 4.7332\n",
       "                10.4510\n",
       "               274.7138\n",
       "                 5.3351\n",
       "                 2.9180\n",
       "                 4.2335\n",
       "                 3.3622\n",
       "                 5.8721\n",
       "                 9.0043\n",
       "                13.7641\n",
       "                 5.5557\n",
       "                22.7783\n",
       "                 1.7646\n",
       "              [torch.cuda.DoubleTensor of size 64 (GPU 0)]),\n",
       "             ('conv4.weight', \n",
       "              ( 0 , 0 ,.,.) = \n",
       "               -2.1684e-01  5.1074e-02 -1.3201e-01\n",
       "                3.1151e-02 -1.1284e-01 -3.3285e-02\n",
       "                8.3496e-03  8.7893e-02 -8.6961e-02\n",
       "              \n",
       "              ( 0 , 1 ,.,.) = \n",
       "               -1.4788e-01 -5.2043e-02  7.6721e-02\n",
       "               -1.4564e-01 -5.7800e-01  4.6032e-03\n",
       "               -2.3237e-01 -6.1077e-02  2.3430e-01\n",
       "              \n",
       "              ( 0 , 2 ,.,.) = \n",
       "                2.1455e-01 -3.9730e-02  7.6216e-02\n",
       "               -3.2334e-02 -2.0096e-01 -6.5235e-02\n",
       "                1.0889e-01  1.3969e-01 -4.5619e-02\n",
       "                  ... \n",
       "              \n",
       "              ( 0 ,61 ,.,.) = \n",
       "               -2.5439e-02 -9.4094e-02  1.6948e-02\n",
       "               -1.3001e-01 -2.5928e-01  3.8161e-02\n",
       "               -1.0290e-01 -2.8646e-01 -1.3750e-02\n",
       "              \n",
       "              ( 0 ,62 ,.,.) = \n",
       "               -2.4788e-01  1.0359e-01  1.3185e-01\n",
       "               -8.4199e-02  2.5707e-01  1.1087e-01\n",
       "               -2.3550e-02 -4.0720e-02 -1.9308e-01\n",
       "              \n",
       "              ( 0 ,63 ,.,.) = \n",
       "               -8.8086e-02  3.1968e-02 -1.1831e-01\n",
       "               -1.1172e-02  8.6254e-02 -5.5435e-02\n",
       "               -1.0640e-01 -1.6932e-01 -6.2159e-02\n",
       "                    ⋮  \n",
       "              \n",
       "              ( 1 , 0 ,.,.) = \n",
       "               -1.4263e-01 -1.3981e-01 -1.4810e-01\n",
       "               -3.7901e-03 -7.0470e-02  1.8940e-01\n",
       "               -2.4358e-02 -9.8869e-02 -1.7025e-01\n",
       "              \n",
       "              ( 1 , 1 ,.,.) = \n",
       "                4.6104e-02 -1.4390e-01 -2.1088e-01\n",
       "                1.3229e-01 -1.3735e-01 -4.2988e-01\n",
       "                3.6101e-02 -5.2207e-02  2.2877e-01\n",
       "              \n",
       "              ( 1 , 2 ,.,.) = \n",
       "               -1.6985e-01 -4.0044e-02 -9.9292e-02\n",
       "               -1.9234e-01 -1.0364e-01  4.3289e-02\n",
       "               -7.4804e-02 -2.5463e-01 -5.4211e-02\n",
       "                  ... \n",
       "              \n",
       "              ( 1 ,61 ,.,.) = \n",
       "                6.8176e-02 -8.1071e-02 -1.8365e-02\n",
       "                3.0404e-02  1.4168e-01  1.2729e-02\n",
       "               -5.6670e-02 -1.2996e-01 -9.5194e-02\n",
       "              \n",
       "              ( 1 ,62 ,.,.) = \n",
       "               -9.8391e-02  4.2992e-02  1.0297e-01\n",
       "               -7.9537e-02  8.8067e-02  8.0809e-02\n",
       "                3.4458e-02 -3.8497e-02 -1.2572e-01\n",
       "              \n",
       "              ( 1 ,63 ,.,.) = \n",
       "               -1.2947e-01 -4.8695e-02 -1.3634e-02\n",
       "               -1.4273e-01 -8.1158e-02  4.6367e-02\n",
       "               -1.1611e-01 -2.9849e-02  2.5475e-02\n",
       "                    ⋮  \n",
       "              \n",
       "              ( 2 , 0 ,.,.) = \n",
       "               -9.1180e-02 -1.0026e-01 -1.4459e-01\n",
       "                1.4901e-01 -1.0059e-02  1.3901e-01\n",
       "               -2.1553e-01 -6.2992e-02 -1.3343e-01\n",
       "              \n",
       "              ( 2 , 1 ,.,.) = \n",
       "               -4.1542e-02 -2.7007e-02 -8.1484e-02\n",
       "               -1.5022e-01  1.8234e-01  1.3810e-01\n",
       "                1.0217e-01  1.8202e-01 -8.7569e-02\n",
       "              \n",
       "              ( 2 , 2 ,.,.) = \n",
       "               -3.0104e-03  8.0348e-02  2.4281e-02\n",
       "                1.3282e-01 -1.5014e-01 -7.2490e-03\n",
       "                5.0689e-02  3.3246e-02 -1.0758e-02\n",
       "                  ... \n",
       "              \n",
       "              ( 2 ,61 ,.,.) = \n",
       "                8.8407e-02 -8.8594e-02  1.2737e-02\n",
       "               -4.2252e-03 -8.7952e-02  4.2666e-02\n",
       "               -6.7323e-02 -8.5075e-02 -5.3748e-02\n",
       "              \n",
       "              ( 2 ,62 ,.,.) = \n",
       "                1.4143e-01 -2.0123e-01  9.0640e-02\n",
       "               -8.0791e-02  8.4187e-02 -3.7203e-02\n",
       "                1.8774e-01  7.3654e-02 -1.5931e-01\n",
       "              \n",
       "              ( 2 ,63 ,.,.) = \n",
       "               -9.9958e-04  3.6090e-02 -7.1365e-02\n",
       "                6.4028e-02  1.7917e-02  2.2090e-02\n",
       "               -3.2864e-02 -7.7347e-02 -1.1172e-02\n",
       "              ...     \n",
       "                    ⋮  \n",
       "              \n",
       "              (125, 0 ,.,.) = \n",
       "               -1.6896e-01 -2.0874e-02 -7.3416e-02\n",
       "               -1.2419e-01  9.9942e-02 -5.6699e-02\n",
       "                2.8584e-02 -2.5234e-02 -6.3400e-02\n",
       "              \n",
       "              (125, 1 ,.,.) = \n",
       "               -1.4937e-01 -1.7226e-01  3.5099e-01\n",
       "                2.4279e-01  1.1066e-02 -1.2251e-01\n",
       "               -3.5648e-02 -9.2876e-02  2.6559e-01\n",
       "              \n",
       "              (125, 2 ,.,.) = \n",
       "                2.0113e-01 -3.0413e-03 -1.8017e-02\n",
       "               -2.8916e-01  2.1878e-01  4.2613e-02\n",
       "               -9.5100e-02 -1.2896e-01 -2.9794e-01\n",
       "                  ... \n",
       "              \n",
       "              (125,61 ,.,.) = \n",
       "               -6.3770e-02  1.0061e-01  6.7138e-02\n",
       "               -1.1168e-02 -5.2669e-02 -2.3844e-02\n",
       "                6.0512e-02 -3.6791e-01 -2.7611e-02\n",
       "              \n",
       "              (125,62 ,.,.) = \n",
       "               -1.3034e-01 -1.2388e-01 -3.7015e-02\n",
       "               -1.4481e-01 -1.3899e-01 -2.9546e-01\n",
       "               -9.2515e-02 -9.0379e-02  1.1218e-01\n",
       "              \n",
       "              (125,63 ,.,.) = \n",
       "               -1.2347e-01  3.0620e-02 -2.7387e-02\n",
       "               -5.5136e-02  2.1122e-02 -7.5971e-02\n",
       "               -8.6306e-02 -3.4980e-02  1.0076e-01\n",
       "                    ⋮  \n",
       "              \n",
       "              (126, 0 ,.,.) = \n",
       "               -5.6370e-02 -7.8456e-04 -5.4623e-02\n",
       "                3.0016e-02 -1.4567e-01 -4.2038e-02\n",
       "               -2.5978e-02 -1.9664e-01  1.6163e-01\n",
       "              \n",
       "              (126, 1 ,.,.) = \n",
       "                2.9375e-02  1.5511e-01 -6.4291e-02\n",
       "                2.8338e-01  4.1435e-02  6.1485e-02\n",
       "                1.8762e-01  2.0991e-01 -2.9028e-01\n",
       "              \n",
       "              (126, 2 ,.,.) = \n",
       "               -1.1313e-01 -1.1689e-02 -8.2408e-02\n",
       "                1.4851e-01 -2.8369e-01 -1.7290e-01\n",
       "               -1.4638e-02 -1.4249e-03 -1.1849e-01\n",
       "                  ... \n",
       "              \n",
       "              (126,61 ,.,.) = \n",
       "                7.8256e-02 -8.0767e-02  3.1783e-03\n",
       "               -2.6074e-01 -2.4926e-01  1.2749e-02\n",
       "                5.3494e-03 -1.8013e-01  2.2717e-01\n",
       "              \n",
       "              (126,62 ,.,.) = \n",
       "                1.3098e-01 -1.8838e-01 -9.1292e-02\n",
       "               -2.7531e-01  1.6777e-01 -2.0585e-01\n",
       "                2.2843e-03 -1.9920e-01 -2.4651e-01\n",
       "              \n",
       "              (126,63 ,.,.) = \n",
       "               -6.6042e-02  8.0750e-04  6.6623e-02\n",
       "               -5.0963e-02 -9.8369e-02  3.1905e-02\n",
       "                2.2321e-02 -4.7409e-02 -7.0971e-02\n",
       "                    ⋮  \n",
       "              \n",
       "              (127, 0 ,.,.) = \n",
       "                6.4109e-02  3.7858e-02 -4.3500e-02\n",
       "                2.1264e-02 -8.2275e-02 -1.3762e-02\n",
       "                2.8282e-02 -4.4018e-02 -5.6513e-03\n",
       "              \n",
       "              (127, 1 ,.,.) = \n",
       "                8.6090e-02  9.7766e-04 -6.1415e-02\n",
       "                4.2090e-02 -1.0385e-01 -7.4493e-02\n",
       "                3.8701e-03  2.7607e-02  5.6303e-03\n",
       "              \n",
       "              (127, 2 ,.,.) = \n",
       "               -1.0601e-02  1.5661e-02 -8.8288e-02\n",
       "               -2.3232e-02 -8.9562e-02 -1.5818e-02\n",
       "                3.3848e-02 -1.6064e-02 -6.9993e-02\n",
       "                  ... \n",
       "              \n",
       "              (127,61 ,.,.) = \n",
       "               -9.2415e-03  3.3313e-02  5.8222e-02\n",
       "               -1.6358e-02 -3.9797e-02  8.8990e-02\n",
       "                4.0774e-02 -2.9275e-02  3.3190e-02\n",
       "              \n",
       "              (127,62 ,.,.) = \n",
       "               -2.4045e-02 -2.7558e-02  6.6531e-03\n",
       "               -8.1029e-02 -4.7341e-02  3.5351e-03\n",
       "                9.7299e-02  3.0770e-03  1.3431e-02\n",
       "              \n",
       "              (127,63 ,.,.) = \n",
       "               -6.1991e-02 -5.2948e-03  1.4317e-02\n",
       "                5.1665e-02 -7.3333e-03 -7.1528e-02\n",
       "                3.9283e-02  5.5958e-02  5.2807e-02\n",
       "              [torch.cuda.DoubleTensor of size 128x64x3x3 (GPU 0)]),\n",
       "             ('conv4.bias', \n",
       "              -0.3037\n",
       "              -0.0032\n",
       "              -0.2336\n",
       "              -0.2669\n",
       "              -0.0822\n",
       "              -0.0104\n",
       "               0.2560\n",
       "               0.0033\n",
       "               0.0427\n",
       "               0.0028\n",
       "              -0.3435\n",
       "              -0.2303\n",
       "              -0.0034\n",
       "              -0.0643\n",
       "              -0.2149\n",
       "               0.0140\n",
       "              -0.1447\n",
       "              -0.5037\n",
       "              -0.3788\n",
       "              -0.3836\n",
       "              -0.2134\n",
       "              -0.1093\n",
       "              -0.3285\n",
       "              -0.1477\n",
       "               0.0130\n",
       "              -0.1282\n",
       "              -0.0810\n",
       "              -0.0227\n",
       "               0.0687\n",
       "              -0.0372\n",
       "              -0.2114\n",
       "              -0.1128\n",
       "              -0.0970\n",
       "              -0.2061\n",
       "              -0.0278\n",
       "              -0.3209\n",
       "              -0.2429\n",
       "               0.0126\n",
       "              -0.0889\n",
       "              -0.0131\n",
       "              -0.0492\n",
       "               0.9356\n",
       "              -0.1683\n",
       "              -0.1060\n",
       "              -0.2313\n",
       "               0.0427\n",
       "              -0.1359\n",
       "              -0.0082\n",
       "              -0.1169\n",
       "              -0.0581\n",
       "              -0.1135\n",
       "              -0.2979\n",
       "              -0.0036\n",
       "              -0.0161\n",
       "              -0.0243\n",
       "              -0.1277\n",
       "              -0.1470\n",
       "              -0.0557\n",
       "              -0.0264\n",
       "              -0.0953\n",
       "              -0.1423\n",
       "              -0.1014\n",
       "               0.0253\n",
       "               0.0117\n",
       "              -0.1323\n",
       "              -0.0825\n",
       "              -0.1377\n",
       "              -0.2891\n",
       "              -0.8361\n",
       "              -0.0450\n",
       "              -0.0102\n",
       "              -0.1847\n",
       "               0.0435\n",
       "               0.0303\n",
       "              -0.0259\n",
       "              -0.0234\n",
       "              -0.0912\n",
       "              -0.3803\n",
       "               0.1375\n",
       "              -0.0647\n",
       "               0.0035\n",
       "              -0.0110\n",
       "               0.0568\n",
       "              -0.0341\n",
       "               0.0335\n",
       "              -0.0407\n",
       "              -0.0430\n",
       "               0.0478\n",
       "              -0.0396\n",
       "              -0.3442\n",
       "              -0.0590\n",
       "               0.0349\n",
       "              -0.0358\n",
       "              -0.1964\n",
       "              -0.0954\n",
       "              -0.0927\n",
       "               0.0457\n",
       "              -0.1511\n",
       "              -0.1225\n",
       "              -0.0709\n",
       "              -0.1930\n",
       "              -0.2153\n",
       "              -0.1253\n",
       "              -0.0718\n",
       "              -0.1392\n",
       "               0.0171\n",
       "              -0.1043\n",
       "               0.0082\n",
       "              -0.2132\n",
       "              -0.0468\n",
       "               0.0176\n",
       "               0.2289\n",
       "              -0.0137\n",
       "               0.0115\n",
       "              -0.0029\n",
       "               0.0307\n",
       "              -0.0613\n",
       "              -0.3473\n",
       "              -0.1155\n",
       "              -0.0389\n",
       "              -0.0220\n",
       "              -0.0184\n",
       "               0.0353\n",
       "              -0.0595\n",
       "              -0.0590\n",
       "               0.0825\n",
       "              -0.2142\n",
       "               0.0267\n",
       "              [torch.cuda.DoubleTensor of size 128 (GPU 0)]),\n",
       "             ('batchnorm4.weight', \n",
       "               1.7081\n",
       "               1.5182\n",
       "               1.1908\n",
       "               0.7661\n",
       "               1.2553\n",
       "               0.3275\n",
       "               1.7173\n",
       "               0.8689\n",
       "               0.7029\n",
       "               1.2676\n",
       "               1.9948\n",
       "               0.4961\n",
       "               0.0692\n",
       "               1.6163\n",
       "               1.6407\n",
       "               1.3304\n",
       "               1.6756\n",
       "               0.6724\n",
       "               1.1828\n",
       "               1.4241\n",
       "               1.7819\n",
       "               1.3259\n",
       "               1.2723\n",
       "               1.3819\n",
       "               0.5842\n",
       "               1.3027\n",
       "               1.2156\n",
       "               0.5428\n",
       "               1.2174\n",
       "               0.7287\n",
       "               1.2077\n",
       "               1.2817\n",
       "               1.0655\n",
       "               1.7721\n",
       "               1.5247\n",
       "               1.6381\n",
       "               1.4158\n",
       "               0.5384\n",
       "               1.1026\n",
       "               1.0384\n",
       "               0.6155\n",
       "               1.2760\n",
       "               1.0691\n",
       "               1.1225\n",
       "               1.5838\n",
       "               0.9262\n",
       "               1.1620\n",
       "               1.3625\n",
       "               0.6879\n",
       "               0.8465\n",
       "               1.4465\n",
       "               1.4619\n",
       "               0.4709\n",
       "               0.9694\n",
       "               1.9744\n",
       "               1.1330\n",
       "               1.4550\n",
       "               0.5806\n",
       "               0.0427\n",
       "               0.6533\n",
       "               1.2092\n",
       "               1.0163\n",
       "               0.5169\n",
       "               1.5051\n",
       "               1.2324\n",
       "               1.3711\n",
       "               0.7972\n",
       "               1.4202\n",
       "               1.2041\n",
       "               1.0081\n",
       "               0.7464\n",
       "               1.3624\n",
       "               1.2608\n",
       "               0.4013\n",
       "               0.4768\n",
       "               1.5321\n",
       "               0.8974\n",
       "               1.1876\n",
       "               1.4169\n",
       "               1.2528\n",
       "               0.7417\n",
       "               1.0008\n",
       "               1.2255\n",
       "               0.8118\n",
       "               0.2140\n",
       "               0.9325\n",
       "               1.4691\n",
       "               1.5614\n",
       "               0.9201\n",
       "               1.2302\n",
       "               0.8977\n",
       "               1.0227\n",
       "               1.0753\n",
       "               1.2215\n",
       "               1.1062\n",
       "               1.9336\n",
       "               1.1271\n",
       "               1.5583\n",
       "               1.1333\n",
       "               1.5091\n",
       "               0.7074\n",
       "               0.9600\n",
       "               1.1526\n",
       "               1.0825\n",
       "               0.8685\n",
       "               0.0614\n",
       "               1.6205\n",
       "               0.6484\n",
       "               1.0713\n",
       "               1.4010\n",
       "              -0.5054\n",
       "               0.6486\n",
       "               1.2851\n",
       "               0.0905\n",
       "               1.0777\n",
       "               0.5243\n",
       "               0.7887\n",
       "               1.2176\n",
       "               0.9797\n",
       "               0.7715\n",
       "               1.0836\n",
       "               1.1607\n",
       "               0.0643\n",
       "               1.5376\n",
       "               0.9761\n",
       "               1.3647\n",
       "               1.2992\n",
       "               0.4422\n",
       "              [torch.cuda.DoubleTensor of size 128 (GPU 0)]),\n",
       "             ('batchnorm4.bias', \n",
       "               0.0925\n",
       "               0.0208\n",
       "               0.0691\n",
       "              -0.0624\n",
       "               0.0110\n",
       "               0.0223\n",
       "              -0.1500\n",
       "               0.0709\n",
       "               0.0917\n",
       "               0.1923\n",
       "              -0.1931\n",
       "               0.0055\n",
       "              -0.0072\n",
       "               0.1186\n",
       "               0.1785\n",
       "               0.0632\n",
       "               0.1438\n",
       "               0.1425\n",
       "               0.0009\n",
       "              -0.1893\n",
       "               0.2227\n",
       "               0.0246\n",
       "               0.0870\n",
       "               0.0950\n",
       "               0.1339\n",
       "              -0.0414\n",
       "               0.0600\n",
       "               0.0762\n",
       "               0.1133\n",
       "              -0.0044\n",
       "               0.0320\n",
       "              -0.1691\n",
       "               0.0899\n",
       "               0.1341\n",
       "               0.1707\n",
       "               0.0522\n",
       "               0.0227\n",
       "              -0.0389\n",
       "              -0.0254\n",
       "              -0.0184\n",
       "               0.0131\n",
       "               0.0121\n",
       "              -0.0707\n",
       "              -0.0402\n",
       "               0.1629\n",
       "               0.1278\n",
       "              -0.0614\n",
       "               0.1120\n",
       "              -0.0176\n",
       "               0.1009\n",
       "               0.1237\n",
       "               0.0850\n",
       "              -0.0216\n",
       "               0.1089\n",
       "              -0.3121\n",
       "              -0.0311\n",
       "               0.0120\n",
       "               0.1448\n",
       "               0.0091\n",
       "              -0.0243\n",
       "              -0.0057\n",
       "              -0.0212\n",
       "              -0.0049\n",
       "               0.0888\n",
       "               0.0543\n",
       "               0.0349\n",
       "               0.0139\n",
       "              -0.0828\n",
       "               0.0437\n",
       "               0.0573\n",
       "               0.0367\n",
       "               0.0711\n",
       "               0.0855\n",
       "               0.1261\n",
       "               0.0193\n",
       "               0.0809\n",
       "               0.0810\n",
       "               0.0628\n",
       "               0.1160\n",
       "               0.1016\n",
       "              -0.0230\n",
       "               0.0044\n",
       "               0.0707\n",
       "               0.0650\n",
       "              -0.0461\n",
       "               0.0596\n",
       "               0.0364\n",
       "               0.0559\n",
       "              -0.0430\n",
       "               0.0877\n",
       "               0.0364\n",
       "              -0.0041\n",
       "               0.0997\n",
       "               0.0575\n",
       "               0.1030\n",
       "               0.1306\n",
       "               0.1407\n",
       "              -0.0519\n",
       "               0.0089\n",
       "               0.1004\n",
       "               0.0208\n",
       "               0.0086\n",
       "               0.1212\n",
       "               0.0447\n",
       "              -0.0888\n",
       "               0.0074\n",
       "               0.0340\n",
       "              -0.0221\n",
       "              -0.0100\n",
       "               0.1596\n",
       "               0.0493\n",
       "              -0.0801\n",
       "              -0.0100\n",
       "              -0.0133\n",
       "              -0.0059\n",
       "               0.0495\n",
       "               0.0168\n",
       "               0.0809\n",
       "               0.0831\n",
       "              -0.0052\n",
       "               0.0214\n",
       "              -0.0116\n",
       "               0.0699\n",
       "              -0.0266\n",
       "              -0.0341\n",
       "              -0.1004\n",
       "               0.0402\n",
       "               0.0337\n",
       "              [torch.cuda.DoubleTensor of size 128 (GPU 0)]),\n",
       "             ('batchnorm4.running_mean', \n",
       "               3.3141e-01\n",
       "               3.0912e+00\n",
       "               2.8517e-01\n",
       "               4.0167e-01\n",
       "               6.5845e-01\n",
       "               8.2510e-01\n",
       "               3.4188e+00\n",
       "               1.1043e+00\n",
       "               2.3133e+00\n",
       "               3.1117e+00\n",
       "               2.1932e+00\n",
       "               1.4088e-01\n",
       "               7.6590e-01\n",
       "               1.3572e+00\n",
       "               1.5690e+00\n",
       "               1.6543e+00\n",
       "               2.4766e+00\n",
       "               8.2596e+00\n",
       "               2.8868e-01\n",
       "               8.8609e-01\n",
       "               1.3604e+00\n",
       "               4.9568e-01\n",
       "               9.5520e-01\n",
       "               8.5426e-01\n",
       "               1.9802e-01\n",
       "               7.2042e-01\n",
       "               1.0724e+00\n",
       "               1.4636e-01\n",
       "               1.4121e+00\n",
       "               3.9228e-01\n",
       "               3.1390e-01\n",
       "               1.0741e+00\n",
       "               1.2941e+00\n",
       "               1.5472e+00\n",
       "               3.3127e+00\n",
       "               1.6758e+00\n",
       "               1.1315e-01\n",
       "               9.4216e-01\n",
       "               7.3371e-01\n",
       "               1.9301e+00\n",
       "               2.7131e-01\n",
       "               1.1367e+01\n",
       "               1.1250e+00\n",
       "               2.6746e-01\n",
       "               7.1212e-01\n",
       "               2.6035e+00\n",
       "               2.4595e+00\n",
       "               3.0252e+00\n",
       "               7.2883e-01\n",
       "               8.8675e-01\n",
       "               2.3726e+00\n",
       "               9.1681e-01\n",
       "               8.8991e-01\n",
       "               2.2485e+00\n",
       "               3.2065e+00\n",
       "               5.5830e-01\n",
       "               6.1733e-01\n",
       "               9.3666e-01\n",
       "               1.4140e+00\n",
       "               1.2067e-01\n",
       "               6.8935e-01\n",
       "               9.0894e-01\n",
       "               9.9620e-01\n",
       "               7.6043e-01\n",
       "               7.4732e-01\n",
       "               1.0094e+00\n",
       "               5.3486e-01\n",
       "               7.2428e-01\n",
       "               7.3697e-06\n",
       "               2.7194e-01\n",
       "               4.7115e-01\n",
       "               7.0240e-01\n",
       "               2.1585e+00\n",
       "               8.6907e-01\n",
       "               6.5251e-01\n",
       "               3.1242e+00\n",
       "               1.5091e-01\n",
       "               2.2440e-01\n",
       "               2.9899e+00\n",
       "               1.7588e+00\n",
       "               3.8116e-01\n",
       "               6.1754e-01\n",
       "               3.0122e+00\n",
       "               3.6799e-01\n",
       "               6.6697e-01\n",
       "               1.0286e+00\n",
       "               3.1835e+00\n",
       "               3.5607e+00\n",
       "               5.4411e-01\n",
       "               1.7529e-01\n",
       "               1.5795e+00\n",
       "               2.4435e+00\n",
       "               3.7492e+00\n",
       "               4.1373e-01\n",
       "               3.1521e-01\n",
       "               2.0582e+00\n",
       "               3.0193e+00\n",
       "               1.5521e+00\n",
       "               3.8979e-01\n",
       "               3.6482e+00\n",
       "               2.7653e-01\n",
       "               5.7950e-01\n",
       "               5.5638e-01\n",
       "               5.2529e-01\n",
       "               2.5126e-01\n",
       "               7.7047e-01\n",
       "               2.1160e+00\n",
       "               4.6988e-01\n",
       "               1.4103e-01\n",
       "               1.1221e+00\n",
       "               1.2419e+00\n",
       "               8.2943e+00\n",
       "               6.5781e-01\n",
       "               4.8081e-01\n",
       "               9.8871e-01\n",
       "               5.0011e-01\n",
       "               1.1925e+00\n",
       "               4.3123e-01\n",
       "               4.2312e-01\n",
       "               4.2883e-01\n",
       "               8.9483e-01\n",
       "               2.1279e+00\n",
       "               1.0623e+00\n",
       "               1.8652e+00\n",
       "               1.8066e-01\n",
       "               1.7079e+00\n",
       "               1.6995e+00\n",
       "               9.1366e-01\n",
       "              [torch.cuda.DoubleTensor of size 128 (GPU 0)]),\n",
       "             ('batchnorm4.running_var', \n",
       "               1.9715e+00\n",
       "               1.5684e+01\n",
       "               8.9988e-01\n",
       "               2.0378e+00\n",
       "               1.2160e+00\n",
       "               4.0080e-01\n",
       "               1.0223e+01\n",
       "               2.1393e+00\n",
       "               2.4914e+00\n",
       "               1.3184e+01\n",
       "               7.5861e+00\n",
       "               5.0185e-01\n",
       "               4.6272e-01\n",
       "               7.7669e+00\n",
       "               8.2873e+00\n",
       "               4.3490e+00\n",
       "               1.3263e+01\n",
       "               2.9121e+02\n",
       "               8.1319e-01\n",
       "               2.1042e+00\n",
       "               9.8933e+00\n",
       "               3.0351e+00\n",
       "               8.0276e+00\n",
       "               4.4912e+00\n",
       "               3.5360e-01\n",
       "               1.9340e+00\n",
       "               1.8198e+00\n",
       "               1.0560e-01\n",
       "               2.5844e+00\n",
       "               6.1252e-01\n",
       "               7.7560e-01\n",
       "               1.9462e+00\n",
       "               5.1917e+00\n",
       "               1.3838e+01\n",
       "               2.5014e+01\n",
       "               9.4107e+00\n",
       "               3.7454e-01\n",
       "               7.9134e-01\n",
       "               1.6214e+00\n",
       "               3.5651e+00\n",
       "               2.9240e-01\n",
       "               3.0486e+01\n",
       "               3.5744e+00\n",
       "               4.6331e-01\n",
       "               3.9182e+00\n",
       "               2.8134e+00\n",
       "               1.0018e+01\n",
       "               1.1940e+01\n",
       "               4.4375e+00\n",
       "               3.1081e+00\n",
       "               1.8219e+01\n",
       "               6.7377e+00\n",
       "               4.3356e-01\n",
       "               3.5988e+00\n",
       "               9.9638e+00\n",
       "               1.2036e+00\n",
       "               1.5614e+00\n",
       "               1.4353e+00\n",
       "               1.0611e+00\n",
       "               1.1594e-01\n",
       "               2.4244e+00\n",
       "               1.4351e+00\n",
       "               9.2915e-01\n",
       "               1.9647e+00\n",
       "               2.0389e+00\n",
       "               6.9818e+00\n",
       "               1.5738e+00\n",
       "               1.8522e+00\n",
       "               2.2789e-06\n",
       "               3.2744e-01\n",
       "               4.3881e-01\n",
       "               2.9444e+00\n",
       "               6.3473e+00\n",
       "               3.7837e-01\n",
       "               3.1018e-01\n",
       "               7.4094e+00\n",
       "               1.6111e-01\n",
       "               1.0756e+00\n",
       "               1.1039e+01\n",
       "               3.3642e+00\n",
       "               4.6753e-01\n",
       "               9.5327e-01\n",
       "               6.0219e+00\n",
       "               5.8041e-01\n",
       "               2.6426e-01\n",
       "               1.4459e+00\n",
       "               5.1658e+00\n",
       "               9.5953e+00\n",
       "               1.0335e+00\n",
       "               5.1398e-01\n",
       "               4.7902e+00\n",
       "               3.5267e+00\n",
       "               9.4764e+00\n",
       "               8.8527e-01\n",
       "               4.1992e-01\n",
       "               1.2017e+01\n",
       "               3.9634e+00\n",
       "               3.1232e+00\n",
       "               7.0733e-01\n",
       "               1.6783e+01\n",
       "               1.2376e+00\n",
       "               1.0988e+00\n",
       "               1.9248e+00\n",
       "               1.4289e+00\n",
       "               6.4443e-01\n",
       "               4.0600e-01\n",
       "               1.8724e+01\n",
       "               3.9354e-01\n",
       "               3.0653e-01\n",
       "               6.7290e+00\n",
       "               7.0626e-01\n",
       "               2.2427e+01\n",
       "               1.0377e+00\n",
       "               3.3913e-01\n",
       "               1.3992e+00\n",
       "               3.2136e-01\n",
       "               1.9449e+00\n",
       "               2.2011e+00\n",
       "               6.3522e-01\n",
       "               5.3702e-01\n",
       "               1.2910e+00\n",
       "               2.5895e+00\n",
       "               5.5559e-01\n",
       "               3.2973e+00\n",
       "               3.3956e-01\n",
       "               2.7312e+00\n",
       "               4.3607e+00\n",
       "               4.8166e-01\n",
       "              [torch.cuda.DoubleTensor of size 128 (GPU 0)]),\n",
       "             ('conv5.weight', \n",
       "              ( 0 , 0 ,.,.) = \n",
       "               -4.4785e-03 -3.2086e-02 -4.0503e-02\n",
       "               -7.5014e-02  3.1614e-02 -9.6647e-02\n",
       "                3.7139e-03 -1.4560e-01 -4.0530e-02\n",
       "              \n",
       "              ( 0 , 1 ,.,.) = \n",
       "               -8.3782e-02  7.3739e-03  6.5268e-02\n",
       "               -1.3153e-01  7.9469e-02  1.2726e-02\n",
       "                4.2255e-02 -7.9793e-02  5.6503e-02\n",
       "              \n",
       "              ( 0 , 2 ,.,.) = \n",
       "               -5.5931e-02 -6.0748e-02 -1.2761e-02\n",
       "                1.0868e-01 -1.7663e-01 -1.2743e-01\n",
       "                2.4072e-02 -9.1265e-02  1.0024e-02\n",
       "                  ... \n",
       "              \n",
       "              ( 0 ,125,.,.) = \n",
       "               -6.2236e-02 -9.1391e-02  2.6925e-02\n",
       "                1.1067e-01 -3.0941e-02  1.5937e-02\n",
       "                6.5425e-02  1.9360e-01 -1.3493e-01\n",
       "              \n",
       "              ( 0 ,126,.,.) = \n",
       "                1.4108e-01 -4.8260e-02  1.5864e-01\n",
       "               -4.7314e-02  6.6055e-03  5.9859e-02\n",
       "                3.8243e-02 -7.7503e-02 -6.2056e-02\n",
       "              \n",
       "              ( 0 ,127,.,.) = \n",
       "                2.2975e-02 -3.3354e-02 -4.9743e-02\n",
       "               -5.8092e-02  1.4545e-02 -1.2272e-02\n",
       "               -7.3998e-02 -1.1673e-02  1.8328e-02\n",
       "                    ⋮  \n",
       "              \n",
       "              ( 1 , 0 ,.,.) = \n",
       "               -6.0412e-02  6.2399e-02 -6.7357e-02\n",
       "                1.7508e-01 -1.9148e-01 -1.6026e-01\n",
       "                3.9601e-02 -1.1284e-01 -1.8392e-01\n",
       "              \n",
       "              ( 1 , 1 ,.,.) = \n",
       "               -3.4554e-02 -2.9692e-02 -2.7359e-02\n",
       "                1.4313e-01 -7.4553e-02 -1.6657e-02\n",
       "               -1.6115e-01 -1.2031e-01 -8.9071e-02\n",
       "              \n",
       "              ( 1 , 2 ,.,.) = \n",
       "                4.0800e-02  1.0889e-02  6.4941e-03\n",
       "               -8.4077e-03  1.1329e-01 -4.6111e-02\n",
       "               -7.7165e-02 -1.8127e-02  7.9770e-02\n",
       "                  ... \n",
       "              \n",
       "              ( 1 ,125,.,.) = \n",
       "               -2.0511e-01 -1.4363e-01 -1.7617e-02\n",
       "               -1.6773e-02 -9.7252e-02 -1.5563e-01\n",
       "                1.5340e-02  1.4305e-01  1.9437e-02\n",
       "              \n",
       "              ( 1 ,126,.,.) = \n",
       "                1.5004e-01 -1.5687e-01  1.8360e-02\n",
       "                1.0219e-01 -2.1780e-02 -1.8497e-02\n",
       "                2.2081e-02 -1.7379e-02  5.1598e-02\n",
       "              \n",
       "              ( 1 ,127,.,.) = \n",
       "               -1.3828e-02 -6.8955e-02 -8.2370e-02\n",
       "                4.4112e-02 -6.8710e-03  6.4556e-02\n",
       "               -3.7348e-02 -5.7744e-02  1.1973e-02\n",
       "                    ⋮  \n",
       "              \n",
       "              ( 2 , 0 ,.,.) = \n",
       "                2.6136e-02 -7.8827e-02  5.1813e-04\n",
       "               -8.6199e-02  2.5632e-02  3.3657e-02\n",
       "               -5.0331e-02  1.0567e-02 -9.3464e-02\n",
       "              \n",
       "              ( 2 , 1 ,.,.) = \n",
       "               -6.1808e-02 -6.7005e-04  3.2659e-02\n",
       "                1.7762e-02 -3.4499e-02 -2.2231e-02\n",
       "               -8.6797e-02  4.2866e-02 -2.3579e-02\n",
       "              \n",
       "              ( 2 , 2 ,.,.) = \n",
       "                2.6829e-03 -2.5720e-02  1.1379e-02\n",
       "                6.9168e-03 -9.6611e-02  4.2418e-02\n",
       "               -6.6205e-02 -6.2190e-02 -9.4100e-03\n",
       "                  ... \n",
       "              \n",
       "              ( 2 ,125,.,.) = \n",
       "                4.8877e-02 -1.5386e-02  1.8417e-02\n",
       "                3.0877e-02 -7.1399e-02 -3.6427e-02\n",
       "               -3.7580e-02  5.4972e-02 -6.7038e-02\n",
       "              \n",
       "              ( 2 ,126,.,.) = \n",
       "                3.1487e-02 -8.7071e-02 -2.7816e-02\n",
       "               -5.5472e-03  8.7304e-03 -6.3527e-02\n",
       "                2.7714e-02 -5.5773e-02  3.1595e-02\n",
       "              \n",
       "              ( 2 ,127,.,.) = \n",
       "               -2.0821e-02 -2.8618e-02 -6.5902e-02\n",
       "                6.4429e-02  1.7747e-02 -5.0681e-02\n",
       "               -7.0250e-02  5.2869e-02  1.7709e-02\n",
       "              ...     \n",
       "                    ⋮  \n",
       "              \n",
       "              (125, 0 ,.,.) = \n",
       "                4.7469e-02 -9.0537e-02 -4.7741e-03\n",
       "                1.5734e-02 -1.2231e-01 -8.1231e-02\n",
       "                7.7696e-02 -3.4403e-02 -1.5500e-01\n",
       "              \n",
       "              (125, 1 ,.,.) = \n",
       "                2.2394e-02 -6.0641e-02  4.7837e-03\n",
       "                1.3393e-02 -6.4333e-02 -7.4332e-02\n",
       "                5.2712e-03 -8.0156e-02 -1.0704e-02\n",
       "              \n",
       "              (125, 2 ,.,.) = \n",
       "                3.9356e-02  6.4032e-02  6.5588e-03\n",
       "                8.6483e-03 -1.4193e-02 -4.9864e-02\n",
       "               -1.8899e-02 -4.4291e-02  6.5041e-02\n",
       "                  ... \n",
       "              \n",
       "              (125,125,.,.) = \n",
       "               -3.4921e-02  4.5990e-02 -4.3726e-02\n",
       "                6.0470e-02 -1.5062e-02 -2.7490e-02\n",
       "               -4.1186e-03 -7.3771e-03 -3.0067e-02\n",
       "              \n",
       "              (125,126,.,.) = \n",
       "               -3.4920e-02 -6.2827e-02 -7.5260e-02\n",
       "                8.1571e-02 -1.2497e-02 -2.5102e-02\n",
       "                6.4912e-02  3.7101e-02 -8.2636e-02\n",
       "              \n",
       "              (125,127,.,.) = \n",
       "               -2.8921e-02  5.5250e-02 -5.8871e-03\n",
       "               -7.6257e-02 -7.0803e-02 -5.6964e-02\n",
       "               -4.3597e-02  5.9255e-02  1.9782e-02\n",
       "                    ⋮  \n",
       "              \n",
       "              (126, 0 ,.,.) = \n",
       "               -1.6714e-02 -1.3567e-02  6.5776e-03\n",
       "               -5.9328e-02  6.2536e-02  5.1218e-02\n",
       "                6.0851e-02 -6.8990e-02  5.4871e-02\n",
       "              \n",
       "              (126, 1 ,.,.) = \n",
       "                6.1350e-02  2.8189e-02  1.7230e-02\n",
       "                7.7116e-02 -2.4881e-02  5.5381e-02\n",
       "               -2.3169e-02  6.5104e-03  5.0654e-02\n",
       "              \n",
       "              (126, 2 ,.,.) = \n",
       "                5.3164e-02 -5.3547e-02 -2.4590e-02\n",
       "                7.3903e-03 -1.1918e-02 -2.5634e-02\n",
       "                1.4538e-02  3.1749e-02  2.8735e-02\n",
       "                  ... \n",
       "              \n",
       "              (126,125,.,.) = \n",
       "               -3.4754e-02 -1.7716e-02 -5.1424e-02\n",
       "               -4.8511e-02 -4.7662e-02  1.9497e-02\n",
       "               -1.3239e-02 -2.2129e-02 -3.0393e-02\n",
       "              \n",
       "              (126,126,.,.) = \n",
       "               -5.1957e-02  1.1575e-02 -7.8471e-03\n",
       "                2.9635e-02  3.1478e-02  5.1041e-02\n",
       "                4.0447e-02  7.2421e-02 -1.6064e-02\n",
       "              \n",
       "              (126,127,.,.) = \n",
       "                5.1384e-02 -4.1554e-02  2.1537e-02\n",
       "               -3.9868e-02  4.0628e-02 -3.8440e-02\n",
       "                1.8150e-02  1.8480e-02 -1.4875e-02\n",
       "                    ⋮  \n",
       "              \n",
       "              (127, 0 ,.,.) = \n",
       "                1.1282e-01 -1.9303e-02  2.0043e-02\n",
       "               -8.2997e-02 -5.8289e-02 -2.9189e-02\n",
       "               -8.9853e-02 -6.2592e-02 -7.1958e-02\n",
       "              \n",
       "              (127, 1 ,.,.) = \n",
       "                7.4840e-02  3.4320e-02 -6.8904e-02\n",
       "               -3.8678e-03  1.4217e-01  8.6427e-02\n",
       "               -2.1577e-02  3.4838e-02 -3.6952e-03\n",
       "              \n",
       "              (127, 2 ,.,.) = \n",
       "                6.3988e-02  1.1109e-01 -5.8047e-02\n",
       "                3.3505e-02 -2.4846e-03  9.0351e-02\n",
       "               -5.4569e-02  1.0858e-01 -2.8157e-03\n",
       "                  ... \n",
       "              \n",
       "              (127,125,.,.) = \n",
       "               -7.6478e-03 -2.1205e-01 -4.6496e-02\n",
       "                2.8777e-02  3.0538e-02 -7.0655e-02\n",
       "                7.0937e-02 -3.0593e-03 -5.7985e-02\n",
       "              \n",
       "              (127,126,.,.) = \n",
       "               -5.0474e-03  1.0580e-03  4.7809e-02\n",
       "                4.3154e-02 -1.9751e-01 -1.0837e-02\n",
       "               -2.9512e-02  4.2270e-02 -6.3887e-02\n",
       "              \n",
       "              (127,127,.,.) = \n",
       "                6.0059e-02  2.3457e-02  3.2904e-02\n",
       "               -8.1646e-02 -5.5027e-02  9.1456e-03\n",
       "               -4.1330e-03 -7.1693e-03 -2.7955e-02\n",
       "              [torch.cuda.DoubleTensor of size 128x128x3x3 (GPU 0)]),\n",
       "             ('conv5.bias', \n",
       "               0.0444\n",
       "               0.0495\n",
       "               0.0235\n",
       "               0.0247\n",
       "               0.0181\n",
       "               0.0737\n",
       "               0.1147\n",
       "               0.0530\n",
       "               0.0070\n",
       "               0.0244\n",
       "               0.0672\n",
       "               0.0786\n",
       "               0.0948\n",
       "               0.1072\n",
       "               0.1105\n",
       "              -0.0270\n",
       "              -0.0152\n",
       "               0.0619\n",
       "               0.0638\n",
       "               0.0092\n",
       "               0.0638\n",
       "               0.0209\n",
       "               0.0738\n",
       "               0.0337\n",
       "              -0.0162\n",
       "               0.1090\n",
       "               0.0298\n",
       "              -0.0060\n",
       "               0.0569\n",
       "               0.0376\n",
       "               0.0185\n",
       "               0.0410\n",
       "               0.0144\n",
       "               0.0269\n",
       "               0.0313\n",
       "              -0.0400\n",
       "               0.0113\n",
       "               0.0024\n",
       "               0.0418\n",
       "               0.0871\n",
       "              -0.0080\n",
       "               0.0377\n",
       "               0.0507\n",
       "              -0.0148\n",
       "               0.0752\n",
       "               0.0181\n",
       "              -0.0511\n",
       "               0.0365\n",
       "               0.0473\n",
       "               0.1040\n",
       "               0.0219\n",
       "               0.1039\n",
       "              -0.0934\n",
       "               0.0718\n",
       "               0.0413\n",
       "               0.1093\n",
       "               0.0672\n",
       "               0.0298\n",
       "               0.0091\n",
       "               0.0148\n",
       "              -0.0191\n",
       "               0.0150\n",
       "              -0.0075\n",
       "               0.0026\n",
       "               0.0774\n",
       "               0.0475\n",
       "               0.0681\n",
       "               0.0023\n",
       "              -0.0065\n",
       "              -0.0253\n",
       "               0.0263\n",
       "              -0.0150\n",
       "               0.0051\n",
       "               0.0332\n",
       "               0.0859\n",
       "               0.0815\n",
       "              -0.0217\n",
       "               0.0579\n",
       "               0.0146\n",
       "               0.0912\n",
       "              -0.0029\n",
       "               0.1218\n",
       "               0.0043\n",
       "               0.0791\n",
       "               0.1889\n",
       "              -0.0255\n",
       "               0.0099\n",
       "               0.0257\n",
       "               0.0055\n",
       "               0.0575\n",
       "              -0.0115\n",
       "               0.0535\n",
       "              -0.0276\n",
       "              -0.0219\n",
       "              -0.0011\n",
       "              -0.0218\n",
       "               0.0028\n",
       "               0.0406\n",
       "              -0.0230\n",
       "              -0.0095\n",
       "              -0.0091\n",
       "               0.0999\n",
       "               0.0274\n",
       "               0.1360\n",
       "               0.0954\n",
       "               0.0287\n",
       "               0.0967\n",
       "               0.0875\n",
       "              -0.0010\n",
       "              -0.0014\n",
       "              -0.0315\n",
       "               0.0231\n",
       "               0.0003\n",
       "               0.0377\n",
       "              -0.0087\n",
       "               0.0549\n",
       "              -0.0161\n",
       "              -0.0272\n",
       "               0.0071\n",
       "              -0.0018\n",
       "               0.1289\n",
       "               0.0557\n",
       "               0.0157\n",
       "               0.0661\n",
       "              -0.0066\n",
       "               0.0109\n",
       "               0.0279\n",
       "               0.0931\n",
       "              [torch.cuda.DoubleTensor of size 128 (GPU 0)]),\n",
       "             ('fc1.weight', \n",
       "              \n",
       "              Columns 0 to 9 \n",
       "               0.1303  0.5505 -0.2618  1.6775  0.9438 -0.6985 -0.7816  0.7779 -0.3993  0.4223\n",
       "              -1.0735  1.0276 -0.1457 -1.2524 -0.1926  0.6804  0.4194  0.1893 -0.8433  2.2520\n",
       "              \n",
       "              Columns 10 to 19 \n",
       "               0.6637  0.3438  1.8445  1.2690  0.9766  0.4587  0.0362  1.1282 -0.7969  0.7476\n",
       "               0.1297  1.1412  0.7191 -0.0699 -1.1915  0.0341 -0.7755 -0.0933 -0.9992 -0.6493\n",
       "              \n",
       "              Columns 20 to 29 \n",
       "               1.4165  0.2480 -0.6475  0.8047  0.4659  0.9417 -0.8931  0.6446  0.8176 -0.4125\n",
       "              -0.8000 -0.4811  0.3580  0.3803 -0.1729 -0.3737 -1.0595 -0.9848 -0.5499 -1.4865\n",
       "              \n",
       "              Columns 30 to 39 \n",
       "              -0.9630  0.5387 -2.0248 -0.8882 -0.7680 -0.5721  0.0566  0.6590  0.0439 -1.3242\n",
       "              -0.7548  0.2394  0.3070 -0.2729  0.6508 -0.4753  0.5380  1.3225 -0.4409 -0.4539\n",
       "              \n",
       "              Columns 40 to 49 \n",
       "               0.6250  1.5770  0.8110  0.1316 -0.8643  0.3737  0.0399  0.4410  0.3328  0.8031\n",
       "              -1.8899  0.7998 -0.6585  0.0145  0.2877 -0.1625 -0.9699  0.3975 -0.6038 -0.1790\n",
       "              \n",
       "              Columns 50 to 59 \n",
       "               0.8247 -0.3435 -1.2541 -0.5072 -0.8586  0.3558  0.2234 -0.9172  0.4132 -1.1955\n",
       "               0.2236  0.9262 -2.7292  2.1393 -0.3706  1.4644  1.0876 -0.1607 -0.1486  0.4087\n",
       "              \n",
       "              Columns 60 to 69 \n",
       "               0.4799 -0.5980 -0.4449  0.3048  0.5049  0.3708  0.8677 -0.7948  0.3082 -0.6257\n",
       "               0.1573  0.0094 -1.8023 -0.2373 -0.7277 -0.9412  0.4638  0.0219  0.5978 -0.6234\n",
       "              \n",
       "              Columns 70 to 79 \n",
       "              -0.2573  0.1398  0.3730 -0.3407 -0.5265  0.1578 -0.2491  0.3196 -0.0251 -0.2518\n",
       "               0.0991  0.3967  0.2339  0.4195  1.0945  0.6520  2.0723 -0.3557 -0.0089  0.7462\n",
       "              \n",
       "              Columns 80 to 89 \n",
       "              -0.0406  0.0927  0.1614 -0.5018  1.1000 -0.1027 -0.3338 -0.7351 -0.0567 -0.3267\n",
       "               0.6350  1.8638  0.1225 -1.1094 -1.4243  0.9798 -0.4446 -0.2500 -0.2851 -1.0958\n",
       "              \n",
       "              Columns 90 to 99 \n",
       "              -0.5259 -0.8613  0.2949 -0.1252 -0.7604 -1.1970  0.3258 -0.7057  1.2370 -0.1809\n",
       "               1.3798  0.1282  0.2170 -0.0894 -0.1857  0.3791 -0.3819  0.5567  0.0165 -0.1285\n",
       "              \n",
       "              Columns 100 to 109 \n",
       "               0.2043  0.8503 -0.7483 -0.5135 -1.5526 -0.5023 -1.4610 -0.4387  0.9846 -0.1714\n",
       "               0.1217  1.4499  0.4776  1.1835  0.4210 -0.8230 -0.0847 -1.4265  0.3129 -0.0115\n",
       "              \n",
       "              Columns 110 to 119 \n",
       "              -0.1903 -1.7477 -0.1527  0.2146 -0.3165  1.0041  0.2273 -0.6261  0.1127 -0.6363\n",
       "              -0.9854 -0.2491  0.6473  0.5242  0.5683 -0.6810 -0.1542 -1.0767 -0.5437 -0.6965\n",
       "              \n",
       "              Columns 120 to 127 \n",
       "               0.6979 -0.2788 -0.0981 -0.6071 -0.5606 -0.0137  0.0400  0.9957\n",
       "              -1.4647  0.5980  0.0033 -0.6044 -0.2901  0.6579  0.1050 -0.7455\n",
       "              [torch.cuda.DoubleTensor of size 2x128 (GPU 0)]),\n",
       "             ('fc1.bias', \n",
       "              1.00000e-02 *\n",
       "               -9.8278\n",
       "                3.4501\n",
       "              [torch.cuda.DoubleTensor of size 2 (GPU 0)])])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "pos = np.empty((0, 2), np.double)\n",
    "pos_inferred = np.empty((0, 2), np.double)\n",
    "\n",
    "for i, samples in enumerate(test_loader):\n",
    "\n",
    "    ## Run on GPU ##\n",
    "    if torch.cuda.is_available() and onGPU:\n",
    "        #Load data as variable\n",
    "        images = Variable(samples['image'].cuda())\n",
    "        labels = Variable(samples['labels'].cuda())\n",
    "    else:\n",
    "        images = Variable(samples['image'])\n",
    "        labels = Variable(samples['labels'])\n",
    "\n",
    "   \n",
    "    # forward pass\n",
    "    outputs = model(images)\n",
    "\n",
    "    pos = np.concatenate((pos, labels.data[:,3:5].cpu().numpy()))\n",
    "    pos_inferred = np.concatenate((pos_inferred, outputs.data.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "torch.save({'model': model.state_dict(), 'optimizer': optimizer.state_dict(), 'loss_epoch': loss_epoch}, f='/home/jacquemont/MyDriveAtLap/saved_models/model1_impactPos_kaimin-uniform_batchnorm_lr0.00005_20epochs.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZoAAAEBCAYAAABBp2PjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npYVGKaVUUv1/f/XJW4dab3gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2879152e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(num_epochs), loss_epoch)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA00AAAFaCAYAAADCT7YmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3XecFdX9//HXB2lixRKjJlh+mgTsgka/GkUQNQgoKqiA\nBTV2jTVKLCzFllijsWBQFBBQ1AAWFESwF0A0giUKgrGgCIIVWPj8/pi77Oxy7947u/fuzL37fj4e\n+9i7M2dmPpuyh3POZz7H3B0RERERERFJr1HcAYiIiIiIiCSZBk0iIiIiIiI10KBJRERERESkBho0\niYiIiIiI1ECDJhERERERkRpo0CQiIiIiIlIDDZpERERERERqoEGTSJ6Z2aFm9oKZfWdmX5vZNDPr\nFndcIiIioH5KpDY0aBLJIzM7BngEeBD4FbAFcDXQtRb3apzf6EREpKFTPyVSOxo0iURkZv/PzBab\n2Z6pn7dKzdQdBNwMDHL3f7n7Undf7e7T3P1PqbaNzOxKM5tvZl+Z2YNmtlHq3LZm5mZ2qpktAKak\nju9jZq+Y2bdm9raZtY/nNxcRkWJgZpea2aPVjv3DzG5D/ZRIrWjQJBKRu38MXAaMMLMWwP3AA8AX\nwK+BsTVcfnLq6yBge2B94I5qbQ4EWgOHmtnWwJPAYGAT4BLgUTPbPE+/joiIlJ4RwGFmtjGsWRE6\nDngY9VMitaJBk0gtuPu9wEfA68CWwBXApqnTX9RwaW/gZnef6+7fA/2A46qlOJS5+w/u/hPQB3jK\n3Z9KzQZOAqYDnfP8K4mISIlw9y+AF4AeqUOHAYtCTdRPiUSkQZNI7d0L7Azc7u7LgW9Sx7es4Zqt\ngPmhn+cDjQlyyit8Gvq8DdAjlfLwrZl9C+yf5RkiIiIPEAxoSH0fjvopkVrToEmkFsxsfeBWYChQ\nZmabAB8QdCRH13Dp5wQdTIVWQDmwMHTMQ58/BYa7+8ahr/Xc/fp8/B4iIlKy/g3samY7A12Akaif\nEqk1DZpEauc2YLq7n0aQy323uztwEXCVmfU1sw1TL9Tub2ZDUteNAi40s+1SA69rgTHuXp7hOSOA\nrqnysOuYWXMza29mvyrw7yciIkXM3X8meHfpIeANd1+gfkqk9jRoEonIzI4gyA8/K3XoImBPM+vt\n7mOBY4FTCGbrFhK8HDsu1fY+ghSJF4B5wM/AeZme5e6fAkcAfwW+JpjRuxT9f1dERLJ7ANiFoN8B\nQP2USO1YMOkgIiJSN6kyw8+nObXU3TfOcm1zYBDBuxcbA7OAy9z9hXzHKdJQmFkr4H3gl+6+LO54\nRJLCzDoDlwN7AquBD4G/uPuUTNdoUzIREcm384E3Qz9nSusJGwocTjBDPRc4B3jGzPZ191n5D1Gk\ntJlZI4JMiNEaMIlUMrMzCMro30EwWdcI2B1oUeN1WmkSEZF8CK00dXL3yRGu241gZekUd78/dawx\nMBv4wN27FSBckZJlZusRpN3NBw5LpdCJNHhmti3wHtDP3W+Ncq1WmkREJG7dgJXAmIoD7l5uZqOB\ny82sWaqsv4jkwN1/INiUVkSqOoUgHe/uqBfqJT0REcm3kWa2ysy+MbOHUu9V1GQnYJ67/1jt+Gyg\nKbBDQaIUEZGGZn+C9/yOM7OPzazczD4ys3OyXaiVJhERyZelwE3ANGAZsAdBRa1XzWwPd/8qw3Wb\nAEvSHF8cOi8iIlJXW6W+/k7QP30M9ADuMLPG7n5bpgs1aKqjzTbbzLfddtu4wxCRBmDGjBmL3H3z\nut5nB7O1lnSy+SJY9fk5dGiIuw8Jt3H3t4C3QoemmdkLwBsEJYuvqk28Ujfqp0SSY8aMz9d8btt2\nq/oP4Jtv4JNPYMstYav8Pz/p/RRBlt0GwMnu/ljq2JTUu079CPbhTEuDpjradtttmT59etxhiEgD\nYGbz83GfH4EzIl5TBj+7e7uoz3L3mWb2IbB3Dc2WANukOV6xwrQ4zTnJkfopkeQwK1vzefr0sozt\nCmLmTNhvPzjoIHj2WWic/2FAEfRT3wA7ApOqHX8WOMzMtnT3L9JdqHeaREQaGCOYMYvyVWCzge3M\nrHq51zbACuCjwocgIlLCvvkGjjoKNt8cxowpyIApnwrYT82ubUwaNImINDAGNIn4VetnmbUDfgu8\nXkOzCanH9Ahd1xg4FnhWlfNEpFS4l635qjerVkGvXvDFF/Doo8HAKeEK2E89nvp+aLXjhwH/y7TK\nBErPExEpDqNH5+1WFTN4+WZmIwheqn2LykIQ/YDPgH+k2myTajPQ3QdC8C6UmY0BbjWzJsA84Cxg\nO6B3AUIVEWk4rr46SMe7917Ya6+4o8lJofop4CmC/QTvMbPNCDZT7wEcAvSt6UINmkREku6BB+CU\nU/J2u4oZvAKYDRwPXECws/qXwGNAf3dfFHr8Oqyd6dAXuAYYDGwMvE2wKefMwoQqItIA/PvfcO21\n8Kc/wWmnxR1NzgrVT7m7m9mRwHXAAKAlQQny3u7+UE3XatAkIpJkQ4bAmWdCx44weXJeblmoGTx3\nv46gI6qpzSepEKof/wm4KPUlIiJ19cEHcOKJsPfecPvtcUcTSQFXmnD3ZcA5qa+cadAkIpJUt98O\n558PnTsHeejrrpuX2xZwpUlERJLgu++ge3do3hzGjoVmzeKOKJIk9lMaNImIJNGNN8Kll8KRRwbv\nM+WxwyvkDJ6IiNSfcAnzNcUl3KFv32ClafJk+PWvY4mtLpLYTyUtHhERueYauPJK6NkTRoyAJvmd\nb0viDJ6IiOTJjTcG2Qk33hjsyVSEkthPadAkIpIU7kGVo8GD4YQT4L77CrP5IPrjLyJSkp57Di6/\nPJh0u6h4XxFNYj+VtHhERBomd7jsMvj734MKR3ffDeusU5BHJXEGT0REoquy39OCBXDccfC738HQ\noWBr1dwpGknspzRoEhGJmzv8+c9B4Yezzw6+Nyrc3uNJ7IxERKQOfv4Zjj4aVqyAxx+H9dePO6I6\nSWI/pUGTiEicVq+Gs84KSotfeCHcdFO9zA7qj7+ISIlwh3POgenTYdw4+M1v4o4oL5LWTyUtHhGR\nhmPVKjj11GDz2n79ggIQ9TBgSuIMnoiI1NK99wbvwF55JXTrltMlaavuJUgS+ykNmkRE4lBeHmw6\nOGoUDBgAV12VccBU2blt2TYfj07iC7YiIlILr78O550Hhx0GZWVxR5M3SeynkhaPiEjpW7ECevUK\nSsJef31QAKIeJXEGT0Sk2NX76s3ChcF7TFtvDSNHRioelMTVpbAk9lMaNImI1Keff4YePeCJJ+DW\nW4MCECmZOtyKz2YDZuQjhCTO4ImISATl5UGlvG++gVdfhU02iTuivEpiP5W0eEREStePP0L37vDs\ns3DXXXDmmXFHJCIixejyy2HqVBg+HHbfPe5oGgQNmkRE6sP33wcv6E6dGryw27dvbKEkMe1BRKSY\npMsMqK+Ut2PtGMbwKLezF+f16VMvz6xvSeynNGgSESm0Zcugc+cghWL4cOjdO22z+upwk5j2ICIi\nOXj3Xe5jPC/xay7mUM6LO54CSWI/lbR4RERKy5IlQVWjmTNh9OjgfaaYJXEGT0REsvj2WzjqKJbR\njB70YCW5F34oNknspwq35Xw9MbOJZuZmNrja8ZZm9i8zW2RmP5jZZDPbJc31zc3s72b2hZn9ZGav\nmtkB9fcbiEjJWrQIOnaEWbOCSnkJGDBB5QxelC8REankXrbmK9/Myqqk/wE0sv6Mb/l7Vv73Y46h\nB1+yQd6fmyRJ7KeKui80s+OB3dIcN2ACsC1wHrAE6Ac8b2a7u/v/Qs2HAocDlwJzgXOAZ8xsX3ef\nVdjfQERK1sKFcPDB8NFHwQ7thx0Wd0RrJHEGT0REMvsrL9KNDzmXP/IKreIOp+CS2E8V7aDJzFoC\ntwAXAg9VO90N2A/o4O7Pp9q/CswD/gKcnzq2G9ALOMXd708dmwbMBgam7iMiEs3nnwcrTAsWBKXF\nO3aMO6IqktgZiYiUkrrs2bRW+6efZrBNhT4ncMcDD3BHho3QS0kS+6liTs+7AXjX3UelOdcN+Lxi\nwATg7ksJVp+OqNZuJTAm1K4cGA0cambNChG4iJSwBQvggAPgf/+DiRMTN2CqkLS0BxERSWPu3GAz\n9F13hbvvhgYwYKqQtH6qKPtCM9sfOJE0qXkpOwHvpjk+GzjRzNZ39+9T7ea5+49p2jUFdkh9FhHJ\nbt486NAhKP4waRLss0/cEaVlQJOof/3LCxGJiIhk9OOPcNRRwUDpscegRYu4I6o3Seynim7QZGZN\ngXuAG939gwzNNgE+SXN8cep7S+D7VLslNbRLu72ymZ0OnA7QqlXp55WKSA4+/DBYVfrxR3juOWjb\ntsbmdUndqCszaJywzkjyS/2USLzq/HfdHU4/Hd55B556CrbfPi9xFYsk9lPFmJ73F2Bd4Jq4AnD3\nIe7ezt3bbb755nGFISJJMWcOHHggLF8OU6ZkHTDFzQyarBPtq3bPSV/dNENbz/Clre5rQf2USJG7\n4w4YORIGDkxUIaH6Ul/9VBRFtdJkZq2AK4DTgGbV3jlqZmYbA98RrB61THOLipWjJaHv29TQbnGa\ncyJSjypWZOp7NSZnb78dVMlr3BimToU2bXK6LM7fp1YzeJGfkb66aRbDCDIJwj7MS0AiIsXipZfg\noougWzf461/jjiYW9dFPRZWwcLLaHmgOjEhz7pLU1x4E7yEdkqZNG2BB6n0mUu26m1mLau81tQFW\nAB/lK3ARKUEzZkCnTrDeesEK0447xh1RTmqVKx7l/jVXN63JZ+7+WmGiEhGJX9bU7M8/D/b02247\nePBBaFQcSWGVv9eWeUm1KHQ/VRsJCyerWcBBaY4/TzCQGkow0BkP9DWzA919GoCZbQh0pWoHPgEY\nAPQAHki1awwcCzzr7ssL9HuISI5quyKTrWOqvnFg5Oe99lqQMtGyZTBg2m67yDHGxqDAG8mvqW5q\nZlEGTSIiDdeKFcGA6bvvYPJk2GijuCOKT+H7qciKatDk7t8CU6sfD/ayZb67T039PB54FRhhZpdS\nubmtAX8L3e8tMxsD3GpmTQj2cToL2A7oXcjfRUSK2IsvQufO8MtfBkUfiu1F+4qt1gtx6+zVTWty\nVupv9irgNaC/u7+Yz/hERBLr4ovhlVdgzBjYaae4o4lXAfup2kpYOPnh7qvNrAtwI3AnQUrfq8BB\n7v5pteZ9CYpKDAY2Bt4GDnP3mfUYsogUi+eeC/LMW7UKPm+1VdwRRVegzijH6qaZjACeAD4neNf0\nUmCKmXWqmBATEalvUSqdZmqbKbOhigcfDIo/XHwx9OwZKcYkqPh9zQbMyMsNNWgqDHdfa6cvd18M\nnJL6qunan4CLUl8iUiKydW65pOGt1QE+/TR07w6/+U2QOvGLX9Q6vjhLjgO1+eu/mZlND/08xN2H\nVGtT6+qm7n5C6McXzWwcwX57g4A/RL2fiEjReOstOOMMaN8err8+7miSI2GjlISFIyKSUOPGBbN/\nO+0UbFy76aZxR1TfFrl7u0wnc61u6u6rcnmYu39nZk+SZeJLRKSQokywZWpb4z0WLw42sN1ssyAt\nL2kl42QN/TcjIpLBmo7ukUfgmGNgzz1h4sSg+EO+7h2Hwrxgm2t101l5f7KISDFatQp69Qoq5r34\nYp2yF0qOCkGIiBSZESPgpJNg332DXdk33DDuiOquMLniuVY3zUmq4mkX4I28RCcikjT9+8Mzz8CQ\nIbD33nFHkyx6p0lEpIjcdx+cdlqQZz5+PKy/ftwR5UcBOqMI1U23AT4GBrr7wNSxS4AdCAZYCwkK\nQVwC/BJVMhWRElKRyteN9xnHGO5lD04//bNgs5wUnxBPbImiQZOISJG4+2446yw49FB4/HFYd924\nI8qv+NIeKpIuwjs2fgB0B44BNgKWAS8Dp7q7VppEpKT8hkUM53HeZCvOo3Pc4SSX0vNERBLu1lvh\nwguha1d4+GFo3jzuiPKrHmfwqlc3dfdPUhGEj00g2GxcRKSkrccKHuNhltOYo+nJcv1TPD2tNImI\nJNtldjA38Bxjac0xY8dC06Zxh5R/CeyMRESKVc6Ffdy5j3H8jkV04gQW+C1rTlXdy2nt+8W+TUV9\nS2A/lbBwRERi4g4DB3IDz/EQO3Mi3SkvxQFThYSlPYiIlLybbqInc7iUg3me7eKOJvkS1k81yt5E\nRKTEucMVV0BZGZx8Mr3KZ1Ee1CgoTRUzeFG+RESk9qZMgcsu4xHacCP/F3c0yZfAfkpdoYg0bO5w\n8cVwyy1w+ulw113QqMTnkxKY9iAikhRRU+Gsa6ptpjczP/0Ujj0Wfvc7TpnTjWqvda71nHSb5aY7\nn2t8RSmB/VSJ/8tARKQGq1fDOecEA6bzzw8q5pX6gAkSOYMnIlKSfv4Zjj4ali+Hxx7je5rFHVFx\nSGA/pa5QRBqmVavgjDNg6FC49FK44QawtWf/SlbCcsVFRKIo5GpLa+9W+ZyuoRNPpH9mjfsqnX8+\nvPlmsHXFb3+bU6zZ2pTs6lJ1CeunNGgSkdhE6fTy2kGWl8Mpp8Dw4XDVVTBgQL0MmBKTUpHAtAcR\nkZJz773B1xVXwJFHxh1NcUlgP5WwcERECmzlSujTJ9h/afDgoDNraBLYGYmIlJQ33oBzzw02SB8w\nIO5oik8C+6mEhSMiUkDLlwcv444bBzfeGBSAaIiMxKU9iIhEUcjV+vdsfOinys+ZnrlW4Yavvgre\nY9pqKxg5Ems8KOs9pJoC9VNm1h54Ps2ppe6+cU3XatAkIrGJ0nnUpaMxK6M5K3mUh+nMR3D77dh5\ni+CSsjrfO4rEdJYJnMETESkJ5eVw3HGwaBG88gpsumncERWnwvdT5wNvhn4uz3aBuk0RKXktWMG/\nGUNH5sI99wSlxc8rizuseOmvv4hI/vXrB88/Dw88AHvsEXc0xa2w/dR77v5alAvUbYpIafvuO344\n4GV46RO4bxicdFLcEYmISD2or+I7Fffu0fYRHpl5I3dscw7nnTQXTipb69mJKQiUQdLji1MD2JBE\nRBqspUuDl3BffhlGjtSAqUJFrniULxERyWz2bO5/uy8vt/w/Ltrp5rijKX6F76dGmtkqM/vGzB4y\ns1bZLtBKk4iUpsWLgwHT22/DI49A9+5VTjfoGTS90yQiDUCUrSyiXFfdRnY5b3IvGzTbgB5tH2Fl\no6Y5PSebOFZ9EtM31q6f2szMpod+HuLuQ6q1WQrcBEwDlgF7AH8FXjWzPdz9q0w3V7cpIqXn66+h\nUyd4//1gQ8HDD487omTRoElEJD9Wr+YB/s12fEuHPafyRfOt4o6oNNSun1rk7u1qauDubwFvhQ5N\nM7MXgDeA84CrMl2rblNESsuXX0LHjjBvHowfD4ccEndEyaS//iIidXfddRzJB5zHYby06R/ijqa0\n1FM/5e4zzexDYO8EhCMisrZ8pB5UucenpwUDps8+g6eegvbt12qTTmLSEeqL9mkSEcnpb3+N/dTE\niXDVVdC7N7cPH84djdLfL9v+TrnGUhtFW9ghgf2UBk0iUhK24Vs44IBgb4xnnoH99os7pORSep6I\nSN3Mmwe9esGuu8KQIWAWd0SlpR77KTNrB/wWGFtTO3WbIlIr9T17VWW1qKzasz/6KFhhWrIMJk+G\nvauusBfV7Fp90KBJRKT2fvwRjjoK3OGxx6BFi7gjKj0F6qfMbATwMcF7TRWFIPoBnwH/qOladZsi\nUtzefz8YMC1fDlOmaDPBXCUs7UFEJCzfE3Pp0rRzue9abdzhzDODyqxPPgnbb5+2bfh51jV0+YTc\nn5+P37uoJw0L00/NBo4HLgBaAF8CjwH93X1RTRdq0CQitZLvP+bZOsh0bXfiKxaWPQhAR07k3RgH\nTEWVN66VJhGR2rnzThg+HAYOhD/+Me5oSleB+il3vw64rjbXanNbESlKu/MFUxlGOY04kJOZzS/i\nDql4VHRGUb5q8xiziWbmZjY4h7bNzezvZvaFmf1kZq+a2QG1e7KISAG8/DJccAF07QpXXBF3NKWt\nnvqpKGr1CDNrAWxK8CtV4e4L6hqUiEhN2vEZzzKCZTSjAycyl03iDqm41MNKk5kdD+wW4ZKhwOHA\npcBc4BzgGTPb191nFSBEEUmwbBXnoq7op2ufKUOgDTPXfJ7DnsGHL77gi47H8H3TbdlrxYN826hy\n3SFbTOGUvFzU9ncsKQnMiMg5HDNrBPyFYOOnX9bQVJnyIg1MPlLTcr7u5Zd5c4MxsPlWtJwyhY+3\n2aZWzwur1/iTooB/qc2sJXALcCHwUA7tdwN6Aae4+/2pY9MIcs8HAt0KF62ISBYrVkCPHmxYvoxO\nv5/E0iYbxx1Rw5CwEUWUMdz1wCUEndijwDcFiUhEJJOpU6FLF9h6a3juOfjVr+KOqDgVfgbvBuBd\ndx9lZlkHTQSDopXAmIoD7l5uZqOBy82smbsvL1CsIlJE8loUokv6e61ZXapwySXw8susN3o07x67\nc07PqMveTEU3CVcIxbzSBPQBJrp750IFIyLFI9uGsXkvjPDss3DEEUGlosmTYcstc35OlCITDUIB\nOyMz2x84kWipeTsB89z9x2rHZwNNgR1Sn0VE6teIEXD77XDRRXDssXFH03AU+aCpJTCuUIGIiGT0\nxBNw9NHQujVMmgSbbx53RMWvAGkPZtYUuAe40d0/iHDpJsCSNMcXh86LiNSvWbPg9NOhfXu44Ya4\no2l4ijg97z/AloUKRESSzwZUfq6P/SWAYOPA444Ldl1/9lnYpOq/n3NZXZJqajeDt5mZTQ/9PMTd\nh1Rr8xdgXeCa2gcnIpJZPookZLvWrIyW/MR0hrD91pvAmDHQuHHGrIWKz3VJvavtPlLZnllU22GE\nFflK0wBgqJkNdfdPCxWQiMgao0dDnz6w997w9NOw0UZxR9SQLXL3dplOmlkr4ArgNKCZmTULnW5m\nZhsD37n7qjSXLwHSVfSoGCEvTnNORKQgGrGakTzG1nwHj06EX2hLC4k2aGoLzAfmmNnjwDygeufn\n7j4oX8GJSAP24IPQty/sv3+QnrfBBnFHVDoKM4O3PdAcGJHm3CWprz2AdOXDZwPdzaxFtfea2gAr\ngI/yHKuISEb9mcYf+YjT6cKQ3/8+7nAapiJfaSoLfe6ToY0DGjSJlCjvn71NttSJnFIF7r0XzjgD\nOnaEceOgRYvIKQZFlYZQ34xC5IrPAg5Kc/x5goHUUDIPfiYQZDP0AB4AMLPGwLHAs6qcJyIVsqXC\nZTzeNXSPNPsmVVzXlQ8Yzws8esoRvPSvq3KKKV2/V5e0uChpdvWWKl/fCtNP1UmUQdN2BYtCRKTC\nHXfAeedB587w6KPQvHncEZWeAszgufu3wNS1HmUGMN/dp6Z+3gb4GBjo7gNT175lZmOAW82sCUEm\nw1kE/U7v/EYqIpLeDnzDcB7nP+3aMOifl0Hw90viUMwrTe4+v5CBiEj9iTIDVtsVnlrNit10U7Af\nxhFHBC/eNmuWuW0dFe3LsfkSX2dUMX/YqNrxvgQFJAYDGwNvA4e5+8z6DU9ESkWmgkAVY6EqfdN3\nl8A++8DCDdjl0aeZ1bzVWvdo7Rn22U7t95TTFhgZVrxqu2JU0n1ZsQ6awsxsUypXnua5uza6FZG6\nueYauPJK6NEDRo6EJk3ijqh01eMMnrtbtZ8/SUVQvd1PwEWpLxGR+uMOp54K770XVGlt1SruiKSY\nV5oAzGw34B/A/tWOvwic7+7v5DE2EamFuGedwmXJc+IOV18NgwcHlfLuvx9rMjh0uqzK93wpuRm5\nKBKYKy4iEptbboGHHw72YurYMe5oBBLZT+U8aDKznYGXCKojjaNyd/adgK7Ai2b2f+5e0F3bzewY\ngkIUbYHNgAXAY8C17v5dqF1L4O/AkQT7hrwKXOju/6l2v+YExSv6EKSEzAIuc/cXCvl7iAjBgOmy\ny+Dvfw9m+e65B9ZJ2F/JUpTAGTwRkVxkKzYUZW8jszLaM49JDKfx0UfDpZfWeN0c9lzrHlWfWZbl\nfPoiFHVRshOACeynooQzEFgJ7Fd9RSk1oHoh1ebo/IWX1iXAZ0A/4H/A7gT/Kz0oNWhbbcGbxxOA\nbYHzCPYA6Qc8b2a7u/v/QvcbChwOXArMBc4BnjGzfd09XWlcEckHd7jgAvjHP+Dss+H226FR9ddc\npGAS1hmJiNS3X7GUMYzlQzalzf33q/BD0iSsn4oSzgHAP9Ol4Ln7u2Z2J3Bm3iLLrKu7fx36eaqZ\nLSYoU9semAJ0A/YDOrj78wBm9ipBRaa/AOenju0G9AJOcff7U8emEayiDUzdR6So1KUcd7oZvMil\nUivKkvev4brVq4OB0j33wIUXBgUgQp1Vyc6cJUUC0x5EROpTU8oZyyM0p5yjOJb3tRdgsiSwn4oy\naFoP+LKG81+k2hRUtQFThTdT37dOfe8GfF4xYEpdt9TMJgBHkBo0pdqtBMaE2pWb2WjgcjNrpv1B\nRPJs1So47TQYNgz69QsKQGh2r34lMO1BRCQsU+W7bHsYVVSyA+CJGu5xxhkw5DO605MP2CxjHBn3\nekoXR5bzEkEC+6ko4cwFugD/zHC+S6pNHA5MfX8v9X0n4N007WYDJ5rZ+u7+fardvGo70Fe0awrs\nQOW7WyIlL1u58DorL4cTT4RRo2DAALjqqjUDpkIWsIi7OEbiJLAzEhGpN0OHwpAhXMv+/JvWcUcj\n6SSwn4ryAsGDwKFm9pCZ7WRm66S+djazkcAhwLCCRFkDM9uaIJVusrtPTx3ehOA9puoWp763zLHd\nJvmKU6TBW7ECjjsuGDBdf31QMU8rTPFZJ+KXiEgJaMdncM450KkTV3FQ3OFITRLWT0UZw90I7Akc\nBxwLrE4db0QwHnwYuCmv0WVhZusTVPIrJ9gYsb6eezpwOkAr1fKXIpRt5SXqaky6+1U59tPlwf5L\nTzzBBRzKbZf/BJdXe0ZZtGdGodWlahI4gyf5pX5KSknGTWVTMv+Nrzzehpm0/HoJY9v25pNPm9N2\n0u6s8oGR4shU+S5bRb+ootyvZDMpEthP5RyOu68CjjWzfxGU8a7Y3HYu8G93n1yA+DIys3UJKuRt\nDxxYrSLQe87RAAAgAElEQVTeEipXk8I2CZ2v+L5NDe0WpzmHuw8BhgC0a9fOo0Uu0rCsy0o44ohg\nw8A77+S2sxfGHZIksDOS/FI/JVLVOuXl3HRcP1p+/S3/x0kspkXcIUlNEthPRQ7H3ScBkwoQS87M\nrAkwFmgHdKq+9xLBe0iHpLm0DbAg9T5TRbvuZtai2ntNbYAVwEf5jVykYWnBCiYwCibND3LITzkF\nzi6LOyxJYGckIg1H1NWR92x85Q++Z433qFKMIbQy9Ocr7mSfKW/Sb1gZb53sa90jJ6EiE1VWnVLH\n87XqE+XaklpdCktgP5WwcLIzs0bASKAD0MXdX0vTbDzQ18wOdPdpqes2JNiE96FQuwnAAKAHQcly\nzKwxQfrhs6qcJ6UqW8nxqNdd6SvWbrv0Ijj8cHhlAb1XH8lDpy6AU8tK9w98sdF7SiLSUIwdy2l/\ne4CHzu7BuJO6wsnjs18j8UtYP5Vx0GRmVwMOXJPaMPbqHO7n7j4ob9Gl90+CQc41wA9mtk/o3P9S\naXrjgVeBEWZ2KZWb2xrwt1Cwb5nZGODW1OrVPOAsgtTD3gX+PURK15IlcNhhMHMmjB7NQz1VhDJR\nEjiDJyJSEHPmQN++vLXvrtxwy8VxRyO5SmA/Ze7pU53NbDXBoGldd1+R+jkbd/eCjgvN7BPSv4cE\nMMBT09hmtglB8YojgeYEg6iL3P3tavdbl2AA1gvYGHgbuMzdp+YST7t27Xz69OnZG4okiA2o/Lxm\nM9rw+UxpD5mOh+937jfQqRPMng2PPALdctsjOtsztUIFZjbD3dvV9T7tdjafPjbis1uTl2dL/VM/\nJUmWS5pdFam9l2b4w2sOtbWeaZtueOiFvPHS3mxUvpS2y3vxORuu9Zx0ceRC/VR6pdxP1TSG2w7A\nfU3ezXY1tK037r5tju0WA6ekvmpq9xNwUepLROrgF98vhIM6wYcfwrhxwWqTJE8CZ/BERPLJcIbN\nOpntf5xLh32m8Pmrz8UdkkSRwH4qYzjuPr+mn0UkfhUrPOlWi+oip9Wl6sc//xw6doT58+HJJ7GD\nXwReW+u6sEwze1lLmOdwv/qY8avL82IvE5uwXHERkXy6jJfovnAKf25zKy9t+gdAg6aik7B+Kucx\nnJlNIXi/Ke3/6szsIOAqd++Qr+BEpEgsWAAdOsDChTBxIhxwAPBi3FFJJgmcwRORhinTZFw4/a4P\nI0JXBCnfbUN7o1e/Ryc+5hqmQK9e3DbifG6zqnupp0uni5IauJYuGY5L7SWwn2oUoW17YIsazv8C\nOLBO0YhI0dmWJXDggbBoEUyalBowSaJVdEZRvkREisA2fMsoHuVdfgFDhlQdLUnxSGA/lc9HbAyo\nRLdIPapIy8uU5pYp7StTOl+22bfqduAbpvAgi79ch04nPsfMZ9ri+6x9XbbCE9mek8v5XNvkU33t\nw5F3CZzBE5HSlK5/yrS6FF6xadu18nN4T6SKVSBP7dcUvkdzVvIyY2iE051jmXvcejnHVqXfm5C9\nTVhF+9jTrktJAvupGsMxs12B3UOH/pDax6i6TYCzgTl5jE1EEqw1X/McD7IOqzno5Bd455e7xR2S\nRFDYOqciIvXNuZsn2Z0v6UIv5rJJ3AFJHSWtn8o2husOVMwLO3BG6iud74Dz8xSXSEmLOhsVpX3U\n+6W7NuvK0DvvMLXFI6xqtD7tT3yOOf9sU3NMoXtUubdm4mLhBqsSNoMnIlIXZzGdk3ib/hzI0+wY\ndzhSR0nsp7KFMwyYSrBINgW4FphUrY0D3wNz3P3nPMcnIkkzYwYccgjLG7egw0lT+GhTdU5FJ4Gd\nkYgUtyhp4jntzRQqutCGyv3+WlekwnWtTM/zlw+B9tfCoV0Y5OPAglf2w2l2EHpOxD2ZssVd0zGp\npQT2UzWGkyozPh/AzPoCL7j7vPoITKSU5Xt1ibLK85E3prX0n9foHzr22mvB3ksbb8wB84/gk9tH\nrt0mjUKurEl0blC+TpQ6QADZ9zc3s0OBy4A2QEvga+AVoMzda0zfNrP0O63DHu4+K1qsItJQbPHz\nl3DMMdCqFQwfjp8Q9W+bJFGh+qm6yHkM5+4PFDIQEUm4F1+Ezp1hiy1gyhQ+2ea+uCOSWnIzVjWO\nOoW3InuT4P3WGcCdBAOmVsDlwGtmtksO+/0NA+6pduzDaHGKSEPRePVKHp7ZE35eCs88AxtvHHdI\nkicF7KdqLWM0ZnZi6uNwd/fQzzVy9wfzEpmIJMdzz0G3bsFM3nPPwVZbxR2R1NGqdfL/hq27jwJG\nhY+Z2RvA+8AxwE1ZbvGZu7+W98BEpOCiZDC09sp0u0wpeWHv2fg1nyv2b2rLHP7+3qUcsPhFeOgh\n2GWXII4JaW9R65S8ODZTT1fJtiEqRD9VFzUN4YYRvK80mmDoVvFzTQXvHdCgSSQPcvljeRV/Ddr2\nv7byYIZUufD9Kq4Ljl+bpnWlw6wPjzOGj9iEXaZODVaaMsQBMIi173elp5/9yVjuNUIOvETnGKvq\nb6v1b1Lfy+vrgSJS+nr9byQXzLuNm7e7kIuOPz7ucCTP6rmfyklNg6aDANzX/GvnoMKHIyKJMn48\n4xjNbDbnEE5gUZoBkxQfxygvYGdkZusA6wDbANcDX1JtBSqDs8zsUmAV8BrQ391fLFigIlKU1n37\nZ+59509M2+QALmt9AxfFHZDkXaH7qdrIOGhy92k1/Swi9Sdcpjtc9CHdKlGmtmGZVpcqVnOu9BXs\nNPZ9ehw/jllsyWH05lvWrdo4dO91wjuup+5ddWWo8nm1LTmu1aX8WlXYXQNfB9qmPn8EdHD3r7Jc\nMwJ4AvicYLB1KTDFzDq5+9RCBSoi0UQuNlSxGW2GDWPpUlkFLyycwjeHUJslf4aj2vFZk5b0bPsw\n5Y2a5BRrWLb+JJwymCndr5B9kvq7QIH7qcjyEo2ZNXP35fm4l4jEb9eR73L0iU/w6b5b0+nlPnxH\ns7hDkjyqZdrDZmY2PfTzEHcfkqHtCcCGwPbAJcAkM9vf3T/JGJP7CaEfXzSzccC7wCDgD1GDFZES\ntHo19O4Nn37K0Xu/wFfNlP1QqootPa8KM/sj8HsPDX/N7GyC1IsWZvYwcJK7r8x7lCINRMZ3fMIb\nzIbeWap4l2iwNU17XXiSLdeZq768RY8TnoD27dlm/HiWrb9+1visrDLAsjTnw9Juliv1qpad0SJ3\nb5fT/d3fS3183cyeBj4hqKJ3Zs4xun9nZk8Cp0QNVEQKJ+Pf9kx9TKq4g3Wt+Xx174X2YarIZSj7\nYAD9//s0Z3I4r788EZhYcWZN2zbMTBtTlEIQuRSTSHdvrRDlT30NmsxsInAocI27X1lT2ygF0C8F\nfhd6SGvgNoJUiknAscA5kaMVkcQ4g+ncx3jo1AmeeAJCAyaR2nD3bwlS9HaIOxYRKV6HL3yC/v8d\nyH3szj1rsn9Fas/Mjgd2y7V9lPS81sBToZ+PBX4C9nb3ZWb2EHAScGuEe4o0eHWpCjd4wLWp63J4\nTsb3olKfb72Vu3kSunSh+RO7sXy9v60VU5WZtVq+myTJUF9pD2a2BcGE28iI120IdAHeKERcIlI8\ndvj+v4x4qw/TN2rLOUsPpeZCzlIqCtlPmVlL4BbgQuChXK6JMmhqCSwK/XwwMMXdl6V+ngp0jnA/\nEUmKG26Ayy+Ho46CUaNY3qzmMuRS3ApVlcjMHgdmAu8Ay4DfEHRI5aT2aDKzbYCPgYHuPjB17BKC\nlajngYUEhSAuAX4J9M57oCKSF7Wd9AsXeQjvwUSX0P0qUuR++AH2OQo2aky7GY/y87b3r/W8TKl3\nFioykY90Ok0Q1p96qJ53A/Cuu49KLfxkFWXQtIigI8PMNgD2gtDmLNAEEvbGlohk4TBwIPTvD8cf\nDw8+CJF34JZiE+SKF+S/59eAnsDFQFPgU4IJtetCRSCMoK8Ip4d/AHQn2AB3I4IB18vAqe6ulSaR\nhsodTjsN5syBiRNhm23ijkjqSQH7Kcxsf+BEIqTmQbRB06vAmWY2G/hj6tqnQ+d3AL6I8nARyW3m\nqsosWtnan6MWfHAvCzqjK6+E/gPh5JPhX/+C1O7buczg5bJLerbrsqYMSsEUIu3B3W8gmL2rqc0n\nVMutcfcJQIZXr0Wkwbr1Vhg9Gq6/PnjXVhqUQvRTZtYUuAe40d0/iHJtlEFTf4LUiYdTPz/g7nNS\nARjBLOHzUR4uIjFxh0sugZtvhtNPh7vugkZR6sJIMUtiKVcRSYYoqWv5mODKOEk37SC49FI46ihm\n/mUY8EDqRM+124bS+qrcO+PeUGVrHctlz6lMNNGXfwXcGuMvwLrANVFvnvOgyd3npCrm7QcsdfcX\nQqc3JniZamrUAEQkvUyFFqKUTU1739Wref3cvfj9nTN59fx27Hvr3ZDanHbNM3NY9cm4+pXluipt\nMpRSz/q8iM+pS7GNUuSQuJ3WRUQqbM0y6NkTdtwR7r8fbJ+4Q5J6Vst+qsatMcysFXAFcBrQzMzC\nm1A2M7ONge/cfVW66yMlC7r7YtKkULj7EoLy4yKSYI1Wr+LuJ87k9zNn8uKlv+fZGw5iX1MVooan\ncLniIiJ10ZRyxvIw/PQTPP44bLhh3CFJLArST20PNAdGpDl3SeprD2BWuosjR2Nm/w84IvVggLnA\nOHf/OOq9RBqqqCsfVd79Ccl2bfh846vLuW/cKZz4znC48kr+MHAgfzBLG0sui1kZn51aMcpX2kNt\n2ubz2lKk9DwRyWRNP5Ah/S2c8hbeSDa8GW3aDWtDx+aENqMNP6e1d+Pqs65ln7s/46jvevJ469Gp\nmOaEbhS0n+EPrznSNjT3l/HvfZrfITxnWNcsDsmvAvVTs4CD0hx/nmAgNZRgX8G0Ig2azGwQwa7u\n1X+Lv5nZte5+dZT7iUg9WbmSkY/14djZD3PlQYMYPKjGTa+lAdCgSUSS5qj7xnHc3Y9y7+Un8/j1\nqpTX0OW7n0pttj61+vGgNAPz3X2tc2E5D5rM7BSCPMBXgL8Bs1OndgIuBa4ws7nuPizXe4pIPVi+\nHI49lmNnj+OSTn/npv0uYXDcMUmstNIkItlW/XNZoa+yxxKVn/2MyvSIsnuC7wO61LwLe1s+58pT\n72MS23Pm9b/O+i5v265rrz4BWNfKo+FVsXRFIZSFkD+V/x1t2TYf90tiPxVlpekc4HWgvbuXh45/\nbGZPAS8C5wHD8heeSPHIJR0t3fmrQtudDSK0qWya4grVr80WRzPKeZSHOZz/ci5/5J+TvodJZVzV\nf8WaNv25rvLaAVnuHS5OESrikO53zxSnOqn41cOmgSIiOduUH3mUh1nI+hzP0axG1Vwbuvrsp9w9\np5e7owyaWgP9qg2YKh5WbmajIfSvLxGJ1bqsZByj6chcTqcL95KXyR8pESoEISJJsA6rGc1YtuB7\n9uMUvqFF3CFJQiStn4oSzQpg/RrOb5BqI9Ig1XYFZbA1XfN5UIbshYwrV+lWo8rKWH/5dzzxUBf2\nnz+PvhzBg+xepUl4RctoWv0OVX+Xf1ZOwHj/9AGm+93rUiJcCiuJaQ8iUs8y7G2UTi5/z8NpcW3u\n7rbm84i7+wAwIHQ+fL8hly3g4Bvm8df7+zOzb/ZY1qT+3R2OKX18mTJA6qMfamhbXVQWEBkwIy/3\nS2A/FWX9803gDDPbovoJM/sFcDpB+p6IxGjDn5fyzPBD2W/By/TmqLUGTCIVnVGULxGRfDuKOfzp\nhgcYfebR/PvkbtkvkAYjif1UlJWmQcBzwHtmNhSoeANvJ6AvwUpT7/yGJ1ICwhvFpt4DyjRrF+W9\nqPC917RdvBgOPRQWvg1jH2bM0e+kjSN8vyu9coF48IB0caRfXcr4Llaa+MMa2uxbUumdJhGJ0+/4\nmmGMY9Y+u3DdrZfEHY4kUNL6qZwHTe7+gpkdBdwBXFzt9ALgJHd/MZ/BiUgEX38NnTrBe+/BY49B\nly7AO1kvk4bHtbmtSIMXriYXtmZiK5y+l8M+Tf2fqHxvtuzMUJu7U9laoX2aNmA5jzOGH2nC4a8d\nzOfNJwLBPk1rxVHt+fZZ6nMuk4xZUhALOYmnScG6SWI/FSkad59gZk8CbYHtUofnAjPdfXW+gxOR\nHH35JXTsCHPnwoQJcMghcUckIiKShjOMf7MDi+nIiXzOhnEHJJKTyEO41ODozdSXSIOWyyxVuDR3\nurbhMt6ZUujCqqTTWVO2YhkceCB89hk8/TS0b581JjYLP7Qy/a5i/6ZcUusgewGLdDT7Fr8kvmAr\nIvmTS9+UrbhD5jTyUNvQfkwzvXWoTc81n2ekCkHs6am3Oq6/Hvq9zwUcygtsW2U1KLzzkhHeAyok\ntWKVsS8Jry49EW6zdnv1R8mVxH4q8qDJzLYCugLbpw7NBZ5w98/yGZiIZNeKb5nCg/BFOTzzDOy3\nX9whSZFIWmckIg3ApElwxRWMYmdu4/dxRyMJl7R+KtKgycyuAq4EmlQ7dbuZXePuA9JcJtLg5LJK\nVMH7h8p/p7+sisEDgvbbL/6Yt1vtSbNlK9j7mGm8OXlvmJz5uiv7hwo3nFPz0pDKhZc2bW4rIvXu\nk0/g+OOhTRtOe7crkNN+otJAJbGfynnQZGbnAgMI0vJuoWr1vAuBq83sG3e/I+9RikgVv1n0AVMe\n6ECTpiu5f8rxvDl+77hDkiKSxBdsRSR/apuSB1X3W0p3viyUnzfz7sqUvLZdK5PrWvvM0PEymq/6\niZde2Z//90M57XZ9nB98h7QxVUn9yxBTuFhE2t+lSoGLsgytJOmS2E9FieY84A1gf3cvDx1/x8zG\nAi+n2mjQJCWp4g97pg3ysm46C5Aq0x3e0HZwhj/q4XuHy3s/fva7TH7wYAzn99+czOw9f0GVjiH0\n7CqrS/+8rjLWc9fe0DYXKhdeOpKW9iAiJcqdO/9zNm2XzqTLXhP4eL0dsl8jQvL6qSib27YCRlUb\nMAHg7iuBkak2IlIgW771JVOHtWe1NeLAk6cxm1/EHZIUoSRuGigipemMBffQ93/DKNuxP09u0SXu\ncKRIJLGfirLStIBgA9tMNki1EZEC2PrNzznpkDF83WRzOpw0hY831Wyd1E4SqxKJSM1y2fw8XQZA\n1AyByvS29G0HdKl8J7ZKi1ClujkVZ159lRX/OYcn2ZGBv7k6/fNySSWsUmFvz7TtpbQksZ+KMmi6\nA/iLmQ119y/CJ8xsa+BM4Pp8BieSJNnKsIaF0+IqCjdAZVpexpLjIeHj/7fgcJ4e8Ue+aLElHfpO\nYX7LbXOKqcqzqfzsoToQ6dIK05VJl9KStBdsRaTELFwIxxzDp2xEH7rjFiW5SSR5/VSUQdNSYCHw\nvpmNAN5PHW8N9AY+BJaZ2Ynhi9z9wXwEWkhm9muC4hadCMq5TAYucHetnEnsDpw3lSce6sLnG2xF\nh5Om8NlGv4o7JClyhXrB1swOBS4D2gAtga+BV4Ayd5+T5drmwCCgD7AxMAu4zN1fyHugIlJYK1dC\nz56wZAndOYlvWTfuiKTIFHshiGGhz2elOd+2WhsIds1M9KDJzFoAU4DlwEkEMQ8GnjezXd39hzjj\nk/qRy+pRxapOprSI6pvOVl4Xek5ZmueVZfgMHMzHjGM082jJwYu78uUt/6oaVP+14860SpRpRUsF\nHRqeAqY9bALMAO4kGDC1Ai4HXjOzXdx9fg3XDgUOBy4l2P/vHOAZM9vX3WcVIliRYpJxA/Usf8Nz\n+Rsfrk5XkZ6XMa0vlIYXrnbXn8pO5pbfLuXCeS/Qa4+R/OetD9e+rmv6mKpWvgtJ88xC9l35KHqk\nwkl1U+zpeQcVLIp4/Ylgo97fuvtHAGb2DvBf4Azg5hhjkwasMx/yKA/zPpvRiRNYxHpxhyQlpBCd\nkbuPAkaFj5nZGwSZCccAN6W7zsx2A3oBp7j7/alj04DZwECg5hrDIpIYOwPHzLuVW7f7M6O27gVv\nlcUdkhSpoh00ufu0QgYSo27AaxUDJgB3n2dmLwNHoEFTg5DTTFxq1ii8ouRe+Z5QuCy431E542YD\n0tw7tKIUXhmy1MuzR773OGPGDOIdtuAQTmBJ2Q1p26eLP6dVrDQrVHWhGbXiUs+bBn6T+r5W5dWQ\nbsBKYEzFAXcvN7PRwOVm1szdlxcwRpEGJ1OhhTWrTqFjbajcdynz3/gyeOcd2GcfvmsHBzz3DDOa\ntGFPaszMrbLKNZM2oTM908ZXH/LRj6kvrJui3ty2hO0EjEtzfDbQo55jEaHnu2MY+Whv3mQrDqM3\ny2ged0hSYgqdK25m6wDrANsQFAj6kmorUNXsBMxz9x+rHZ8NNAV2SH0WkaT69ls46iho2ZJ5D68H\nTSz7NSIZFPs7TaVqE2BJmuOLCV5kFqk3J8x6kPvH9eXlX+/H4Qv243uaxR2SlKgCpz28TvCeK8BH\nQAd3/6qG9jX9Ha44LyJJtXo19OkDCxbAtGmU//LUuCOSElC06XlSycxOB04HaNVK+/kWq1yKP4St\nKe8dKqgwKJQqFy7vTeh4qA7EmvS7tMUa7r2XYf8+nSlsxxEL9udHQsUkwil84YIOFSXCM70gHL4u\n1KS26XSZrlMaQnGp5Qu2m5nZ9NDPQ9x9SIa2JwAbErwvegkwycz2d/dPIgcrtaJ+qnhF/fucrn34\nWGuvfCUw0x5H4QIMFdfO8IfXHOvDiLTPq7j32YOGcO6TT3I2nbnr/56hSmpdRb+XKY08lHrXtmtl\nKl+mrTHS/Y7qg0pPsReCKFVLSL+ilGnmk9Q/FIYAtGvXztO1EYnkn/+Ec89lIjtwND35mSZxRyQl\nrhad0SJ3b5dLQ3d/L/XxdTN7GviEoIremRkuWUKQylddxQrT4jTnpAbqp6S+HPDki5xbdg/3szt3\nkdOfCJGcaNCUPLMJ8umrawNZ3l6UopDLbFSmzWbTrQiFN6618OpSlUILGYJJtalYcQLwDW6Giy+G\nI46g85gx/NSs2VpxZPwdUgUdMq2a5XsmTrN5EpW7f2tmHxG8l5TJbKC7mbWo9l5TG2AFQYqfiCRM\nq48+5YY+VzF7z99x9szOBFtdipQmDZpgPHCjmW3v7nMBzGxbYD+CmVGRgun3wrUw5Qro0QNGjoQm\nWmGSwqvPqkRmtgXwO2BkDc0mAAMIiu88kLquMXAs8Kwq50lDlWlCLEp69Hs2vvJ+XSrT88Lpd4Qm\n8irS5fqQPq2v4h4tyn/gbztuTznlHD7zUH7uck2NcdRlEi9de03ilTZVz0ume4FzgXFmdiXBKyiD\ngE+Be+IMTPIjp3LcYaHjVfqriveH+leuLg0OPydUZvwq+qV/ZmVQDHi+P1e/MIjh7ErfR37Hqkdq\n6HAyxJquDPogrl3rfPXP6mwatkJVJTKzx4GZwDvAMuA3wIUE5cZvSrXZBvgYGOjuAwHc/S0zGwPc\namZNgHkEm6hvB/TOe6AiUjfu3PvOn9iJrzmM3sxn47gjkhJTVNXzzGxKLe7n7t6xDvHUO3f/wcw6\nALcAwwnWlp8DLnD372MNTkqUc/3ky7ns5b/xrz1O5Yy3tmI1jeIOShqYAuWKv0bwBvjFBKXCPwWm\nAteFikAYQTny6v+j7wtcQzAXsTHwNnCYu89EpAHJ96RWpvuZhfdBqvw4Y0KwV1Lb0HmjcrXKvQxu\n+wc8OQquvZZJ/fql7pf+OdniyEQTfVJM7zRtT9XCXwDrAZulPn+b+l4xvbAIKMpBhrsvAI6OOw5p\nCJxbmcifX36DO9udxbmd78DfGhh3UNLAFKoqkbvfANyQpc0npHnxwd1/Ai5KfYlIUk2bFryH2707\nXK63GKQwiqp6nrtvG/7ZzLYHngduA25w9y9Tx39J8O7PkUBRrTJJwxN5tiqcFlfxuX/lsSolva3y\nBydcTSI1C7fa2WqdSZzJDLjgAs6++WbONsMapXlG9bg3q/w3Zjj1z/3adM1D59PfL0yzeQ1PEnPF\nRST5tmIZ9OwJO+wAw4aBqfCDFEYS+6koyYK3AK+4+4Xhg6nB0wWpwdMtBIMnEQmxVas58rSn2JP/\ncB370e/mm9XZSKySlisuIjWzrpWfq+yrlOZ4eG+m8HmeKFvzMVwIom3XyuN7pgoHtw5lxs5hT1i+\nHNq3h3d/hKlTYcMNMwcb2nspHGs2VX4XTeI1eEnrp6JE0x64rIbzU4Hr6xKMSD6ly6/OVBQiXMTB\nPf2WJuEy4WmFC0gsCt27vBxOOgke+g+UldHv6qu5yq4IXVe5iW3GWAeEnh2Ke1Aq1FxWi6JsTKvV\np9KWxLQHEUm4Cy+E116DsWOhdeu4o5ESl8R+KsqgyYGa/l+Sbq8jkQatSfkKOK4XPPooXHed8r8l\nEZLYGYlIgg0bBnfdBX/5CxytV8Cl8JLYT0UZND0LnGVmM4DhnpqONzMDTgTOAP6d/xBFaqdihSS8\nSSz/DKXElVWuKIVXhsKvI4VVbGprln5lqH/owlXej3WWl3Ncj8dhwkdcwKHc1u9nPDVmCpcFHxx6\ndJXVqiyViKKKsmKk1aXSl7TOSESyCKXWZcrubpPaW6nKvkqh81UyGEIpeWnvnUqx22PpTHjjTOjY\nEa6pujVGGzIUt8wh1nTU90hY0vqpKIOmi4C9gPuB683sv6njOwJbEJSWVdUjEaDxTyvp1f1Rdnxm\nHmfRmbvZK+6QRNZI4gu2IpI8m65YxGPTj4IttoBRo6Bxst4xkdKVxH4q5//1u/v/zGx3gveajgD2\nTp2aCwwD/ubu32a4XKTBaAIcf/gjbDt1Po8P7czdp2rAJMmSxE0DRSRZGvkqRs08nl8u/xIefQk2\n3zzukKQBSWI/FSkad18K/DX1JVJwUQsSpE1pC5fxPidU5CHDvavcI3Tt4AxpeRUGlDkb/LyMJx86\nnG2ef5kT6c7IU3dNH2eGFMBMv+NVof/LhVP70l2nIg6Si6SlPYhI7rIV/AlvRhuupEcobS+cQpfO\noCfb04mXOIVu3Neu3VrPAKpUySP0zHSxZqrip/5LMklaP5WsIZxIEdv4pyVMHHEYe34xk+M4mrGq\njUbMLhoAACAASURBVCIJlcQXbEUkObrzHn/lJe6mLfezB/fFHZA0OEnspyINmszs1wSvyR8C/AI4\nzN2nmNnmBLvA3+Xub+Y/TGkIKmaYMpXDrrI6k2kT2DQzVuENaDM+O7wXbaj8OOeEnpPa1LZK24p7\nf/MNMzdrw858xTH0YJyPXtPmqjQLsxVFJQAGD7g2bduqK1uVnwelr4heGZNm5ySLJOaKi5SyfKyg\nVC3iEDqeZR+kcFGIjML7Kv39fdhrL97eaWfumnYHrZs1zTH+TMdTMqwuiaSTxH4q50GTmW0HvAY0\nT33fsuKcu39tZu2A0wANmqRh+eorOPhg2vA1R3AcE9kx7ohEskparriIxG/98u+ge3dYd10uGPs3\nVjarOS1dpJCS1k9FieYaYDWwM/AT8FW1808BXatfJFKTKGW1wytG4cuyzVhF2dQ1aF/5ID8nS1Cf\nfx6UYZ0/n+aTn+Hpjh2De1RZFavsdAanHtm/7LpQHOF3lEKlyEOzdvmYlVOuuFRIYtqDiMTMnWGz\nToav/wuTJ7PwVxvGHZE0YEnsp6IMmg4Gbnf3T81s0zTn5wO/yk9YIsn3q6WfwoEd4MsvYeJEOOCA\nuEMSEZEEqu1EVaaiCzMmtFnzuQ0janxOeC+l92x85rY3/A2efAxuugnat2dO+JxnT/HLNjGXy38G\nmtCTJIsyaNoQ+KKG800j3k+kaG27ZB5THugAvgQmTYJ99ok7JJGcJXEGT0RiNHky/PWvcOyxcOGF\ncUcjksh+Ksog51OosRzYPsBHdQtHGpqMpb7THKsyA5WhEERaGdrmUlgiXSw7nNebKQ90YL0VP8BL\nz0Hbtmu1rVLoIZRyV5FiaGWVKYADMpQ4D6tSIGLA2vfLhWbwJCxpL9iKSEzmz4fjjoM2bWDoUDCL\nOyIRoDD9lJkdSrDnbBugJfA18ApQ5u5zaro2yqDpMeBMMxtK5YqTpwI4GugBRPgnnEjxac3XPHf/\nATReXc5BJz/P2213izskkciSuGmgiATC6XThya7w8bbWM9SmMnVuTVW9UKW6Gf5w5XVUXteGmTT9\neTkjjj6VXy9dSbtdHuOj49Zbc22mibZc0v30Dq3UVQH7qU2AGcCdBAOmVsDlwGtmtou7z890YdRC\nEF2A14EXCAZMl5vZtcDewCzgplqFL0JoA7wcikNUKQqRrX1o9SZjAYn+lZ/Dqzrhe+/CQibzIKu+\nb8SBnMh7dz+O/TLDoClU/CFdFdYrfcWaz+k2q60eU9ggTU1IHSUx7UFE6pk7V599PTvPeI+ue43n\no/VV+VWSo1D9lLuPAkaFj5nZG8D7wDHUMJbJedDk7svMbF9gENALMKAT8C3BaO0Kd/85cvQiRWAP\nvmASw/mJxnTgJP5LulooIsVDgyaRZArvq5SpEIRnKMzQekKwCvReKMOubdfKjCMP7/N3zz1w/3i4\n+momDAgXPy5b69nhScYq8VG50hSWds9ErURJRPXYT32T+l5eU6NI617uvgz4M/Dn1Ia2Bnzt7lm2\n2xSpu5zeb0rzTlDUP8hVNpUtK2Pv/73OM8MP5dvlTenAScyjZY3Pq0nl75D7ZrW53E+djkShlSaR\nBu611+C88+CPf4T+Sl+Q5Cl0P2Vm6wDrANsA1wNfUm0FqrqcBk1mtj4wHhjp7kMh2NC2TtGKFIH9\n57/IUyM7s/D/t3ff8VJU5x/HP4+KvaCiRomKxti7xBYTEQsaxYiCDexRYwwmKsaAqJRgxxr5SVGJ\nLQqKCjYUEGxgxBoRNTGgYgWxo0h5fn+cuTLs3Xrv7p3Zvd/36zWvvTtzZvbZvdx9OGXOWWU92s/v\nyPuskXRIIo3maCIIkWbrk0+gc2fYcEO44w5YZpmkIxKppwny1PNA3Uxe/wXau3vmGrRLKarS5O7f\nmNkvgDsbF59IYbkXne2T9eecvT0l9gLVe/0JE6DjgbDpRqw2fjzvtx5SL75cvV+lLNrbGOphkobR\nRBAiaVDK0LWlcyBZy0zvWDd0LvuwORYuDNOKz50LkyfDWmvlfM1icnFD115S7pLCGpSnWpnZ1Njz\nIe4+JEfZ4wjLKW0K9ACeMLO93H1mrouXEs0rwFYllBepXo89Bp06wWabhfUr1lsv6YhEyqYSwx7M\nrDPQjdBy1wp4jzDr6iXu/nWBc3MNUt3J3V8pa6Aizdn558OkSXD77bCDZn+V9Gpgnprj7m2Lur77\n9OjH583sUWAmYRa93+c6p5RK08XA/Wb2sLs/WcJ5ItVl9Gjo0iWsWfHEE9CqVdIRiZRdBcaK9wA+\nAHoCs4AdCXeU72Nme7r74gLnDwcGZ+x7u8wxijRbR31wNzx0NZx1FnTrlnQ4IgU11b237v6Fmf0X\n2CxfuVIqTd0ILYfjzOxVQjKbV/91/ZSSIpVmJ+fQtWg4Xc4FW2PD7eJl4lOE9784x/Td2eLoW3/f\nEdPu5d77j4GddoKxY2HNNeufV8TQiZzDGvrkPy7SFByrxFjxjhn3uk40s7nAP4B2wIQC53/g7lPK\nHZRIrVgq33TMXQ5gKz/0x5/fAPj3v2H3U2CvveCqq4q6Rq6cpvwlTaFCeSorM1sP2JICtyGVUmk6\nMfbzjtGWyQFVmqQqHfPaXdx+/3Gw5x7wyCOw+upJhyRSEZVYNDDH5EAvRI+ty/piIlK8L76Aww+H\nNdaAESOgRYukIxIpqFKL25rZ/cBLwGvAV8DmwNmE6cbzrjdbyjpNml5Fyi5bi1XO1q0cPVDxxWFL\nuUE1fr2T7LfczGgm0YaOz/6ab9e4Ouc1imlli/diZYtba1RI0ppo2MPe0eP0vKWCM8zsPGARMAW4\n2N2frlhkIs2ALV4Mxx0H774LEyfC+usnHZJI0SqUp6YARwLnEtZ/eR+YCFyabxIIKH7K8RWA3YCP\n3P0/jYlUJHUGD+ZWRjOWn9GJo/gOtcJJbWuKdZrMrDXQDxjn7lMLFL8DeAj4kLBmxnnABDPb390n\nVjRQkTIqx8xy8UVsi5uJtX6Zuln0Lny7H7z9EGdu+3cGXbonPiZW6KFirl0/jvjQv+m2ZJY+NQBK\nOVUqT7n75cDlDTm32J6mRcB4Qq1MlSYpWTl6Vgr13hRz7cwEdBZTuI6xcMghdBg5knkrrlg4jgqO\n81YPlDQFx1i0uORkVPRUrtHafg8ShjucVDAe9+NiT582sweB14H+wK9KDVRE4KBPHqHP2334x0+P\nZ9DGf0g6HJGSNDBPVVSx6zQtNLOPAStYWKRKnMezXME47mMrjrjvPlh++aRDEmkaDgsXVmYqVzNb\nCRhDWPtib3efVXJ47l+b2cPAyaWeKxLX1A1Rpa5tlG2dpnhvUHw9pngPVK5rv+gjAOjSfgx3vtKV\nV1ffgd/P+inM6lvveoXWFsz5XpaaQGJJT1Mpn7UaCKWghuWpiirlPqWRwJFmpnubpMo5FzKJKxjH\nP9mWo+isCpM0K+7GooXLlbQVw8xaAPcCbYHfuPu/K/k+RKQ+m7eYUVMPxzEObzuK7zXkXKpQpfJU\nY5TyCsOAfQgr5l5LGKaXOeU47v5emWKTGpVrjHa2VciLGZJXaMx3b/9hyTUWD4DeveGSiQxnB07h\nUBZntB0Uii+Xhg4fXOo8tbhJlYoa1O4E2gOHNGb6cDNbHTgE+FeZwhNpHtzZ+NSPaPn11xy066PM\nXHmTpCMSqRmlVJpeJ0wpboQ1N3JJV1+aSB136NEDrr4aTj2Vk4euj2vEqTRDoQWv7F/VNwJdgAHA\nt2a2e+zYLHefZWYbA+8A/dy9H4CZ9SAsKPgk8AlhIogewE+AruUOUpqXSjVElWt4Wd25xU34sMRW\nY1768efpsTS28w1nwF1/ohftefxfk4HJWV8vVxzxWHKWjU8mkWUSimKogVAKqVCeapRSKk39CJUm\nkZyKSSQ5x0lHPS7xXpr4z7l6cgqNy+7PJbB4cVgF/cYboXt3uO46Fg/JUWGKLaK71M+FxMteXPx5\nS71HjfOWpuBUIhkdFD1eEG1xfQn/uzJCw1q8e/ctoBPQGViDsG7Gs8Ap7q6eJpEi7cW7cO4A+O1v\nuezBHZIOR6RxKpOnGqWUdZr6VDAOkcpZvBhOPx2GDQs9TVdckXF3rUjz4m4sXFDeZOTubYooM5OM\nCYXcfQxh4ggRaaD1+ZqRjIRNN4V//ANveU3SIYk0SiXyVGNV/q4paVZK6fqvV76up+bi7GWXkqMn\np97rL1wIJ54It98e7mXq169whSnWY1TS4rtlaFdQ24Q0DWPxIn39izRUyd/VOWa+K3TtrYkPw+sT\n+zlWfn4vaNcOXoOt396P6S2vWer1lp6NL7Y/npdjM+KVkvdEKid9eaqkmfDMbDUzu8jMnjGz/5jZ\nHtH+VtH+LSsTpkgDLFgA3bqFClP//mFTD5NIGGi9cNnSNhFJp7PPhsmT4dZbmc46SUcjUh4pzFNF\nV+HMbB3gGcLaG/+NHlcCcPc5ZnYC0BI4pwJxipRm/nw4+mh44AG48sowLE9EAjdVhERqwPG8AoMe\nhPPOgy5dgGlJhyRSHinMU6X0e/2NMJvRbsB7wKcZxx8E9i1TXFKlGjMRRN2wuFxTcMevnW+hwBVY\nyH2M4GD+Q3cO5IZYhSl+7VyTPBQaelDq4oUiqePAQvW6ipRDMctUeI679grNmvcGO8cuuPPSB196\nCX55OeO/34QOV67Ioiuzv15ReTlLeeUxSVQK81Qpw/MOAQa5+0tkn0Xvf8CGZYlKpIFWYgFj+CcH\n8R9O4xD+zm5JhySSTgtL3EQkPT77DA4/HNZZh6M5gkWl3W0hUh1SlqdK6WlqRRiWl8tiYMXGhSPV\nrtSFaeN6X9wLgL/1vaS014laxVbhB+bt/Rw8PRNuGc6QE05gSOZ58TjiE070JaulWgGjnqli3otI\nqjmqCImUSamjD7L2LuWYKCI+QcOLY7YOPyxydj52I/joI3jmGeb0+8WSQg/1yfvaxchWXr1O0uRS\nmKdKqTR9DPwsz/GdCMP2RJrc6nzPI9wFz3wId9wBxxyTdEgi6ZXCZCQixdngotnw+JswdCj84heF\nTxCpRinMU6VUmh4BTjGzG4Af4gfMbDfgeODaMsYmKVFKi1UxZXOV6U/oYepf4mKva/IdY7mDHfgY\nRowMQxZo+LjshrbQqSVOqoYDC5IOQkRKtcYDX/OTSz6DU0+F3/0u6XBEKieFeaqUSlNf4FDgZWA0\n4e2cYGanAocDHwKXlz3CGDPbHOhOmHBiI+Br4AXgQnd/NUv5U4FzgU2AmcA17n5TlnKHARcDWwGf\nAEOBS919UWXeiZTN7NmM5za2ZjaHcxQPRRUmEcnDAX27STOQxgl6Cq2DlGtljGOsPS8wlOdpza+H\nrssPQ/vUu17duUWtjdhAafxMpQalME8Vfeegu38M7A48D5xMWNX9OOBI4HHgV+4+txJBxhwAtAeG\nEypwfwDWAaaY2S7xglGFaTBwH3AgMBIYZGZnZJTrEJV5ATgIuA7oDRS+sUaS9fHHsM8+bMkcOnIM\nD7N50hGJVI+U3WArIrmtynzu5x6+Zzk604UfSmrzFqlSKctTOf/qzGwjYLa7f1e3z93fB35rZqsD\nWxAqTv9tgspSnbuBG939x9n7zGwCoRfpT4QhgpjZcsAA4HZ3vyAq+qSZbQD0N7Nh7l7X6XcZ8Iy7\nnxYrtyrQ28yuiSqLzVpDW6waM1Sv0Hmt7RwmcBs/5StWmfA4j++zT9HnZnvthpZRK5tUpRSOFReR\nXJxbeZAt+Iz9OI5ZrJF0QCKVl8I8la+pYgahJ+ku+LFyMsDdx7v7V4SemSbl7nOy7PvSzN4GWsd2\n70Hogbojo/jtwEnAXoTK0YbAjsBpWcr1JfQ83Vqe6KVs3n2XpxjOOnxLB7rxTJYKk4jkkcJkJFIJ\nDW3cK8sQtBwz4mWT9zWuvBL+Mp1z2Z+JbFLeazeAGgulSaQwT+WrNC0AWsSetwOGVTSaBjCztYBt\nWbpys030+HpG8bqlsrcGnsxVzt1nmNm8qFxVK/TFX2piKMfCr6VcL/MamzKXCdzGz1oajH2aZ3bd\ntejzi31tjdeWmpfCZCQiWYwfD3/9Kxx5JFeP2DLpaESaTgrzVKGepkPN7AF3/zLal21R26TdQBgm\nGJ+5b63o8fOMsnMzjucqV7dvrSz7MbPTiHqnNtpooxLDlYbanDmM5zZWZCGMfwZ23rnwSSIizZDy\nVH3ZZlTN1TDW0AazrXlpyTXGNDJHvfces/c7lE9Zm91G/IzwX526a2c/pdSGyGznNXTmWZFal6/S\ndAPwd+AwC9OxOHCHmWUOeYtzdy/67kQz2w94ooiik9y9XZbzewLHAqe4e76Fd8vK3YdAWDe1bdu2\naaxI/qihPUO5lLpgbTleE4Bp03hrvXvBV4Jx42C77Yo+tdy9aSJVL4UteFJe1ZSnJIvvv4cjjmB5\nFtGJo/iW5ZOOSKRppTBP5azguPsgM3sD2B9YHzgBeAb4Xxlf/znCNN+FzMvcYWa/J8xw19vdb8k4\nXNdztCbwUWx/Xc/R3CzlMq0ZKydJeuUV2H9/aNECJkyALTVEQaTRUpaMRCTiDmeeCVOnchxH8x/W\nTjoikWSkLE/l7RVy94nARAAzOxEY7O53levF3X0e8Gap55nZccAgYKC7D8hSpO7epW1YutJUd4/S\nG1nKTY5dvw2wcqycJOWFF6BDB1h11VBh2myzpCMSqX4pXDRQpNKaYhTBGywZklfMJBPZjjN0KNxy\nC/Tuzej+/RsURzEjLMo9NFGkrFKYp0qZ6H8TYHalAimWmXUiTPowzN175Cg2GZgDdAXGxfZ3I/Qe\nPQvg7u+Z2atRuWEZ5RYAj5Y3+uqXa0he3bC9+PGlhvKVMEHEj2Wfe44v2x/EZyutTfvDJzBzszYF\nr1HKtOUizVYKFw0UEeD556F7dzjwQOjTJ+loRJKTwjxVdKXJ3d+tZCDFMLNfA/8EXgWGm9nuscPz\n3f1lAHdfYGYXEhaz/YBQcWpPWJS3u7v/EDuvF/CQmQ2Orr0TYXHb67RGU4ImTYKDD+aTVTag/QkT\n+GCNnyYdkUjtSOFYcZFm75NP4IgjoHVruPNOWHbZpCMSSU4K81RJS0qb2dFAd+DnkHWQbUkTQTRA\ne2AFYGei3qKYd4E2sUBuMjMHzgXOA94D/ujugzICfsTMOgMXAycCnxDulco27K9ZKqabv/fFvaKy\nyxcsW3D68SeegN/+Ftq0YfPx45m1/voNiklEckhhMhJJk3LkmJLWfVq4EI4+Gj77DCZPhrWyTt67\n5HodY68Tm0mvnDPfKc9KolKYp0qZ6e484DLgM2BK9NikPPzV9imh/GBgcBHlRgGjGhyYlM8jj8Dh\nh8MWW4TK07rrJh2RSO1JYTISadb++leYOBFuvx123DHpaESSl8I8VUqv0JnA88C+7v5dheKRFCqu\nx2j5Esrm8MADcOSRTF3Qig6vdWDueoNKnxK90A22IhKUORlFPfbdgF2AVoTe/VHAJe7+dYFzVwT6\nR+e3BF4Bznf3p8obpUgK3XMPDBwIf/wjdOuWdDQi6VHFlaafAFeowiSVcCSvQ+e/wS9+wX5T9uZL\nVkw6JJHaVZkWvB7AB0BPYBawI2FkwD5mtqe7L85z7s3AwYSh1P8jNNKNNbM93P2VskcqEsk5BO2Q\nPplFlypfamNczvKvvw6nnMIza/6S9v8byIKOuReuXep68SF5HesfL2ZonSZRklSr8p6m/xJaAEXK\nqhuvMpwHYc+94OGH+XL1gUmHJFLbKpOMOrp7fIbViWY2F/gH0A6YkO0kM9uBsEj5ye5+a7RvEmFJ\niH7AoWWPVCQNvvgiDEdfbTW6bDuSBctoAVuRH1V5pWkg0NvMrnf3byoVkKTPUlOHx6YUz9YKVUpZ\nAIYNg9P6Qfv2rDJ+V+atPrDBrWI5Y2rEzay53o9IVavA+hcZFaY6L0SPrfOcemgUzT2xay00s7uB\nv5rZCu4+v3yRiiyRM5fk6O0pW45ZvBiOPx5mzIAnn+SjvepPeFT06zzUgNcvsaxIk6vydZoWAZ8C\nb5rZLcAMssyg7u63lSk2qXU33hjGcB90ENx3H/NWvjzpiESah6Zb/2Lv6HF6njLbADOixc7jphFu\nltyMJQuRi9SGSy6BMWPghhtgr72SjkYkfap5nSZgeOzn3jnKOKBKUxUoNC671JazbIvb5r3e1VfD\nueeGqcXvuQdWWKHg6zR0UojGtKYttVhvGadyFUlchYc9mFlrwvC6ce4+NU/RtYDPs+yfGzsuUjse\nfRQuuihM+nDmmUlHI5JeVTw8b5+KRSHNyyWXwAUXQJcuYQG/Fi2SjkikeWnYWPFWZhav/Axx9yHZ\nCprZqsCD0auc1JAQRZpawTUEcyhmPaa6/ZvwOf9reRtsvz0MHgxmeeOIX6OUYekiVa+a72ly90mV\nDETKp6H3/pRyPPN1ftwX21Xvy94d+vQJFaauXWH4cKzF3+qVL9eCeuVOJEpMUjMalozmuHvbQoXM\nbCVgDLApsLe7zypwyufAxln21/Uwzc1yTKTqrMQCRnFPqCiNGgUrr5x0SCLpVc2VJpFGcYeePeHy\ny+Hkk2HIEFh22aSjEmmeKnSDrZm1AO4F2gL7u/u/izhtGtDJzFbOuK9pa+AHwsytIlXOGcIYtucT\nuOtR2HTTpAMSSbdqmgjCzI6Pfrzd3T32PC9NBCH1uMPZZ8N118EZZ8Df/w7LLJN0VCJSRma2DHAn\n0B44xN2nFHnqGKAv0IUwPTlmthxwFPC4Zs6TYpRjhEI5RhPkHN1xfSs469/Qvz8ceGC94+VYV0lE\nKitfT9NwQj3vbkJrX93z+gNwl9BEEClQ7i/TUr6oM8dwG86NPMwZvMg17MY5/7cOPmiZrOWLfY1y\nxVrMeUpSUpMqMyvRjYSKzwDgWzPbPXZslrvPMrONgXeAfu7eD8DdXzaze4Bro56qGcAZwCZA17JH\nKdLUnnkGzjkHDj0UevVKOhqR6lBls+ftA+DuP8SfixRrGRYzlDGczCtcyi/pxb7kr3OLSJMp/1jx\ng6LHC6Itri/Qh/AFsCyQ2dV8EqGy9TfCIuqvAge6+0tlj1JqUpKNWvka3dbna15kCOv/fBO47bac\noyyKaaxTw500O9VyT1PmxA+aCKL6ldJrUmrPS71JIRYuZNGx78Bdr0CfPvS86CJ6RrMEFbpGuRe3\nLYZmJZJmpQI32Lp7myLKzCRLy4m7fwecE20iNaEFixjJSFZjfpj4YY01kg5JpHpoIghpFhYsgGOP\nhXvvDdOL9+yZdEQiEpfCG2xFas1AxvJL3udIOjNi222TDkekuqQwT6nSVCNK7YXJ1qvTmPt6ftw/\nfz4ceSSMHh0WsD377PqF+5R27WKPi0iRUjhWXCRppUzGUHDY3G230Z0X4NxzGXHVVSXFsVT+7Rjb\nP6bwudmWAlHulKpUoTxlZp2BbsAuQCvgPWAUcIm7f53vXFWapHy++w4OPxweewxuvBH+8IekIxKR\nbFI47EGkZrz8Mpx+OrRrB5ddlnQ0ItWpcnmqB/AB0BOYBexIuOd2HzPb090X5zpRlSYpj2+/DTMD\nPfkkDBsGp5ySdEQiko8qTSLlN3duaDxs1QruuQeW03+zRBqsMnmqo7vPjj2faGZzCUtetAMm5DpR\nf801opju94ZOn12w7FdfwcEHw3PPhdmBunUr/rUvLj4OESmTFI4VF0lao2ewW7Qo3M/74Yfw9NPY\neoOKOy/f640pXCauHEttlELLckjFVChPZVSY6rwQPbbOd64qTdI4X3wRFup78UW4+27o0iXpiESk\nEN3TJFJ+F18MY8fCkCGw667AI0lHJFK9mjZP7R09Ts9XSJWmGlRKC1ljWonWtr/wOHewHZ/QhS6M\nPnIa7tkrTSW1fvWNnXdxSSGJSDF0T5NIeT34IAwYEIamn3pq0tGIVL+G5alWZjY19nyIuw/Jd4KZ\ntQb6AePcfWq+sqo0ScN8+ilP8g825zN+y9E8xs+TjkhEiqVKk0g9DZ09j7feguOOg7Zt4e9/L3iN\nbIopW+7hb+W4nobkScU0LE/Ncfe2xRY2s1WBB6NXOqlQeVWaalC5v6jr+egj2Hdftl/paxj9GI/u\nt1/p14hkS1K5epdK7RUrtFiuSLOle5pEyuObb8LEDyusAPfdByuumHREIrWhwnnKzFYCxgCbAnu7\n+6xC56jSJKV5/31o3x4+/jhMLf7rXycdkYg0hO5pkmagUGNbqY1xS5Vxh5NPhjffhCeegI02qujE\nCNnWYKrE64ikRoXylJm1AO4F2gL7u/u/izlPlaZmJNuXeUlf8DNmhArT3Lnw+OOwxx71rl3ql3cl\ne8WUSERy0PA8kcYbOBBGjoQrrgi5UUTKp0J5ysyWAe4E2gOHuPuUYs9VpUmK85//wL77hqEI48eH\nsdsiUp1UaRJpnAkT4PzzoXNn6NEj6WhEak/l8tSNQBdgAPCtme0eOzYr3zA9VZqksOnTQ4VpwYKw\neO0OOyQdkYg0hu5palZefPHDZnuPZ6H326DP4/334aijYIst4JZbwKxx1ytSc/vdSTNXuTx1UPR4\nQbTF9QX65DpRlaZmJNsXbsHF/F57DfbbD5ZdFiZNwrYZAdxf71x9mYuISM37/ns44giYPx/uvx9W\nWy3piESkBO7epqHnqtIkub30Euy/P6y0UhiKsPnmSUckIuWgxW1FGqZ7d3jhhVBh2mKLpKMRqV0p\nzFOqNNW4UiZ6WOr4889Dhw7QsmWoMG26aVHXaOhri0gT0z1NzcYuu2zA1Kl9kg6j+g0dCsOGQa9e\ncNhhP+5uqhnzlEel2UlZnlKlSep75hn4zW9g3XXDpA8bb5x0RCJSTpoIQqQ0//oX/PGPcMAB0K9f\n0tGI1L4U5ilVmmpcSauaQ+hV6tgRNtwwVJhaty77a4tIwjQRhNSYcvTI5LzGp5+G+5g22ADuuguW\nXbZsPUCFJuhQHpVmK4V5SpUmWWLs2DDkYLPNYNw4WG+9pCMSkUpI4VhxkVRauBCOPhrmzIHno+th\n3AAAG7FJREFUnoO11046IpHmIYV5SpUmCcaMCetNbL11WNm8VaukIxKRSknhsAeRVOrZMyy1MXw4\n7LRT0tGINB8pzFOqNDVTS3X533dfaEnbaafQ27TmmonFJSJNJGXJSKQxyjGMrd41RoyAq66CM8+E\nE04Asg+niw/VKzUmDb8TySNleWqZpAOQhN11V1ikb7fdwpA8VZhEal/dWPFStiKY2U/N7AYzm2xm\n88zMzaxNked6jm3H0t6cSBlMmwYnnwx77glXX510NCLNT4XyVGOop6lKNHQ197w3q956K5xyCuy9\ndxiet+qqjYpRRKpE5caKbwYcCbwIPA0cUOL5w4HBGfvebnxYIiX48kvo1CnkxJEjYfnlk45IpPnR\nPU2SGoMHw+9/HxavfeABWHnlpCMSkaZSubHiT7n7egBm9jtKrzR94O5Tyh+WVLMmXato8WI4/niY\nMSPMJrvBBksdzvb65YipMe9RazlJTdI9TVKKcnwRZj3v+uvhT3+Cgw+Ge++FFVds0vj0BS+SsAol\nI3dfXP6rijShSy+F0aPhuuvgV79KOhqR5iuFlSbd09TcXHllqDB16gSjRjW4wiQiVSyFY8UjZ5jZ\n/Oh+qAlmpv+1StN57DG48ELo2hW6d086GpHmLYV5Sj1NzUn//nDRRWGmvNtugxYtko5IRJKSsrHi\nwB3AQ8CHwMbAecAEM9vf3ScmGZgkq1zD1fLeGzxjBhx7LGy3HQwZAmYlx9kYjRl1oREbUrNSlqdU\naWqkF1/8sMGTNBRStuu5h9azAQPCtKk33wzLLluGy/Zp0vNEpIy85DNamdnU2PMh7j6kbOG4Hxd7\n+rSZPQi8DvQH1OMklTNvHhx+eMiVo0bpHl+RtCg9T1VUVVeazOxo4J+Em4d/muX4qcC5wCbATOAa\nd78pS7nDgIuBrYBPgKHApe6esjpuA7jDeefBwIFw6qlw002wjEZlikjJ5rh726Z6MXf/2sweBk5u\nqteU2pCrYS7rfvcwKdKrr8LDD8PPflaRmHQvr0j1q9r/PZtZS+Ba4OMcx08lTF17H3AgMBIYZGZn\nZJTrEJV5ATgIuA7oDVxSTBy77LIB7n3S+SW4eHEYlz1wIHTvjg1dH1u2X86F+ERERJqVQYPg9tuh\nTx846KCkoxGRFKvaShNwBfAqMDbzgJktBwwAbnf3C9z9SXfvTVgDpL+ZxW/muQx4xt1Pi8pdTagw\nnW1mP6n4u6iUxYvh9NPhxhuhR48wExBNO0ZbRKShzGx14BDgX0nHIjXq2Wfhz3+GQw6B3r2TjkZE\nUq4qh+eZ2S+BbsD2hF6hTHsA6xBuLI67HTgJ2At40sw2BHYETstSri+h5+nW8kWeXdm77RctCiuZ\n33Ybf+NXXHjVynBV33T2holITTGzztGPu0SPB5nZbGC2u08ys42Bd4B+7t4vOqcHYWHcJwlDpDcG\negA/Abo2ZfzSTHz0EXTuDG3ahJ6mEoetl5q3lX9Fql/VVZqiXqIhwJXu/l/LPsPNNtHj6xn7p0WP\nWxOSc9Zy7j7DzOZF5arLggVhYb6774b+/bnwwpRNci8iKVA3l2tFjMx4Pih6nAS0I3R5L8vSIx3e\nAjoBnYE1gK+AZ4FT3F09TVJeP/wAXbrAV1/BE09Ay5ZJRyQi9VQ0TzVI1VWagPOBFYBL85RZK3r8\nPGP/3IzjucrV7Vsry/70+uGHMJ34/ffDFVeECSAu7JN0VCKSOpVbNdDd844DdveZZIwVdvcxwJiK\nBCSSqUePMDTvn/+EbbdNOhoRySp9q9smWmkys/2AJ4ooOsnd25nZZsAFQCd3/76y0eVmZqcRDenb\naKONGn29snTbf/99GGrw8MNw/fU/LsxXyrXTMrtPWuIQqV3pa8GT8ip3nqoZd9wBN9wA55wTGhkb\nqNy5SXlPJFP68lTSPU3PEab5LmRe9Hg9MAGYEs2eB7A8YNHz+e7+HUt6jtYEPopdp67nqK7HKV4u\n05qxckuJ1iYZAtC2bdvkZ5GfNw8OOwzGjYPBg+G0zFu0RETi0teCJ+WVujyVBq+8EvLj3nvD5Zcn\nHY2I5JW+PJVopcnd5wFvlnDK1oQbhHMNp7sO+DNL7l3ahqUrTXX3KL0RPcbLTa4rZGZtgJVj5dLr\nm2/CzD9PPw233hoWr22gtLRupSUOkdqVvhY8kYqaOzcsYLvWWnDPPbBc0m3GIpJf+vJUtX1rHA2s\nmLHvr4RZmroAs6J9k4E5hFmXxsXKdiP0Hj0L4O7vmdmrUblhGeUWAI+WOf7y+vJL+M1v4Pnnw5CD\nY45JOiIRqQrpS0YiFbNoEXTtCh98AE89Beutl3RE9aixUCRT+vJUVVWa3H1K5j4zO5EwLG9irNwC\nM7uQsJjtB4SKU3vCyvLd3f2H2CV6AQ+Z2WDgn8BOhGnMr3P3rAvnpsLnn0OHDvDyy6HV7Igjko5I\nRKpKuoY9iFRM377w2GNw002w225JRyMiRUtXnqqqSlMp3P0mM3PgXOA84D3gj+4+KKPcI9G6IhcD\nJxLWCLmEsDhuOs2ZA/vvD2+8AaNGQceOSUckIlUlfS14IhUxejT07x/WLizj/b6auEGk0tKXp6q+\n0uTuJ+Y5NhgYXMQ1RgGjyhhW5XzyCey7L7zzTkgGHTokHZGIVJ303WArUnZvvw3HHQdt28KNN0L2\ndR1FJJXSl6eqvtLUrHzwQagwvf8+PPII7LNP0hGJSFVKXwueSFl9802Y+KFFC7j3Xlgx83ZoEUm3\n9OUpVZqqxbvvQvv2MHs2jB0Le+2VdEQiUrXS14InUjbucMopMH16yJcbb1yBl+hT9muKSFz68pQq\nTdXgnXdChemrr8JaTLvumnREIlLV0teCJ1I2V18NI0bAZZfBfvslHY2INEj68pQqTWn31lthSN73\n38P48bDzzklHJCJVL30teCJl8eSTcP75YUbZv/wl6WhEpMHSl6dUaUqzadNChck9JILttks6IhGp\nCelrwRNptPffh6OOgp//PCz2njHxQ92MdxpaJ1IN0penVGlKq1dfDcMKWrQIPUxbbZV0RCJSM9LX\ngifSKPPnQ+fOYVTG/ffDaqslHZGINEr68pQqTWk0dSoccACsuipMmACbbZZ0RCJSU9LXgifSKGed\nBf/6V1i7cMstsxZRD5NINUlfnlom6QAkw+TJYUhey5bw1FOqMImIiOQzbBgMGQI9e0KnTklHIyI1\nSj1NaTJpEhx8MGywQRiSt+GGSUckIjUrXcMeRBrkhRfgzDNh//2hf/+koxGRskpXnlKlKS3GjYND\nD4U2bUKFaf31k45IRGpW+oY9iJRs9uwwS97668Ndd8GyyyYdkYiUTfrylCpNafDII2Hl8i22gCee\ngHXXTToiEalp6UtGIiVZuBCOPjpUnJ59Flq1SjoiESmr9OUpVZqS9sADcOSRsP32YeXytddOOiIR\nqXnpm5VIpCS9eoWJkm69VesXitSk9OUpVZqSNGIEdO0KbdvCo4+GyR9ERCoufS14IkUbORKuvBLO\nOANOPDHpaESkItKXp1RpSsodd8AJJ8AvfwkPP6w1JUSkCaWvBU+kKG+8ASedBLvvDtdem3Q0IlIx\n6ctTmnI8CTffDMcfD+3ahR4mVZhEpEnVteCVshVmZj81sxvMbLKZzTMzN7M2RZ67opldaWYfmdl3\n0TV+XeIbk1r25ZdhSvFVVoF774Xll086IhGpmPTlKVWamtqgQfC730GHDvDQQ+HLX0SkSdW14JWy\nFWUz4Ejgc+DpEoO6GTgVuAg4BPgIGGtmO5Z4HalFixeH0RnvvBOG57VunXREIlJR6ctTGp7XlK65\nBs45J0wtPmIErLBC0hGJSLNUsbHiT7n7egBm9jvggGJOMrMdgGOBk9391mjfJGAa0A84tBLBShW5\n7DJ48MEwJO/X6oAUqX3pylOgnqamc+mlocLUpUsYVqAKk4gkpjIteO6+uIEBHUrIjvfErrUQuBvo\nYGb6wmyEF1/8ELM+mPVJOpSGGTsWeveGY4+Fs85KOhoRaRKpy1Pqaao4d+jbN2xdu8Lw4bCcPnYR\nSVLqZiXaBpjh7vMy9k8DlicMp5jW5FFJ8mbMCJWlbbeFIUPALOmIRKRJpC5PqdJUcRdeCAMGhNl+\nhg7ViuUikgKpm5VoLcL48kxzY8elufnuu7Dw+6JFMGqU7gEWaVZSl6cwd086hqpmZrOBdwsUawXM\naYJwqo0+l+z0uWSnzwU2dvd1GnsRM3uM8HmWYkXg+9jzIe4+JM9r/A4YCmzi7jMLxPM4sLq7756x\nfz/gCeDX7l7qxBISKTJPpZn+9quHflfVo1K/q5rMU6CepkYr5h+GmU1197ZNEU810eeSnT6X7PS5\nlI+7H5h0DBk+BzbOsr+uh2lulmNSpHL8ByZJ+tuvHvpdVY+0/65SmKc0EYSIiCRuGrCJma2csX9r\n4Afgv00fkoiIyBKqNImISNLGAC2ALnU7zGw54CjgcXefn1RgIiIioOF5TSXneMpmTp9LdvpcstPn\nUgXMrHP04y7R40HRPTWz3X2SmW0MvAP0c/d+AO7+spndA1xrZi2AGcAZwCZA16Z9B5JC+tuvHvpd\nVY9m+7sqlKdynqeJIEREpFzMLFdSmeTu7cysDaFS1Nfd+8TOWwkYQFjktiXwKnC+u0+sZLwiItK8\nFMpTOc9TpUlERERERCQ33dNUJmY208w8y3ZYlrKnmtmbZjbfzN4ys9/nuOZhZvaymX1vZu+aWW8z\nq5qFnsxsczO7wczeMLNvzOwjMxttZjtkKTsxx+f35yxlq/pzycbMNjSze83sSzP7ysxGmdlGScdV\nCWbW2cweMLP3zey76G/gUjNbLVamTY5/D25mLTOut6KZXRn9+/rOzCab2a+b/p2JSEMph1av5pS/\n0sjM2uX42/kio9yaZjbMzOaY2bdmNs7MtstyPeXUHHRPU3mNBfpk7Hsr/sTMTgUGA5cC44B9gUFm\nZu7+f7FyHYD7gJuBc4CdgEuA1YDzKxR/uR0AtAeGA1OBNYC/AFPMbC93fzGj/GvA6Rn7Zsaf1Mjn\nshQLM4ZNAOYDJxBWdPsb8KSZbe/u3yYZXwX0AD4AegKzgB0Jfzf7mNme7r44VvZSYHTG+V9nPL8Z\nOBg4D/gfcCYw1sz2cPdXyh++iFSIcmiVaYb5K83OAl6IPf9xZVgzM8KEO22A7oRlHnoSfk87uvus\n2HnKqbm4u7YybIT/3N9RoMxywKfAPzL230JYYKxFbN/LhLGV8XIXEabf/UnS77fIz6QV0RDQ2L41\nCH+st2Xsnwg8U8Q1q/5zyfKe/gQsAjaL7duE8IV3TtLxVeD9rpNl3/GEZNs+et4mev67AtfaISp3\nUmzfcoT/aI1O+r1q06atuE05tDq35pa/0rgB7aI8uF+eMr+NyuwT27cGYQ2862P7lFPzbBqe17T2\nANYB7sjYfzuwNrAXhK5uQut7tnItgIMqG2Z5uPscj/7iYvu+BN4GWpd6vVr5XLI4FJji7j+uRePu\nM4BnCV90NcXdZ2fZXdc6Vuq/i0OBBcA9sesvBO4GOpjZCg0KUkTSqFnl0CrRrPJXFTsU+NDdn6zb\nEf1/bAxL/56UU/NQpam8OprZvGic9ZQsY7G3iR5fz9g/LXrcOl+56ItoXqxc1TGztYBtgelZDu8U\njYleYGavmdkpGcdr9XPZhvr/JiD8u6jW91SqvaPHzH8Xl5rZwujfxegs46+3AWa4+7yM/dOA5YHN\nKhCriFSGcmj1Uf5KjzvNbJGZfWZmd2XcV5bv97SRma0aK6ecmoPuaSqfMYTW8hnAesAfgfvN7Dh3\nr2vtWit6/Dzj3LkZx3OVq9u3Vpb91eIGwIBrM/Y/BdxJ6IVqSRiuNczM1nf3v0VlavVzWYvs72ku\nsGYTx9LkzKw10A8Y5+5To93zCfctPA7MBrYEegHPmdkv3P3NqFy+z67uuIikn3JodWrW+SslvgQG\nApOArwj37/UCJpvZTu7+KeH3NDPLuXV/O2sC36CcmpcqTVmY2X7AE0UU/XE+d3fvnnGN+4EphBtP\nM4cIVKWGfC4Z5/ckrMFySrwrH8DdL8oo/mD0GfYys2vd/ZsGhi0pFrVuPUgY/35S3X53/wiIz4j1\ntJk9RmjtugA4rinjFJHiKYeKNB13f5lwD1+dSWb2FPAvwqQPFyYSWA1SpSm754CtiiiX2X35I3df\nZGYjgcuj3pKPWFJ7XxP4KFa8ruZeV5OPl8u0ZqxcU2vw5xJNCXsJ0Nvdbyny9f4JHAZsB0wmvZ9L\nY31O9veUq8WnJlhYzHQMsCmwty89e0897v6+mT0D7Brb/TmwcZbimX9TItJ0lEObj2aZv9LO3V8y\ns7dZki/z/Z7qjtc9KqfmoEpTFtFYzjcLFixd3bjrbVj6C79u3O8bWcpNritkZm2AlWPlmlRDPxcz\nOw4YBAx09wGNCCGVn0sZTGPJGPy4rane95SXmbUA7gXaAvu7+78beKlpQCczWzljDPbWhFmy/pv9\nNBGpFOXQZqXZ5a8qNY2wDEymrYH3YqN5lFPz0EQQFWJmywFHEf4x1n25TyZMi9o1o3g3Qu39WQB3\nfw94NUe5BcCjFQq77MysE3ArMMzde5R4elfgO+DfUFufS4bRwO5mtmndjii5/5L6axRVPTNbhnD/\nWnvgMHefUuR5GxFmx3o+tnsMYTasLrFydX97j7v7/HLFLSJNRzm0ajSr/FUtzKwtsAVL8uVooLWZ\n7R0rszrQkaV/T8qpeainqQzM7BjgEOARwqKdPyEsBrYzcExdOXdfYGYXEhbi+4CwMF974GSgu7v/\nELtsL+AhMxtMGKa2E9AbuM7dP678u2q8aAXpfxKS13Az2z12eH40Dhcz+xVhEbVRwHuEiSBOIEx9\n+deM+5mq/nPJYijhpucHzaw3YY2E/sD7hMkQas2NhC/kAcC3Gf8uZrn7LDMbCCwm3NMwl/Dl3zPa\n92Nvpbu/bGb3ANdGvVczgDMI64Rk/odJRFJIObSqNbf8lTpmdgfwDuG+prqJIHoS/pauj4qNJjQ6\n3GFm57FkcVsDrqi7lnJqAUkvFFULG7A7YUXsTwitWF8Qvsw75Ch/OmGWuPnAf4A/5Ch3OKHCMZ9Q\nmbgIWDbp91vC59KH8AWabZsZK7cZoeXvg+i9fkMYE39MLX4uOd7TRoTV678CvgYeANokHVeF3uvM\nPP8u+kRlTibMpPV59Df1MXAXsEWW660EXB2V+Z7QstYu6fepTZu24jbl0OremlP+SuNGqPy8RphF\nbwGhwjoEWD+j3FqEhaDnEu4nHA/skOV6yqk5Nos+IBEREREREclC9zSJiIiIiIjkoUqTiIiIiIhI\nHqo0iYiIiIiI5KFKk4iIiIiISB6qNImIiIiIiOShSpOIiIiIiEgeqjSJZDCzPmbm0armqWZmE81s\nZgnlh5uZ1hkQEaliylMiTU+VJpEaY2Ynmtmfk45DREQkG+UpqUaqNIlUtwOALTL2nQjkSkanElb7\nFhERaQrKU1ITlks6AJFSmNmywAruPi/pWNLA3X8osfwCYEGFwhERafaUp5amPCW1Qj1NklpR972b\n2X5mdqGZvQN8DxwZK9PWzO43szlmNt/M3jKzC8xsuYxr7RqNk37bzOaZ2ddm9qyZdWpkjBPNbKaZ\nbWpmD5rZl2b2VRTTplnKr2Jml5rZO1G8H5vZbWa2cUa5Zczsz2b2WhTrV9F7u9nMWmS+fuz5TGBv\nYOPos6vb2kXHs44VN7Pto5g/M7PvzewNM/tLlPzj5YZH11vDzP7PzD6Nyj9rZrs15rMUEak2ylPK\nU9J8qKdJqsFVQAtgKPAV8BaAmR0MjAL+CwwE5gJ7AP2AHYEusWt0ArYERgDvAmsDJwCjzKyru9/V\niPhWASYCzwM9gZ8DfwB2N7Od3P3jKN4WwFjgl8C9Ucw/B84ADjCztu4+K7rmBdH7GAPcBCwCNgEO\nBVYgdyvcn4FLgVbA2bH903MFb2ZtgUnRNW8EPgY6ApcDOwBds5w2Fpgdxbg2cA7wsJlt4u5f53ot\nEZEapTylPCW1zt21aUvlRhjz7ITks3LGsRUJX5pPActlHDs7Oq9dbN8qWa6/cnTtNzL294nOb1NE\njBOjstdm7O8U7b8ptu/UaN8VGWUPjvbfHtv3UmZceV5/ZqF9sWPDw5/9UvueBRYC28f2GSFxO7Bv\n5vnAoIxrdIn2n570vxtt2rRpa6pNeUp5Slvz2TQ8T6rB/3n9seH7A+sBtwItzaxV3QY8EpU5oK6w\nu39b97OZrWxmaxOS0QRgKzNbvZExXhZ/4u73ExLdYbHdnYDFhBa2eNmHgVeA35pZ3d/kl0BrM9ur\nkXHlZWbrAnsCo939tVhMDgyIxZ3pmoznE6LHn5c9SBGR9FOeqhDlKUkLVZqkGrydZd9W0eMthO73\n+PZmdGy9usJmtq6ZDTGzT4BvgTlR2d9HRVo2Ir4vPBrakGE6sJ6ZrRI93wT40N0/z1J2GrAaYbgC\nQC/CuPinzewDM7vTzI41s+UbEWc2m8ReP9N0QvKsN+Yd+F/8ibt/Fv24dvlCExGpGspTylNS43RP\nk1SDbDMQWfR4HqH1K5sPAczMgMcJCew6YCqhhWwRcBJwLClrQHD3yWb2M6ADsE+0HQv0NrO93H1u\nwvEtynHIcuwXEallylPKU1LjVGmSavWf6PFbdx9XoOz2hBtF+7n7xfEDZva7MsTS0sx+kqUVbyvg\n09iQi/8BB5pZS3f/IqPs1oSbh+fU7XD3b4D7og0z+wPhBthTgCvzxFPKSuozosdtshzbkpCk/5fl\nmIiI5Kc8lZvylFSdVLVaiJRgLPAp8FczWyvzoJmtZGarRU/rWpsso8y2ZB8H3RB/zbh2J8Jifg/E\ndj9A+JvLLHsQsBNhvPbiaF8r6nspeqz3fjN8A6wZtVzm5e6fAs8BHaPPoy4mI8ywBHB/oeuIiEg9\nylO5KU9J1VFPk1Qld//WzI4nfMG/ZWa3EKZ0bUloeTqckGgmEsY8TwP+YmZ1MxFtDpwO/BvYpZHh\nzAEON7MNoterm8r1E8IMR3WGE6aPPd/M2hBmVNosVrZXrOx0M5tCmB72Q2B94DTgB+DuAvFMAQ4B\n/m5mzxGS8YQo8WTzJ8JUrk+bWd1UrocQhlzc5e7jC7yeiIhkUJ7KS3lKqo4qTVK13H2smf2C0CLW\nDVgH+Bx4B7gaeC0qtyhaK+MqQjJYBXg9+nkHGp+MvgXaE2bquYzQUvgYcK67fxSLd4GZdQB6A0cR\nEuYXwEigt7u/H7vmQOA3wFnAGoTWyinApe7+aoF4riHcFNuZcAPxMoSx5lmTkbtPNbM9gb6ExLgK\nYajD+VEcIiLSAMpTOSlPSdWxMGOjiDSEmU0krJPRJuFQRERE6lGeEikP3dMkIiIiIiKShypNIiIi\nIiIieajSJCIiIiIikofuaRIREREREclDPU0iIiIiIiJ5qNIkIiIiIiKShypNIiIiIiIieajSJCIi\nIiIikocqTSIiIiIiInmo0iQiIiIiIpLH/wMIIAQrI6sjjQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2870052cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#histogram definition\n",
    "bins = [100,100] # number of bins\n",
    "\n",
    "cm = plt.cm.jet\n",
    "cm.set_under('w',1)\n",
    "# histogram the data\n",
    "f, (fig1, fig2) = plt.subplots(1, 2, sharey=True)\n",
    "_, _, _, im1 = fig1.hist2d(pos[:, 0], pos_inferred[:, 0], bins=bins, cmap=cm, cmin=1)\n",
    "fig1.plot([-500, 0, 500], [-500, 0, 500],'r')\n",
    "fig1.set_title('xCore')\n",
    "fig1.set_xlabel('real position')\n",
    "fig1.set_ylabel('inferred position')\n",
    "_, _, _, im2 = fig2.hist2d(pos[:, 1], pos_inferred[:, 1], bins=bins, cmap=cm, cmin=1)\n",
    "fig2.plot([-500, 0, 500], [-500, 0, 500],'r')\n",
    "fig2.set_title('yCore')\n",
    "fig2.set_xlabel('real position')\n",
    "f.colorbar(im1, ax=fig1)   \n",
    "f.colorbar(im2, ax=fig2)\n",
    "f.set_figwidth(14)\n",
    "f.set_figheight(5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mdl = torch.load(f='/home/jacquemont/MyDriveAtLap/saved_models/model1_kaimin-uniform_batchnorm_lr0.001_20epochs.tar')\n",
    "l = mdl['loss_epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEBCAYAAAB8NQKFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFT9JREFUeJzt3X2wXHd93/H3x0GAqbEeYjWT2FaFB4aOH0TT3jbJmKmf\nMmAYS6Y1qKSZ0LEHHFzGziSDPaPQeFw31C0hY6pQO7imDzMGEoUUkDoNwTbCkFY0XEOjWA10SA2W\nx2QiR0JgWwl++PaPc259z+3K3nv33Lt3775fMztH+zu/XX333HPvZ3/nd85uqgpJkuacMu4CJEmr\ni8EgSeowGCRJHQaDJKnDYJAkdRgMkqQOg0GS1GEwSJI6DAZJUsdLxl3AUpxxxhm1devWcZchSRPj\nwQcffLyqNg/TdyKDYevWrczOzo67DEmaGEm+PWxfDyVJkjoMBklSh8EgSeowGCRJHQaDJKnDYJA0\nWQ7ugdvPh1s2NMuDe8Zd0ZozkaerSppSB/fAvhvg6RPN/eOHm/sA23aOr641xhGDpMlx/63Ph8Kc\np0807eqNwSBpchx/dHHtWhKDQdLkWH/W4tq1JAaDpMlx2c2w7tRu27pTm3b1xmCQNDm27YTtu2H9\n2UCa5fbdTjz3zLOSJE2WbTsNgmXmiEGS1GEwSJI6hgqGJGcl+Y0kB5I8laSSbB3Qb2OSu5M8nuTJ\nJPcluWBAv5cn+bUk30lyon3evz/6y5EkjWrYEcOrgZ3AMeBLgzokCbAPuBy4HrgKWAfsT7LwXLKP\nAu8CbgauAL4D/H6Sv7XYFyBJ6tewk89frKofAUjyTuANA/rsAC4ELq2q/W3fA8DDwE3ADW3b64B/\nDFxTVf+hbXsAOATc2j6PJGlMhhoxVNVzQ3TbATw2Fwrt447TjCKuXNDvaeC35/V7Bvgt4I1JXjZM\nTZKk5dHn5PN5wEMD2g8BW5KcNq/fw1X11IB+L6U5bCVJGpM+g2ETzRzEQkfb5cYh+20a9ORJrk0y\nm2T2yJEjIxUqSTq5iTldtaruqqqZqprZvHnzuMuRpDWrz2A4xvOjgvk2zVs/TL+jA9ZJklZIn8Fw\niGb+YKFzgUeq6ol5/V6V5BUD+v0A+GaPNUmSFqnPYNgLnJnkormGJKcD29t1c/bRXN/wtnn9XgL8\nI+BzVfVXPdYkSVqkoT9EL8lb23/+nXb5piRHgCNV9QDNH/8DwD1JbqQ5ZLQLCPCBueepqq8l+W3g\nQ0nW0VzncB3wKuBnR3w9kqQRLebTVX9nwf072uUDwMVV9VySK4APtuteThMUl1TV4QWPvRp4P/Cr\nwAbgj4DLq+qri6xfktSzVNW4a1i0mZmZmp2dHXcZkjQxkjxYVTPD9J2Y01UlSSvDYJAkdRgMkqQO\ng0GS1GEwSJI6DAZJUofBIEnqMBgkLc3BPXD7+XDLhmZ5cM+4K1JPFnPlsyQ1Du6BfTfA0yea+8cP\nN/cBtu0cX13qhSMGSYt3/63Ph8Kcp0807Zp4BoOkxTv+6OLaNVEMBkmLt/6sxbVrohgMkhbvspth\n3andtnWnNu2aeAaDpMXbthO274b1ZwNpltt3O/G8RnhWkqSl2bbTIFijHDFIkjoMBklSh8EgSeow\nGCRJHQaDJKnDYJAkdRgMkqQOg0GS1GEwSJI6DAZJUofBIEnq6DUYklyY5HNJ/jzJ95N8Nck1C/ps\nTHJ3kseTPJnkviQX9FmHJGnpeguGJNuA+4B1wLuAfwh8BfhokuvaPgH2AZcD1wNXtf33J/GD3CVp\nFejz01XfDvwQsL2qnmjb7m0D4x3AncAO4ELg0qraD5DkAPAwcBNwQ4/1SJKWoM9DSS8FfgA8taD9\n+Lz/Zwfw2FwoAFTVcZpRxJU91iJJWqI+g+E/AgF2J/mxJBuSvAu4DLi97XMe8NCAxx4CtiQ5rcd6\nJElL0NuhpKp6KMnFwKeA97TNTwPvrqrfau9vAr414OFH2+VG4IkB6yVJK6S3YEjyGuB3ad79vxs4\nQXN46DeT/GVVfWzE578WuBZgy5YtI1YrSTqZPief/yXNCGF7Vf2gbbs/yQ8D/ybJJ4BjNKOChTa1\ny2Mne/Kqugu4C2BmZqZ6q1qS1NHnHMMFwMF5oTDnD4EfBv46zWjivAGPPRd4ZN7ZTJKkMekzGP4M\n2JbkpQvafwL4S5p5hL3AmUkumluZ5HRge7tOkjRmfQbDh4FzgH1JrkzyhiQfBn4GuLMdSewFDgD3\nJHl7kje2bQE+0GMtkqQl6i0YquqTwJuBlwF300xEv57mDKUb2z7PAVcA9wJ30JzB9CxwSVUd7qsW\nSdLS9Tn5TFX9HvB7L9LnKHBNe5MkrTJ+uqokqcNgkCR1GAySpA6DQZLUYTBIkjoMBklSh8EgSeow\nGCRJHQaDJKnDYJAkdRgMkqQOg0GS1GEwSJI6DAZJUofBIEnqMBgkSR0GgySpw2CQJHUYDJKkDoNB\nktRhMEiSOgwGSVKHwSBJ6jAYJEkdBoMkqcNgkCR1GAySpI7egyHJm5N8MckTSb6XZDbJpfPWb0xy\nd5LHkzyZ5L4kF/RdhyRpaXoNhiQ/D3wGeBD4B8DbgN8BXtGuD7APuBy4HrgKWAfsT3JWn7VIkpbm\nJX09UZKtwIeAG6vqQ/NW/f68f+8ALgQurar97eMOAA8DNwE39FWPJGlp+hwxXAM8B/zmC/TZATw2\nFwoAVXWcZhRxZY+1SJKWqM9geD3wdeDtSf40yTNJvpnkPfP6nAc8NOCxh4AtSU7rsR5J0hL0GQw/\nBrwG+DXgXwFvAO4FPpzkF9o+m4BjAx57tF1uPNmTJ7m2nciePXLkSH9VS5I6+gyGU4BXAj9fVf+u\nqj5fVdcBnwV2jfrkVXVXVc1U1czmzZtHfTpJ0kn0GQx/0S7vXdD+OeBHkvwozWhh0KhgU7scNJqQ\nJK2gPoPh0JB9zhvQfi7wSFU90WM9kqQl6DMYPtUu37ig/XLg0ar6DrAXODPJRXMrk5wObG/XSZLG\nrLfrGID/CuwHPpLkDOD/0Fzg9gbg6rbPXuAAcE+SG2kOHe0CAnygx1okSUvUWzBUVSV5C3Ab8M9p\n5hK+DvxsVX287fNckiuADwJ3AC+nCYpLqupwX7VIkpYuVTXuGhZtZmamZmdnx12GJE2MJA9W1cww\nff10VUlSh8EgSeowGCRJHQaDJKnDYJAkdRgMkqQOg0GS1GEwSJI6DAZJUofBIEnqMBgkSR0GgySp\nw2CQJHUYDJKkDoNBktRhMEiSOgwGSVKHwSBJ6jAYJEkdBoMkqcNgkCR1GAySpA6DQZLUYTBIkjoM\nBklSh8EgSepY1mBI8tkkleRXF7RvTHJ3kseTPJnkviQXLGctkqThLFswJPkZ4HUD2gPsAy4Hrgeu\nAtYB+5OctVz1SJKGsyzBkGQjcDvwSwNW7wAuBH6uqj5RVZ9t204BblqOeiRJw1uuEcO/Bh6qqk8M\nWLcDeKyq9s81VNVxmlHElctUjyRpSL0HQ5LXA+8A3nOSLucBDw1oPwRsSXJa3zVJkobXazAkeSnw\nEeCDVfWNk3TbBBwb0H60XW7ssyZJ0uL0PWK4CTgVeH/Pz0uSa5PMJpk9cuRI308vSWr1FgxJtgDv\nA34FeFmSDUk2tKvn7v8QzWhh0KhgU7scNJqgqu6qqpmqmtm8eXNfZUuSFuhzxHAO8HLgHpo/7nM3\ngPe2/76AZi7hvAGPPxd4pKqe6LEmSdIivaTH5/qfwCUD2vfThMVHgW8Ce4Grk1xUVQ8AJDkd2A58\nvMd6JElL0FswVNV3gS8sbG+uZ+PbVfWF9v5e4ABwT5IbaUYSu4AAH+irHknS0qz4ZyVV1XPAFcC9\nwB3Ap4BngUuq6vBK16NV5uAeuP18uGVDszy4Z9wVLb9pfM1a1fo8lDRQVWVA21HgmvYmNQ7ugX03\nwNMnmvvHDzf3AbbtHF9dy2kaX7NWPT9dVavH/bc+/wdyztMnmva1ahpfs1Y9g0Grx/FHF9e+Fkzj\na9aqZzBo9Vh/kg/XPVn7WjCNr1mrnsGg1eOym2Hdqd22dac27WvVNL5mrXoGg1aPbTth+25YfzaQ\nZrl999qehJ3G16xVL1U17hoWbWZmpmZnZ8ddhiRNjCQPVtXMMH0dMUiSOgwGSVKHwSBJ6jAYJEkd\nBoMkqcNgkCR1GAySpA6DQZLUYTBIkjoMBklSh8EgSSthgr6pb9m/wU2Spt6EfVOfIwZJWm4T9k19\nBoMkLbcJ+6Y+g0GSltuEfVOfwSBJy23Ub+pb4YlrJ5+1thzc0xy3Pf5o827ssptX5eSepszcPriU\nfXMME9d+g5vWjoW/QNC8K/OrMjXJbj+/CYOF1p8Nv/jQ0E/jN7hpOk3YmR/SUMYwcW0waO2YsDM/\npKGMYeK6t2BI8tYkn05yOMmJJN9IcluSVy7otzHJ3UkeT/JkkvuSXNBXHZpiE3bmhzSUUSeul6DP\nEcN7gWeBXcCbgDuB64B7k5wCkCTAPuBy4HrgKmAdsD+Jv70azRh+gaRlt21nM0+2/mwgzXKZ5836\nPCtpe1UdmXf/C0mOAv8JuBj4PLADuBC4tKr2AyQ5ADwM3ATc0GM9mjajnPkhrWbbdq7oftxbMCwI\nhTlfaZdntssdwGNzodA+7niSfcCVGAwa1Qr/Aklr0XJPPl/ULv+kXZ4HDDq/6hCwJclpy1yPJOlF\nLFswJDkTuBW4r6rmLjrYBBwb0P1ou9y4XPVIkoazLMHQvvP/DPAMcHVPz3ltktkks0eODDpqJUnq\nQ+/BkORUmjOPzgHeWFXzTyI/xuBRwaZ56weqqruqaqaqZjZv3txbvZKkrl6DIck64JPADPDmqvrj\nBV0O0cwzLHQu8EhVPdFnPZKkxevzArdTgI8BlwJvqaovD+i2FzgzyUXzHnc6sL1dJ0kasz6vY/i3\nwNuA9wNPJvnJeesebQ8p7QUOAPckuZHm0NEuIMAHeqxFkrREfR5KelO7fB/NH//5t3cCVNVzwBXA\nvcAdwKdorpa+pKoGfHygJGml9XmB29Yh+x0FrmlvkqRVxk9XlSR1GAySpA6DQZLUYTBI0rAO7mm+\navOWDc3y4J5xV7Qs+jxdVavNwT1+BLXUl4XfKX78cHMf1tzvlSOGtWpuJz5+GKjnd+Jh3+FMyTsj\naWhT9J3iBsNaNcpOPGqoSGvRFH2nuMEwjEl89zzKTjzqO6NJ3F7Si5mi7xQ3GF7MpL57HmUnHiVU\nJnV7SS9mir5T3GB4MZN6XHGUnXiUUJnU7aXpMMpodttO2L4b1p8NpFlu373mJp7Bs5Je3KQeV5zb\nWZdyVtJlN3fPvoDhQ2VSt5fWvj7OKpqS7xSfnmBY6qmb689qD4sMaF/tlroTjxIqk7y9tLa90Gh2\nCv7YL8Z0BMMo7xRGefc8939P4rUESw2VUbfXOE3qz0rDcTQ7tOmYYxjluPcoxxX7mIidtDN8JvU4\nrNd9rH1TdFbRqFJV465h0WZmZmp2dnb4B9yyARj0OgO3fLevsv5/t59/ksMqZ8MvPvTij1840oHm\n3fck/KGdNKP8rCb55zSuUdI4/t9J/jn1IMmDVTUzTN/pGDGM653CqENXz/BZOeO87mNcxnVq8bj+\n30kdzY7BdATDuM4/HjWQPCa6csZ13cc4jSvQxhmk23Y2I8BbvtssDYWBpiMYxvVOYdRA8pjoyhnX\ndR/jNK5Am9QgnSLTEQwwnncKowbSFF1pOXaj/KzG+XMaZdJ7XIE2qUE6RaZj8nmSeQrlZJjEydRx\nTcZO+STwuCxm8tlgkCbVqGe9wXSdlTTlFhMM03GBm7QW9XGsflwf8TAlHy0xqaZnjkFaazxWr2Vi\nMEiTypMTtEwMBmlSecGWlolzDNIk81i9loEjBklSh8EgSeowGCRJHQaDJKnDYJAkdUzkR2IkOQJ8\ne4kPPwN4vMdy1jq31+K4vRbH7bU4o2yvv1FVm4fpOJHBMIoks8N+XojcXovl9loct9firNT28lCS\nJKnDYJAkdUxjMNw17gImjNtrcdxei+P2WpwV2V5TN8cgSXph0zhikCS9gKkIhiRnJ/lkkuNJvpfk\nPyfZMu66VqMkFyepAbfvjru21SDJWUl+I8mBJE+122brgH4bk9yd5PEkTya5L8kFK1/xeA2zvZJs\nPck+V0k2jKfylZfkrUk+neRwkhNJvpHktiSvXNBv2fetNR8MSV4BfB74m8A/AX4OeA2wP8lfG2dt\nq9wNwE/Nu/30eMtZNV4N7ASOAV8a1CFJgH3A5cD1wFXAOpp9btq+RedFt9c8t9Hd534K+P6yVre6\nvBd4FtgFvAm4E7gOuDfJKbCC+1ZVrekb8Avtxn71vLZXAc8AvzTu+lbbDbgYKOCnx13LarwBp8z7\n9zvbbbV1QZ8r2/ZL5rWtB44Cu8f9Glbh9tratr9z3PWOeVttHtD2jnbbXNreX5F9a82PGIAdwJer\n6ptzDVX1MPDfaDayNLSqem6IbjuAx6pq/7zHHad5pzdV+9yQ20tAVR0Z0PyVdnlmu1yRfWsaguE8\n4KEB7YeAc1e4lknysSTPJvmLJB93TmZRXmif25LktBWuZ1LcluSZdi5w7zTOyQxwUbv8k3a5IvvW\nNHyD2yaa45sLHQU2rnAtk+A48OvAA8D3gB8Hfhk4kOTHq+rPx1nchNgEfGtA+9F2uRF4YsWqWf3+\nCvgI8DngCM184C8D/z3J362qr4+zuHFJciZwK3BfVc22zSuyb01DMGgRquprwNfmNT2Q5IvAH9JM\ndv3KWArTmlVV3wHePa/pS0k+S/Mu+H00J4xMlfad/2do5kKvXun/fxqC4RiDRwYnG0logar6apL/\nDfy9cdcyIV5on5tbrxdQVYeT/AFTuM8lOZVmzuAc4KKqenTe6hXZt6ZhjuEQzXG5hc4F/tcK16Lp\n8EL73CNV5WEkDZRkHfBJYAZ4c1X98YIuK7JvTUMw7AV+Msk5cw3tBTYXtuv0IpLMAK8F/se4a5kQ\ne4Ezk8xNHJLkdGA77nNDaU92eD1TtM+11yp8DLgUeEtVfXlAtxXZt9b8ZyW1F7H9EXAC+Gc05wD/\nC+CVwDbfvXUluQf4U5p5hrnJ513AU8Dfrqqp/1KVJG9t/3kZzbHxf0ozaXqkqh5of8H/ADgbuJFm\neL8L2Aa8rqoOr3zV4zPE9vp14DngyzSTqK+l2V7rgZ+oqm+sfNUrL8mdNNvn/cB/WbD60ap6dMX2\nrXFf1LFCF45sAX6X5g/d94FPs+AiG2//b1vtAg7SnJ30NHCY5hMdf3Tcta2WG82bi0G3L8zrswn4\n9zR/6J4C7m9/ccde/2rbXsA1NOfrH2v3uT8DPg68dty1r/B2+tYLbKtbVnLfWvMjBknS4kzDHIMk\naREMBklSh8EgSeowGCRJHQaDJKnDYJAkdRgMkqQOg0GS1GEwSJI6/i81dAyQB45W6gAAAABJRU5E\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff4d814c0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(range(21), l)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
