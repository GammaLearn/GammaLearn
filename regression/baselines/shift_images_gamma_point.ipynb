{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hipecta.data import ctaTelescope2Matrix\n",
    "from hipecta import core\n",
    "import numpy as np\n",
    "import h5py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset, ConcatDataset, sampler\n",
    "from torch.optim import lr_scheduler\n",
    "import matplotlib.pyplot as plt\n",
    "import hipecta.plots as plots\n",
    "from torchvision import transforms, utils\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "\n",
    "converter_path = os.path.abspath(os.path.join('/home/jacquemm/GammaLearn/converter_hdf5'))\n",
    "if converter_path not in sys.path:\n",
    "    sys.path.append(converter_path)\n",
    "    \n",
    "from converter_hdf5 import *\n",
    "from datasets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_1 = '/home/jacquemm/hdf5/gamma_point/LaPalma_gamma_point_source_20deg_0deg_prod3b_training_0000.hdf5'\n",
    "f_1 = h5py.File(file_1, 'r')\n",
    "file_2 = '/home/jacquemm/hdf5/gamma_point/LaPalma_gamma_point_source_20deg_0deg_prod3b_training_0001.hdf5'\n",
    "f_2 = h5py.File(file_2, 'r')\n",
    "file_3 = '/home/jacquemm/hdf5/gamma_point/LaPalma_gamma_point_source_20deg_0deg_prod3b_training_0002.hdf5'\n",
    "f_3 = h5py.File(file_3, 'r')\n",
    "file_4 = '/home/jacquemm/hdf5/gamma_point/LaPalma_gamma_point_source_20deg_0deg_prod3b_training_0003.hdf5'\n",
    "f_4 = h5py.File(file_4, 'r')\n",
    "file_5 = '/home/jacquemm/hdf5/gamma_point/LaPalma_gamma_point_source_20deg_0deg_prod3b_training_0004.hdf5'\n",
    "f_5 = h5py.File(file_5, 'r')\n",
    "file_6 = '/home/jacquemm/hdf5/gamma_point/LaPalma_gamma_point_source_20deg_0deg_prod3b_training_0010.hdf5'\n",
    "f_6 = h5py.File(file_6, 'r')\n",
    "injTable = np.array(f_1['/Cameras/LSTCAM/injTable'])\n",
    "nbRow = f_1['/Cameras/LSTCAM'].attrs['nbRow']\n",
    "nbCol = f_1['/Cameras/LSTCAM'].attrs['nbCol']\n",
    "dataset_1 = LSTCamDataset(hdf5_file=f_1,\n",
    "                             transform=transforms.Compose([\n",
    "                                 TelescopeToSquareMatrix(injTable, nbRow, nbCol)\n",
    "                             ]))\n",
    "dataset_2 = LSTCamDataset(hdf5_file=f_2,\n",
    "                             transform=transforms.Compose([\n",
    "                                 TelescopeToSquareMatrix(injTable, nbRow, nbCol)\n",
    "                             ]))\n",
    "dataset_3 = LSTCamDataset(hdf5_file=f_3,\n",
    "                             transform=transforms.Compose([\n",
    "                                 TelescopeToSquareMatrix(injTable, nbRow, nbCol)\n",
    "                             ]))\n",
    "dataset_4 = LSTCamDataset(hdf5_file=f_4,\n",
    "                             transform=transforms.Compose([\n",
    "                                 TelescopeToSquareMatrix(injTable, nbRow, nbCol)\n",
    "                             ]))\n",
    "dataset_5 = LSTCamDataset(hdf5_file=f_6,\n",
    "                             transform=transforms.Compose([\n",
    "                                 TelescopeToSquareMatrix(injTable, nbRow, nbCol)\n",
    "                             ]))\n",
    "dataset_test = LSTCamDataset(hdf5_file=f_6,\n",
    "                             transform=transforms.Compose([\n",
    "                                 TelescopeToSquareMatrix(injTable, nbRow, nbCol)\n",
    "                             ]))\n",
    "\n",
    "\n",
    "dataset_train = ConcatDataset([dataset_1, dataset_2, dataset_3, dataset_4, dataset_5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterable subset creation\n",
    "train_loader = torch.utils.data.DataLoader(dataset=dataset_train,\n",
    "                                           batch_size=len(dataset_train))\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=dataset_test,\n",
    "                                          batch_size=len(dataset_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('/home/jacquemm/hdf5/converted/gamma_point_train', 'w') as f_train:\n",
    "    for i, samples in enumerate(train_loader):\n",
    "        f_train.create_dataset('images', data=samples['image'].numpy(), dtype=np.float32)\n",
    "        f_train.create_dataset('telescopes', data=samples['telescope'].numpy(), dtype=np.float32)\n",
    "        f_train.create_dataset('labels', data=samples['labels'].numpy(), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Can't prepare for writing data (no appropriate function for conversion path)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-b9471665c0a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/jacquemm/hdf5/converted/gamma_point_test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf_test\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mf_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'images'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mf_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'telescopes'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'telescope'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mf_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jacquemm/.local/lib/python3.5/site-packages/h5py/_hl/group.py\u001b[0m in \u001b[0;36mcreate_dataset\u001b[0;34m(self, name, shape, dtype, data, **kwds)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \"\"\"\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0mdsid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_new_dset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m             \u001b[0mdset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jacquemm/.local/lib/python3.5/site-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36mmake_new_dset\u001b[0;34m(parent, shape, dtype, data, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0mdset_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdset_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5d.pyx\u001b[0m in \u001b[0;36mh5py.h5d.DatasetID.write\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_proxy.pyx\u001b[0m in \u001b[0;36mh5py._proxy.dset_rw\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_proxy.pyx\u001b[0m in \u001b[0;36mh5py._proxy.H5PY_H5Dwrite\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Can't prepare for writing data (no appropriate function for conversion path)"
     ]
    }
   ],
   "source": [
    "with h5py.File('/home/jacquemm/hdf5/converted/gamma_point_test', 'w') as f_test:\n",
    "    for i, samples in enumerate(test_loader):\n",
    "        f_test.create_dataset('images', data=samples['image'].numpy(), dtype=np.float32)\n",
    "        f_test.create_dataset('telescopes', data=samples['telescope'].numpy(), dtype=np.float32)\n",
    "        f_test.create_dataset('labels', data=samples['labels'].numpy(), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_1.close()\n",
    "f_2.close()\n",
    "f_3.close()\n",
    "f_4.close()\n",
    "f_5.close()\n",
    "f_6.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
